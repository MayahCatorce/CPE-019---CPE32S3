{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
        "--- | ---\n",
        "Course Code: | CPE 019\n",
        "Code Title: | Emerging Technologies in CpE 2\n",
        "2nd Semester | AY 2023-2024\n",
        "<hr> | <hr>\n",
        "<u>**Hands-on Activity 6.2 Training Neural Networks**\n",
        "**Name** | Catorce, Mayah Mae A.\n",
        "**Section** | CPE32S3\n",
        "**Date Performed**: |March 30, 2024\n",
        "**Date Submitted**: |April 2, 2024\n",
        "**Instructor**: | Engr. Roman Richard\n",
        "\n",
        "<hr>"
      ],
      "metadata": {
        "id": "uuADGe0GwZmb"
      },
      "id": "uuADGe0GwZmb"
    },
    {
      "cell_type": "markdown",
      "id": "union-alcohol",
      "metadata": {
        "id": "union-alcohol"
      },
      "source": [
        "# Activity 1.2 : Training Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "floppy-teens",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-modem",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-april",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cutting-fountain",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entertaining-therapist",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "differential-native",
      "metadata": {
        "id": "differential-native"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "other-married",
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-newsletter",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "studied-twelve",
      "metadata": {
        "id": "studied-twelve"
      },
      "outputs": [],
      "source": [
        "\n",
        "filepath = \"pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "photographic-carnival",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "undefined-inventory",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "undefined-inventory",
        "outputId": "38e6714b-846e-43f0-fa0a-98fbd84e9a71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "279               2                     108              62              10   \n",
              "92                7                      81              78              40   \n",
              "274              13                     106              70               0   \n",
              "335               0                     165              76              43   \n",
              "334               1                      95              60              18   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "279      278  25.3              0.881   22             0  \n",
              "92        48  46.7              0.261   42             0  \n",
              "274        0  34.2              0.251   52             0  \n",
              "335      255  47.9              0.259   26             0  \n",
              "334       58  23.9              0.260   22             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fa4dcbf-ba7e-4a59-83cf-1e1898bc65a9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>62</td>\n",
              "      <td>10</td>\n",
              "      <td>278</td>\n",
              "      <td>25.3</td>\n",
              "      <td>0.881</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>7</td>\n",
              "      <td>81</td>\n",
              "      <td>78</td>\n",
              "      <td>40</td>\n",
              "      <td>48</td>\n",
              "      <td>46.7</td>\n",
              "      <td>0.261</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>13</td>\n",
              "      <td>106</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>34.2</td>\n",
              "      <td>0.251</td>\n",
              "      <td>52</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>0</td>\n",
              "      <td>165</td>\n",
              "      <td>76</td>\n",
              "      <td>43</td>\n",
              "      <td>255</td>\n",
              "      <td>47.9</td>\n",
              "      <td>0.259</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>1</td>\n",
              "      <td>95</td>\n",
              "      <td>60</td>\n",
              "      <td>18</td>\n",
              "      <td>58</td>\n",
              "      <td>23.9</td>\n",
              "      <td>0.260</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fa4dcbf-ba7e-4a59-83cf-1e1898bc65a9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0fa4dcbf-ba7e-4a59-83cf-1e1898bc65a9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0fa4dcbf-ba7e-4a59-83cf-1e1898bc65a9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b83f3f5e-0525-4955-844f-870fa3e21fc8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b83f3f5e-0525-4955-844f-870fa3e21fc8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b83f3f5e-0525-4955-844f-870fa3e21fc8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"diabetes_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"times_pregnant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 13,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7,\n          1,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"glucose_tolerance_test\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32,\n        \"min\": 81,\n        \"max\": 165,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          81,\n          95,\n          106\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"blood_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 60,\n        \"max\": 78,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          78,\n          60,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"skin_thickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18,\n        \"min\": 0,\n        \"max\": 43,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          40,\n          18,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 128,\n        \"min\": 0,\n        \"max\": 278,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          48,\n          58,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.395613191048563,\n        \"min\": 23.9,\n        \"max\": 47.9,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          46.7,\n          23.9,\n          34.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pedigree_function\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2787540134240223,\n        \"min\": 0.251,\n        \"max\": 0.881,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.261,\n          0.26,\n          0.251\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 22,\n        \"max\": 52,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          42,\n          26,\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_diabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "systematic-motorcycle",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "systematic-motorcycle",
        "outputId": "3724d4d5-ee07-4aae-f6dc-7dcc030d9d5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collected-lafayette",
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-parallel",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rational-hollow",
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acceptable-equity",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acceptable-equity",
        "outputId": "e12be521-b970-4689-fae4-05af31a74792"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-reconstruction",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-zealand",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "painted-mathematics",
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "previous-electricity",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "found-bowling",
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "model  = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "level-terminal",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "correct-kingdom",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "correct-kingdom",
        "outputId": "ea403d12-070e-4a6a-99ed-3f2dd363e2ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                108       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "herbal-anderson",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "happy-prompt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "happy-prompt",
        "outputId": "c82b5681-6f66-4707-d1a6-23674d95c9f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 15ms/step - loss: 0.7895 - accuracy: 0.5399 - val_loss: 0.7474 - val_accuracy: 0.5417\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7408 - accuracy: 0.5799 - val_loss: 0.7050 - val_accuracy: 0.5729\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7021 - accuracy: 0.6163 - val_loss: 0.6716 - val_accuracy: 0.6406\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6710 - accuracy: 0.6319 - val_loss: 0.6448 - val_accuracy: 0.6406\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.6580 - val_loss: 0.6232 - val_accuracy: 0.6823\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6250 - accuracy: 0.6806 - val_loss: 0.6059 - val_accuracy: 0.6927\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6080 - accuracy: 0.6944 - val_loss: 0.5917 - val_accuracy: 0.6823\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5939 - accuracy: 0.7083 - val_loss: 0.5798 - val_accuracy: 0.6979\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5818 - accuracy: 0.7240 - val_loss: 0.5697 - val_accuracy: 0.7188\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5714 - accuracy: 0.7292 - val_loss: 0.5613 - val_accuracy: 0.7344\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7413 - val_loss: 0.5539 - val_accuracy: 0.7344\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.7535 - val_loss: 0.5475 - val_accuracy: 0.7500\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7465 - val_loss: 0.5419 - val_accuracy: 0.7448\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7483 - val_loss: 0.5370 - val_accuracy: 0.7448\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7465 - val_loss: 0.5327 - val_accuracy: 0.7500\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7500 - val_loss: 0.5289 - val_accuracy: 0.7604\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5265 - accuracy: 0.7517 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5224 - accuracy: 0.7535 - val_loss: 0.5225 - val_accuracy: 0.7708\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5186 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.7708\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.7587 - val_loss: 0.5172 - val_accuracy: 0.7656\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5119 - accuracy: 0.7604 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5088 - accuracy: 0.7622 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5059 - accuracy: 0.7656 - val_loss: 0.5110 - val_accuracy: 0.7604\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5032 - accuracy: 0.7656 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5008 - accuracy: 0.7639 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4985 - accuracy: 0.7639 - val_loss: 0.5065 - val_accuracy: 0.7604\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4962 - accuracy: 0.7656 - val_loss: 0.5053 - val_accuracy: 0.7604\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.7656 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4921 - accuracy: 0.7639 - val_loss: 0.5033 - val_accuracy: 0.7604\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4902 - accuracy: 0.7656 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4885 - accuracy: 0.7656 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4868 - accuracy: 0.7639 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4851 - accuracy: 0.7639 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4836 - accuracy: 0.7656 - val_loss: 0.4995 - val_accuracy: 0.7760\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4822 - accuracy: 0.7656 - val_loss: 0.4989 - val_accuracy: 0.7760\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4808 - accuracy: 0.7656 - val_loss: 0.4983 - val_accuracy: 0.7812\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4795 - accuracy: 0.7656 - val_loss: 0.4978 - val_accuracy: 0.7812\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4784 - accuracy: 0.7674 - val_loss: 0.4973 - val_accuracy: 0.7812\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7691 - val_loss: 0.4969 - val_accuracy: 0.7812\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4760 - accuracy: 0.7674 - val_loss: 0.4966 - val_accuracy: 0.7812\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7708 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7691 - val_loss: 0.4957 - val_accuracy: 0.7760\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7691 - val_loss: 0.4955 - val_accuracy: 0.7760\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7691 - val_loss: 0.4952 - val_accuracy: 0.7760\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7760\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7708 - val_loss: 0.4948 - val_accuracy: 0.7760\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7708 - val_loss: 0.4947 - val_accuracy: 0.7760\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7708 - val_loss: 0.4945 - val_accuracy: 0.7760\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4666 - accuracy: 0.7691 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4659 - accuracy: 0.7674 - val_loss: 0.4943 - val_accuracy: 0.7812\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7812\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7812\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7812\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.4939 - val_accuracy: 0.7812\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7708 - val_loss: 0.4939 - val_accuracy: 0.7812\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7691 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7691 - val_loss: 0.4938 - val_accuracy: 0.7812\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7691 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7708 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7708 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7743 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7743 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7743 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7743 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7708 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7708 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7708 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7708 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7708 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7760\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7708 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7743 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7743 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7743 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7743 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7743 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7743 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7795 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7778 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7795 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7795 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7778 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7812 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7812 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7812 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7812 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7812 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7812 - val_loss: 0.4950 - val_accuracy: 0.7656\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7812 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7812 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7812 - val_loss: 0.4951 - val_accuracy: 0.7656\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7812 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7812 - val_loss: 0.4952 - val_accuracy: 0.7604\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.7847 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7812 - val_loss: 0.4953 - val_accuracy: 0.7604\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7812 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7812 - val_loss: 0.4954 - val_accuracy: 0.7604\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7812 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7812 - val_loss: 0.4955 - val_accuracy: 0.7604\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7812 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7812 - val_loss: 0.4956 - val_accuracy: 0.7604\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7812 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7812 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7812 - val_loss: 0.4957 - val_accuracy: 0.7604\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7795 - val_loss: 0.4958 - val_accuracy: 0.7604\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7812 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7778 - val_loss: 0.4959 - val_accuracy: 0.7604\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7778 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7778 - val_loss: 0.4960 - val_accuracy: 0.7604\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.7795 - val_loss: 0.4961 - val_accuracy: 0.7604\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7795 - val_loss: 0.4962 - val_accuracy: 0.7604\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7795 - val_loss: 0.4962 - val_accuracy: 0.7604\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7795 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7795 - val_loss: 0.4963 - val_accuracy: 0.7604\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7604\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.4964 - val_accuracy: 0.7604\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7812 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7830 - val_loss: 0.4965 - val_accuracy: 0.7604\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7812 - val_loss: 0.4966 - val_accuracy: 0.7604\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7812 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7830 - val_loss: 0.4967 - val_accuracy: 0.7604\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7830 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7812 - val_loss: 0.4968 - val_accuracy: 0.7604\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7812 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7830 - val_loss: 0.4969 - val_accuracy: 0.7604\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7812 - val_loss: 0.4970 - val_accuracy: 0.7604\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7830 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7830 - val_loss: 0.4971 - val_accuracy: 0.7604\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7812 - val_loss: 0.4972 - val_accuracy: 0.7604\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7830 - val_loss: 0.4973 - val_accuracy: 0.7604\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7830 - val_loss: 0.4974 - val_accuracy: 0.7604\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7830 - val_loss: 0.4975 - val_accuracy: 0.7604\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7847 - val_loss: 0.4976 - val_accuracy: 0.7604\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7847 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7830 - val_loss: 0.4977 - val_accuracy: 0.7604\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7830 - val_loss: 0.4978 - val_accuracy: 0.7604\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7830 - val_loss: 0.4979 - val_accuracy: 0.7604\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7604\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.7847 - val_loss: 0.4981 - val_accuracy: 0.7604\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7847 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7830 - val_loss: 0.4983 - val_accuracy: 0.7604\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7847 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7847 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7847 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7847 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7847 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7847 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7847 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7847 - val_loss: 0.4990 - val_accuracy: 0.7604\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7847 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7847 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7847 - val_loss: 0.4992 - val_accuracy: 0.7604\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.4994 - val_accuracy: 0.7604\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7604\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4325 - accuracy: 0.7847 - val_loss: 0.4995 - val_accuracy: 0.7604\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7552\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.4996 - val_accuracy: 0.7552\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.7830 - val_loss: 0.4997 - val_accuracy: 0.7552\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7552\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.4997 - val_accuracy: 0.7552\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7552\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.4998 - val_accuracy: 0.7552\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.4999 - val_accuracy: 0.7552\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4311 - accuracy: 0.7882 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4310 - accuracy: 0.7882 - val_loss: 0.5000 - val_accuracy: 0.7552\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4309 - accuracy: 0.7865 - val_loss: 0.5001 - val_accuracy: 0.7552\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.7865 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.7899 - val_loss: 0.5002 - val_accuracy: 0.7552\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.5002 - val_accuracy: 0.7500\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.7882 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4302 - accuracy: 0.7882 - val_loss: 0.5003 - val_accuracy: 0.7552\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4301 - accuracy: 0.7882 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4300 - accuracy: 0.7882 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7899 - val_loss: 0.5004 - val_accuracy: 0.7552\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7882 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7899 - val_loss: 0.5005 - val_accuracy: 0.7552\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7882 - val_loss: 0.5006 - val_accuracy: 0.7552\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unsigned-nevada",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unsigned-nevada",
        "outputId": "9e932fe4-c8fa-4ec7-9b08-c1f731b574a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_prob_nn_1 = model.predict(X_test_norm)\n",
        "y_pred_class_nn_1 = np.argmax(y_pred_prob_nn_1, axis=1) #.predict_classes is depreciated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tough-catering",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tough-catering",
        "outputId": "18b3bca0-95be-40b6-f126-3c658a54b155"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "combined-zimbabwe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "combined-zimbabwe",
        "outputId": "a8636f97-5877-4445-a835-fd7a9bf7fbbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5275471 ],\n",
              "       [0.8619003 ],\n",
              "       [0.27257654],\n",
              "       [0.18358831],\n",
              "       [0.1970193 ],\n",
              "       [0.51728374],\n",
              "       [0.03410977],\n",
              "       [0.26623526],\n",
              "       [0.91236424],\n",
              "       [0.134162  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "going-estonia",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "supposed-moderator",
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "second-festival",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eleven-nebraska",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "eleven-nebraska",
        "outputId": "a5041e1f-3347-4175-fad5-69a90eaebc72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.641\n",
            "roc-auc is 0.820\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "invalid-nevada",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hidden-physics",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hidden-physics",
        "outputId": "7e2249fa-283d-4a49-a922-fe20090445d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "banned-spider",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "banned-spider",
        "outputId": "53bd8f91-c751-42be-b82f-f5982fc12b67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7aed127cb940>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSGUlEQVR4nO3de1hU1f4G8HdmuAkKqCgXQVDDO4IhElpqyQk7HjU7J8ljoobaRStDTanUtFOYmllmaR4v9bNSO2nZzTJE00RRiDQjQhOQ5KIZIJiiM/v3x24GBmaG2cPceT/PM88we/aeWdtR5nWt71pbJgiCACIiIiI7Jrd1A4iIiIiaw8BCREREdo+BhYiIiOweAwsRERHZPQYWIiIisnsMLERERGT3GFiIiIjI7jGwEBERkd1zsXUDzEGlUuHChQto164dZDKZrZtDRERERhAEAVeuXEFQUBDkcsN9KE4RWC5cuICQkBBbN4OIiIhMcP78eQQHBxvcxykCS7t27QCIJ+zt7W3j1hAREZExqqurERISovkeN8QpAot6GMjb25uBhYiIyMEYU87BolsiIiKyeyYFlnXr1iEsLAweHh6IjY1FVlaW3n23bt0KmUymdfPw8NDap6amBrNnz0ZwcDDatGmDvn37Yv369aY0jYiIiJyQ5CGhHTt2ICUlBevXr0dsbCzWrFmDhIQE5Ofno3PnzjqP8fb2Rn5+vuZx466flJQU7N+/H9u2bUNYWBi+/vprPPbYYwgKCsLYsWOlNpGIiIicjOTAsnr1asyYMQPTpk0DAKxfvx6ff/45Nm/ejIULF+o8RiaTISAgQO9rHjlyBFOmTMGIESMAADNnzsSGDRuQlZXFwEJEZAWCIODmzZtQKpW2bgo5GYVCARcXlxYvOyIpsNTV1SE7OxupqamabXK5HPHx8cjMzNR7XE1NDUJDQ6FSqXDrrbfipZdeQr9+/TTPDxkyBHv27MFDDz2EoKAgHDhwAL/88gteffVVE06JiIikqKurQ2lpKa5evWrrppCT8vT0RGBgINzc3Ex+DUmB5dKlS1AqlfD399fa7u/vj59//lnnMb169cLmzZsxYMAAVFVVYdWqVRgyZAhOnz6tmXO9du1azJw5E8HBwXBxcYFcLsfGjRsxbNgwna95/fp1XL9+XfO4urpaymkQEdFfVCoVzp07B4VCgaCgILi5uXEBTjIbQRBQV1eHixcv4ty5cwgPD292gTh9LD6tOS4uDnFxcZrHQ4YMQZ8+fbBhwwa88MILAMTAcvToUezZswehoaH49ttvMWvWLAQFBSE+Pr7Ja6alpWHp0qWWbjoRkdOrq6uDSqVCSEgIPD09bd0cckJt2rSBq6srioqKUFdX12TijbEkBRY/Pz8oFAqUl5drbS8vLzdYo9KQq6srBg4ciDNnzgAA/vzzTzzzzDPYvXs3Ro8eDQAYMGAAcnNzsWrVKp2BJTU1FSkpKZrH6oVniIjINKb+r5fIGOb4+yXpFdzc3BAdHY309HTNNpVKhfT0dK1eFEOUSiVOnTqFwMBAAMCNGzdw48aNJiejUCigUql0voa7u7tmkTguFkdEROT8JA8JpaSkYMqUKRg0aBAGDx6MNWvWoLa2VjNrKCkpCV26dEFaWhoAYNmyZbjttttwyy23oLKyEitXrkRRURGmT58OQJzyPHz4cMyfPx9t2rRBaGgoDh48iHfffRerV68246kSERGRo5IcWBITE3Hx4kUsXrwYZWVliIqKwt69ezWFuMXFxVq9JX/88QdmzJiBsrIytG/fHtHR0Thy5Aj69u2r2Wf79u1ITU3FpEmTcPnyZYSGhuLFF1/EI488YoZTbJmSEqCgAAgPB5q5LhMRETmwsLAwzJkzB3PmzLF1U0gHmSAIgq0b0VLV1dXw8fFBVVWVWYeHNm0CZs4EVCpALgfefhtITjbbyxMR2dy1a9dw7tw5dOvWzeRiSGtrbhbTkiVL8Pzzz0t+3YsXL8LLy6tFxccjRoxAVFQU1qxZY/JrOCN9f8+kfH87xcUPLaGkpD6sAOL9ww8DCQnsaSEi0slKXdKlpaWan3fs2IHFixdrrabetm1bzc+CIECpVMLFpfmvu06dOpm3oWRWLAvXo6CgPqyoKZXAX5ObiIiclyAAtbXSbm++CYSGAnfdJd6/+ab01zCywz8gIEBz8/Hx0aymHhAQgJ9//hnt2rXDl19+iejoaLi7u+Pw4cM4e/Ysxo0bB39/f7Rt2xYxMTH45ptvtF43LCxMq2dEJpPhv//9L8aPHw9PT0+Eh4djz549Lfqj/eijj9CvXz+4u7sjLCwMr7zyitbzb775JsLDw+Hh4QF/f3/861//0jz3v//9DxEREWjTpg06duyI+Ph41NbWtqg9joQ9LHqEh4vDQA1Di0IB3HKL7dpERGQVV68CDXopJFOpgFmzxJsUNTWAl5fp79vAwoULsWrVKnTv3h3t27fH+fPn8fe//x0vvvgi3N3d8e6772LMmDHIz89H165d9b7O0qVLsWLFCqxcuRJr167FpEmTUFRUhA4dOkhuU3Z2NiZMmIDnn38eiYmJOHLkCB577DF07NgRU6dOxYkTJ/DEE0/g//7v/zBkyBBcvnwZhw4dAiD2Kk2cOBErVqzA+PHjceXKFRw6dAhOUNVhNAYWPYKDxZqVvyYzQS4HNmzgcBARkSNYtmwZ/va3v2ked+jQAZGRkZrHL7zwAnbv3o09e/Zg9uzZel9n6tSpmDhxIgDgpZdewuuvv46srCyMGjVKcptWr16NkSNHYtGiRQCAnj174qeffsLKlSsxdepUFBcXw8vLC//4xz/Qrl07hIaGYuDAgQDEwHLz5k3cd999CA0NBQBERERIboMj45CQAcnJwIQJ4s9PPcWCWyJqJTw9xd4OY2/5+eL/6hpSKMTtUl7HjCvtDho0SOtxTU0N5s2bhz59+sDX1xdt27ZFXl4eiouLDb7OgAEDND97eXnB29sbFRUVJrUpLy8PQ4cO1do2dOhQFBQUQKlU4m9/+xtCQ0PRvXt3TJ48Ge+9957m+k6RkZEYOXIkIiIicP/992Pjxo34448/TGqHo2JgaYY6kF+6ZNt2EBFZjUwmDs0Ye+vZU+ySVijE4xUKsUu6Z09pr2PGaxh5NRpamjdvHnbv3o2XXnoJhw4dQm5uLiIiIlBXV2fwdVxdXRv90cj0LmraUu3atUNOTg4++OADBAYGYvHixYiMjERlZSUUCgX27duHL7/8En379sXatWvRq1cvnDt3ziJtsUcMLM3o0UO8Z7EtEZEByclAYSGQkSHe21mX9HfffYepU6di/PjxiIiIQEBAAAoLC63ahj59+uC7775r0q6ePXtC8VfYc3FxQXx8PFasWIGTJ0+isLAQ+/fvByCGpaFDh2Lp0qX4/vvv4ebmht27d1v1HGyJNSzNUBfZnj1r23YQEdm94GC7LfQLDw/Hrl27MGbMGMhkMixatMhiPSUXL15Ebm6u1rbAwEDMnTsXMTExeOGFF5CYmIjMzEy88cYbePPNNwEAn332GX799VcMGzYM7du3xxdffAGVSoVevXrh2LFjSE9Px913343OnTvj2LFjuHjxIvr06WORc7BHDCzNUPewlJWJQ6wtKZwnIiLbWL16NR566CEMGTIEfn5+WLBgAaqrqy3yXu+//z7ef/99rW0vvPACnnvuOezcuROLFy/GCy+8gMDAQCxbtgxTp04FAPj6+mLXrl14/vnnce3aNYSHh+ODDz5Av379kJeXh2+//RZr1qxBdXU1QkND8corr+Cee+6xyDnYI650awQ/P+D334EffgAa1F8RETk8R1zplhyPOVa6ZQ2LEdTDQqxjISIisg0GFiOoh4VYx0JERGQbDCxGYA8LERGRbTGwGIFTm4mIiGyLgcUInNpMRERkWwwsRlD3sBQVMbQQERHZAgOLET79tP7nnj2BTZts1xYiIqLWiIGlGSUlwMMP1z9WqcTHJSW2axMREVFrw8DSjIICMaQ0pFSyAJeIyNGNGDECc+bM0TwOCwvDmjVrDB4jk8nw8ccft/i9zfU6rQkDSzPCw3VfNV1diEtERNY1ZswYjBo1Sudzhw4dgkwmw8mTJyW/7vHjxzFz5syWNk/L888/j6ioqCbbS0tLLb6s/tatW+Hr62vR97AmBpZmBAeLV01vGFo2bLDb63sRETm95ORk7Nu3DyU6xua3bNmCQYMGYYAJ11Hp1KkTPD09zdHEZgUEBMDd3d0q7+UsGFiMkJwMfPaZ+HPHjnZ31XQiIrtQUgJkZFi+xu8f//gHOnXqhK1bt2ptr6mpwYcffojk5GT8/vvvmDhxIrp06QJPT09ERETggw8+MPi6jYeECgoKMGzYMHh4eKBv377Yt29fk2MWLFiAnj17wtPTE927d8eiRYtw48YNAGIPx9KlS/HDDz9AJpNBJpNp2tx4SOjUqVO466670KZNG3Ts2BEzZ85ETU2N5vmpU6fi3nvvxapVqxAYGIiOHTti1qxZmvcyRXFxMcaNG4e2bdvC29sbEyZMQHl5ueb5H374AXfeeSfatWsHb29vREdH48SJEwCAoqIijBkzBu3bt4eXlxf69euHL774wuS2GINXazbSHXeI97//Dly+DHToYNv2EBFZiiAAV69KO+add4DHHxdr/uRyYO1aYMoUaa/h6QnIZM3v5+LigqSkJGzduhXPPvssZH8d9OGHH0KpVGLixImoqalBdHQ0FixYAG9vb3z++eeYPHkyevTogcGDBzf7HiqVCvfddx/8/f1x7NgxVFVVadW7qLVr1w5bt25FUFAQTp06hRkzZqBdu3Z4+umnkZiYiB9//BF79+7FN998AwDw8fFp8hq1tbVISEhAXFwcjh8/joqKCkyfPh2zZ8/WCmUZGRkIDAxERkYGzpw5g8TERERFRWHGjBnN/6HpOD91WDl48CBu3ryJWbNmITExEQcOHAAATJo0CQMHDsRbb70FhUKB3NxcuLq6AgBmzZqFuro6fPvtt/Dy8sJPP/2Etm3bSm6HJIITqKqqEgAIVVVVFn2fkBBBAAThyBGLvg0RkdX8+eefwk8//ST8+eefmm01NeLvOmvfamqMb3deXp4AQMjIyNBsu+OOO4QHH3xQ7zGjR48W5s6dq3k8fPhw4cknn9Q8Dg0NFV599VVBEAThq6++ElxcXITffvtN8/yXX34pABB2796t9z1WrlwpREdHax4vWbJEiIyMbLJfw9d5++23hfbt2ws1Df4APv/8c0EulwtlZWWCIAjClClThNDQUOHmzZuafe6//34hMTFRb1u2bNki+Pj46Hzu66+/FhQKhVBcXKzZdvr0aQGAkJWVJQiCILRr107YunWrzuMjIiKE559/Xu97N6br75kgSPv+5pCQBL17i/c//2zbdhARtXa9e/fGkCFDsHnzZgDAmTNncOjQIST/NWavVCrxwgsvICIiAh06dEDbtm3x1Vdfobi42KjXz8vLQ0hICIKCgjTb4uLimuy3Y8cODB06FAEBAWjbti2ee+45o9+j4XtFRkbCy8tLs23o0KFQqVTIz8/XbOvXrx8UCoXmcWBgICoqKiS9V8P3DAkJQUhIiGZb37594evri7y8PABASkoKpk+fjvj4eCxfvhxnG6yc+sQTT+A///kPhg4diiVLlphU5CwVA4sEvXqJ9wwsROTMPD2Bmhrjb/n5umdT5udLex2p9a7Jycn46KOPcOXKFWzZsgU9evTA8OHDAQArV67Ea6+9hgULFiAjIwO5ublISEhAXV2dmf6UgMzMTEyaNAl///vf8dlnn+H777/Hs88+a9b3aEg9HKMmk8mgarzuhhk9//zzOH36NEaPHo39+/ejb9++2L17NwBg+vTp+PXXXzF58mScOnUKgwYNwtq1ay3WFoCBRRL2sBBRayCTAV5ext969hRnU6r/869QiLMpe/aU9jrG1K80NGHCBMjlcrz//vt499138dBDD2nqWb777juMGzcODz74ICIjI9G9e3f88ssvRr92nz59cP78eZSWlmq2HT16VGufI0eOIDQ0FM8++ywGDRqE8PBwFBUVae3j5uYGpVLZ7Hv98MMPqK2t1Wz77rvvIJfL0Uv9P2UzU5/f+fPnNdt++uknVFZWom/fvpptPXv2xFNPPYWvv/4a9913H7Zs2aJ5LiQkBI888gh27dqFuXPnYuPGjRZpqxoDiwTqwNKgh46IiCDOniwsFGcJFRZaZzZl27ZtkZiYiNTUVJSWlmLq1Kma58LDw7Fv3z4cOXIEeXl5ePjhh7VmwDQnPj4ePXv2xJQpU/DDDz/g0KFDePbZZ7X2CQ8PR3FxMbZv346zZ8/i9ddf1/RAqIWFheHcuXPIzc3FpUuXcP369SbvNWnSJHh4eGDKlCn48ccfkZGRgccffxyTJ0+Gv7+/tD+URpRKJXJzc7VueXl5iI+PR0REBCZNmoScnBxkZWUhKSkJw4cPx6BBg/Dnn39i9uzZOHDgAIqKivDdd9/h+PHj6NOnDwBgzpw5+Oqrr3Du3Dnk5OQgIyND85ylMLBIoA4sZ88CLZhJRkTklIKDgREjrLtOVXJyMv744w8kJCRo1Zs899xzuPXWW5GQkIARI0YgICAA9957r9GvK5fLsXv3bvz5558YPHgwpk+fjhdffFFrn7Fjx+Kpp57C7NmzERUVhSNHjmDRokVa+/zzn//EqFGjcOedd6JTp046p1Z7enriq6++wuXLlxETE4N//etfGDlyJN544w1pfxg61NTUYODAgVq3MWPGQCaT4ZNPPkH79u0xbNgwxMfHo3v37tixYwcAQKFQ4Pfff0dSUhJ69uyJCRMm4J577sHSpUsBiEFo1qxZ6NOnD0aNGoWePXvizTffbHF7DZEJgiBY9B2soLq6Gj4+PqiqqoK3t7fF3kcQAG9vcax161Zg5EguIEdEju3atWs4d+4cunXrBg8PD1s3h5yUvr9nUr6/2cMigUwmLhwHAFOnAqGhvHIzERGRNTCwSFBSAjSsp+KVm4mIiKyDgaU5DdaaLiho+jSv3ExERGR5DCyGvP22OO5z111AaCjCT3zQZNodr9xMRERkeQws+pSUAI8+Ko77AIBKheDUyXhxfqVmF/VaAyy8JSIisiyTAsu6desQFhYGDw8PxMbGIisrS+++W7du1VylUn3TVYmel5eHsWPHwsfHB15eXoiJiZG8vLFZFRTUhxU1pRILEnKhbv7+/bxyMxE5ByeYMEp2zBx/vyQHlh07diAlJQVLlixBTk4OIiMjkZCQYPB6Bt7e3igtLdXcGq8EePbsWdx+++3o3bs3Dhw4gJMnT2LRokW2nWIXHq5zrWl5z1vQv7/48NIl6zeLiMic1Mu9X5V6eWYiCdR/vxpfXkAKF6kHrF69GjNmzMC0adMAAOvXr8fnn3+OzZs3Y+HChTqPkclkCAgI0Puazz77LP7+979jxYoVmm09evSQ2jTzCg4Wa1hmzBAXYJHJNOM//fsDJ04AP/4I3HefbZtJRNQSCoUCvr6+mv90enp6apa3J2opQRBw9epVVFRUwNfXV+vijVJJCix1dXXIzs5GamqqZptcLkd8fDwyMzP1HldTU4PQ0FCoVCrceuuteOmll9CvXz8AgEqlwueff46nn34aCQkJ+P7779GtWzekpqZKWpXQIpKTgWPHgI0bxZ//Gv9R97D8+KMN20ZEZCbq/1CaeuVfoub4+voa7LgwhqTAcunSJSiVyibXNvD398fPeq4I2KtXL2zevBkDBgxAVVUVVq1ahSFDhuD06dMIDg5GRUUFampqsHz5cvznP//Byy+/jL179+K+++5DRkaG5sqbDV2/fl3regzV1dVSTkOayEjxvsH4jzqwnDplubclIrIWmUyGwMBAdO7cGTd43REyM1dX1xb1rKhJHhKSKi4uDnFxcZrHQ4YMQZ8+fbBhwwa88MILmktjjxs3Dk899RQAaK7JsH79ep2BJS0tTXM9A4vr3l28//VXzaaICPG+oAC4dg3gatZE5AwUCoVZvliILEFS0a2fnx8UCkWTK16Wl5cb3dXj6uqKgQMH4sxfq635+fnBxcVF63LWgHjpa32zhFJTU1FVVaW5Nbw8ttl16ybe//qrWMsCIDAQaN9eXDSOV24mIiKyPEmBxc3NDdHR0UhPT9dsU6lUSE9P1+pFMUSpVOLUqVMIDAzUvGZMTAzyG33z//LLLwgNDdX5Gu7u7vD29ta6WUxYmHhfUwP8/jsAsf5WPSy0cyeX5iciIrI0ydOaU1JSsHHjRrzzzjvIy8vDo48+itraWs2soaSkJK2i3GXLluHrr7/Gr7/+ipycHDz44IMoKirC9OnTNfvMnz8fO3bswMaNG3HmzBm88cYb+PTTT/HYY4+Z4RRbyMMDUF+yvMGwkLrX9KWXeBFEIiIiS5Ncw5KYmIiLFy9i8eLFKCsrQ1RUFPbu3aspxC0uLoa8wfolf/zxB2bMmIGysjK0b98e0dHROHLkiNYQ0Pjx47F+/XqkpaXhiSeeQK9evfDRRx/h9ttvN8MpmkH37sCFC2JgGTwYJSXAwYP1T6svgpiQwFVviYiILEEmOMHyhtXV1fDx8UFVVZVlhoemTAHefVfsTklNRUaGeHmhxjIygBEjzP/2REREzkjK9zevJWSMhoW30LsILi+CSEREZCEMLMZoNLVZvQiumlzOiyASERFZEgOLMdQ9LOfOaTYlJwN//7v488KFvAgiERGRJTGwGEPdw1JUpBVa1DXBDSYPERERkQUwsBjjiy/Ee5VKLFT5aw7zwIHi5u+/t1G7iIiIWgnOEmpOSYm40MpflxAAIFbYFhai3DUYAQHiQnLV1UDbtuZ9ayIiImfGWULmVFCgHVYAcU3+M2fg7y+uKScIwA8/2KZ5RERErQEDS3OamcPMYSEiIiLLY2BpjnoOszq0yGRac5jVgeWLL3hNISIiIkthYDFGcrK40i0gzhhqMIf5r+sh4ssveU0hIiIiS2FgMdbQoeL9+fNiDQvEHpUNG+p3UV9TiD0tRERE5sXAYqyQEMDNDairA4qLARisxyUiIiIzYmAxlkIB9Ogh/lxQAIDXFCIiIrIWBhYpwsPF+78Ci7oeVyYTNzeqxyUiIiIzYWCRolFgAcT623feEX8OC+M1hYiIiCyBgUWKnj3F+19+0dqsvgjiuXPA5ctWbhMREVErwMAihY4eFgDo2LG+biUry8ptIiIiagUYWKRQB5Zz54AbN7Seuu028f7YMSu3iYiIqBVgYJEiKAho00acu1xYqPVUbKx4z8BCRERkfgwsUsjl9WM///uf1gpx6sDy3Xfi2nJERERkPgwsUrm6ivfPPKO1Fn9Ojri5ulqcLcQl+omIiMxHJgiCYOtGtFR1dTV8fHxQVVUFb29vy71RSQnQtSvQ8I9MoUBJ5nmE3haoteqtQiGOGnFNFiIiIt2kfH+zh0WKggLtsAIASiUKDpdziX4iIiILYmCRQs9a/OG3+3OJfiIiIgtiYJEiOBh44436xwoFsGEDgmMC8fbb4kO1V17hcBAREZG5MLBI9eijYlUtAGzbplmLPzlZrFkJCRGf6tbNJq0jIiJySgwspoiKEu8rKrQ2BwcDo0aJPx86ZN0mEREROTMGFlP06yfe//hjk6fuuEO8Z2AhIiIyHwYWU/TvL96fPt3kqdtvF+9PnAC++EJrbTkiIiIyEQOLKRr2sDSa5hwWBvj6itOaR4/WWluOiIiITMTAYopevQAXF3FZ299+03rqt9+Aysr6xyoV8PDD7GkhIiJqCQYWU7i5AT17ij83qmMpKGi6OxeRIyIiahkGFlOph4U+/lir+0TP2nJcRI6IiKgFGFhMdf26eL9hg1ahSnCwuElNLhcfcxE5IiIi0zGwmKKkBPj00/rHjQpVpk8H/vlP8amHH9asLUdEREQmMimwrFu3DmFhYfDw8EBsbCyysrL07rt161bIZDKtm4eHh979H3nkEchkMqxZs8aUplmHnosgNixUGTdOvD9+3IrtIiIiclKSA8uOHTuQkpKCJUuWICcnB5GRkUhISEBFo1VfG/L29kZpaanmVlRUpHO/3bt34+jRowgKCpLaLOsyolBl5EjxPjsbuHzZim0jIiJyQpIDy+rVqzFjxgxMmzYNffv2xfr16+Hp6YnNmzfrPUYmkyEgIEBz8/f3b7LPb7/9hscffxzvvfceXF1dpTbLuoKDgbffrn+so1AlKAjo00fsiFm7ltOaiYiIWkJSYKmrq0N2djbi4+PrX0AuR3x8PDIzM/UeV1NTg9DQUISEhGDcuHE43WiFWJVKhcmTJ2P+/Pnop559Y8D169dRXV2tdbO65GRg/Hjx5/nzdRaqBAaK988/zwXkiIiIWkJSYLl06RKUSmWTHhJ/f3+UlZXpPKZXr17YvHkzPvnkE2zbtg0qlQpDhgxBSYMuh5dffhkuLi544oknjGpHWloafHx8NLcQ9SWSrS0mRrw/f77JUyUlQEZG/WMuIEdERGQ6i88SiouLQ1JSEqKiojB8+HDs2rULnTp1woa/5v5mZ2fjtdde0xTnGiM1NRVVVVWa23kdgcEqDFxTyIi6XCIiIjKSpMDi5+cHhUKB8vJyre3l5eUICAgw6jVcXV0xcOBAnPnrm/vQoUOoqKhA165d4eLiAhcXFxQVFWHu3LkICwvT+Rru7u7w9vbWutmEevgqLw+4eVPrKS4gR0REZD6SAoubmxuio6ORnp6u2aZSqZCeno64uDijXkOpVOLUqVMI/KvAY/LkyTh58iRyc3M1t6CgIMyfPx9fffWVlOZZX1gY4OkJ1NUBZ89qPaWuy23YacQF5IiIiEzjIvWAlJQUTJkyBYMGDcLgwYOxZs0a1NbWYtq0aQCApKQkdOnSBWlpaQCAZcuW4bbbbsMtt9yCyspKrFy5EkVFRZg+fToAoGPHjujYsaPWe7i6uiIgIAC9evVq6flZllwu9rIcPy5eU6hRe5OTxWLbv/0NcHcH/v1vG7WTiIjIwUkOLImJibh48SIWL16MsrIyREVFYe/evZpC3OLiYsgbjIX88ccfmDFjBsrKytC+fXtER0fjyJEj6Nu3r/nOwpbUgeX06frlbRsYORIICRHrcg8cAO65x/pNJCIicnQyQWhcGup4qqur4ePjg6qqKuvXs7zyCjBvHjB8OLBtm84xn4cfFoeHxo8HXn+dw0JERESAtO9vXkuopdTzlA8e1LvYinodvN27uR4LERGRKdjD0hIlJWICUanqtykUQGGhphvFiF2IiIhaJfawWEtBgXYSAZostmLELkRERNQMBpaWMGKxFa7HQkRE1HIMLC3ReLEVmazJYivqXRSK+sNeeonDQURERFIwsLRUcjKwbp3484ABOi+CmJws1qxERIiPPTys1zwiIiJnwMBiDnffLd7n5Ymr3uoQHAz8tbYeNm/mRRCJiIikYGAxh+7dAV9fMazouBCimjrL/PADpzcTERFJwcBiDjIZEB0t/nzihM5dSkqAZ56pf6xSiQvKsaeFiIioeQws5qIOLNnZOp/m9GYiIiLTMbCYy6BB4r2ewMLpzURERKZjYDEXdQ9Lbi7w669NntY1vXnCBE5vJiIiMgYDi7ns3y/e37wpdqfoqKhVT2+eNUt8nJ8PZGSwjoWIiKg5vJaQOUi8YNCFC0CXLvWP5XKx90XHEi5EREROi9cSsjaJFbWNd+WMISIiIsMYWMxBYkVtQUHTbZwxREREpB8DiznoqqhdtUpvRS1nDBEREUnDwGIu6orakBDxsYH0YcQ1E4mIiKgBBhZzCg4GRo4Uf87MNLhrcjLw/vviz56eYhEua1iIiIh0Y2AxtyFDxPtmAgsgrsPSoQNQWwvccw+vL0RERKQPA4u5xcWJ91lZ4posBly4APzxR/1jzhYiIiLSjYHF3Pr2Bby9xW6TLVsMpo+CAqDxKjicLURERNQUA4u5yeX11bMzZxoc5+FsISIiIuMwsJhbSQmQl1f/2MA4j3q2UMPQsnYtZwsRERE1xsBibhLHeZKTxWsldu4sPi4uZg0LERFRYwws5mbCOE9oKDB0qPjz8uWcLURERNQYA4u5qcd51OTyZleFKykBPvmk/jFnCxEREWljYLGE5GTggQfEnx95pNnLMEu8diIREVGrw8BiKfHx4v3p083uytlCREREhjGwWIp6xdusLODGDYO76rp24qBBFmwbERGRg2FgsZRevQBfX+DPP4GTJ5vdXX3txHHjxMfHjrH4loiISI2BxVLkcuC228Sf33nH6AraTz+t/5nFt0RERCIGFktycxPv1641qruExbdERES6MbBYSkkJ8Nln9Y+N6C7RVXwrl7P4loiIiIHFUkzoLtFVfOvnB+Tnc1iIiIhaN5MCy7p16xAWFgYPDw/ExsYiKytL775bt26FTCbTunl4eGiev3HjBhYsWICIiAh4eXkhKCgISUlJuHDhgilNsx8mzlVWF99+9hng7g5UVIgzpFmAS0RErZnkwLJjxw6kpKRgyZIlyMnJQWRkJBISElBRUaH3GG9vb5SWlmpuRUVFmueuXr2KnJwcLFq0CDk5Odi1axfy8/MxduxY087IXqi7S2Qy8bFM1uyKtw0PjYwE6urqt7EAl4iIWjOZIDS+Up9hsbGxiImJwRtvvAEAUKlUCAkJweOPP46FCxc22X/r1q2YM2cOKisrjX6P48ePY/DgwSgqKkLXrl2b3b+6uho+Pj6oqqqCt7e30e9jFTt2iKve+vsDpaX1AaYZGRnAXXfp3j5ihHmbSEREZAtSvr8l9bDU1dUhOzsb8epVXAHI5XLEx8cjMzNT73E1NTUIDQ1FSEgIxo0bh9PNrP5aVVUFmUwGX19fnc9fv34d1dXVWje7NXasOLZTXg788ovRh+krwPXyMnP7iIiIHICkwHLp0iUolUr4+/trbff390dZWZnOY3r16oXNmzfjk08+wbZt26BSqTBkyBCU6BnbuHbtGhYsWICJEyfqTVtpaWnw8fHR3EJCQqSchnW1aVO/6u3+/UYfpqsAV6USl3ZhLQsREbU2Fp8lFBcXh6SkJERFRWH48OHYtWsXOnXqhA0bNjTZ98aNG5gwYQIEQcBbb72l9zVTU1NRVVWluZ0/f96Sp9By6rGd7dslFaEkJwOZmdqjSKxlISKi1khSYPHz84NCoUB5ebnW9vLycgQEBBj1Gq6urhg4cCDONJreqw4rRUVF2Ldvn8GxLHd3d3h7e2vd7FptrXj/7beSp/vU1ACNq4y4mBwREbU2kgKLm5sboqOjkZ6ertmmUqmQnp6OuLg4o15DqVTi1KlTCAwM1GxTh5WCggJ888036Nixo5Rm2beSEmDFivrHErtIWMtCRERkwpBQSkoKNm7ciHfeeQd5eXl49NFHUVtbi2nTpgEAkpKSkJqaqtl/2bJl+Prrr/Hrr78iJycHDz74IIqKijB9+nQAYlj517/+hRMnTuC9996DUqlEWVkZysrKUNdwXq+jauF6+6xlISIiAlykHpCYmIiLFy9i8eLFKCsrQ1RUFPbu3aspxC0uLoa8QZfAH3/8gRkzZqCsrAzt27dHdHQ0jhw5gr59+wIAfvvtN+zZswcAEBUVpfVeGRkZGOHoc3jVXSQNQ4sRC8g1lJwMDBgAxMbWDw+pO2oSEoxa2oWIiMihSV6HxR7Z9TosgNgVMnNmfWh5803g0UclvQTXZSEiImdjsXVYyETq9fb9/MTHPXpIfgldtSwymbh0P2cMERGRs2NgsZaQEGDMGPHnr7+WfLiuWhZBABITeZ0hIiJyfgws1nT33eL9rl0mdYuoO2ref197O9dmISIiZ8fAYk3q1YDPnTO5WyQ4GNC15I1SKS4yR0RE5IwYWKylpASYO7f+cQu6RXTVswDiNRY5NERERM6IgcVaWrgeS0PqepbGoYVDQ0RE5KwYWKxFV7eIxPVYGkpOBj74oOl2LttPRETOiIHFWnRN85k7t0Wrvg0ZwmX7iYiodWBgsSb1NJ+RI8XHDS/DbAIu209ERK0FA4u1BQcDDz0k/vzFFy1+ueRkcXZQw+zDWhYiInI2DCy2MGqUOHZz6hSwfXuLk0VNTf01htQ4zZmIiJwJA4stdOgAdO8u/jxxYouXquU0ZyIicnYMLLZQUgKcPVv/uIVjOJzmTEREzo6BxRYKCnSP4bRgPrKhac4ffsjQQkREjo2BxRbMvCaLmq5pzgCQksILJBIRkWNjYLEF9RiOemqPTAZs2NCiNVkavmzDac5qKhUwcyZw/HiL3oKIiMgmGFhsJTlZHKsBAG9vICnJbC9bWAisXt30Oa7RQkREjoqBxZbuvRfw8wOqqoDXXzdboUlwMHD//bqHh1iIS0REjoiBxZYUCqB3b/HnefPMWmiib+YQwDVaiIjI8TCw2FJJCfDdd/WPzdz9kZwMHD3KNVqIiMjxMbDYkgWmNzcWE6N/jRYW4RIRkaNgYLElC01vbkzfGi0swiUiIkfBwGJLugpN1q9v8fRmXfSt0aLuadm5k4W4RERkvxhYbC05Gfj5Z8DdXXwcFWWRtzFUhKtSAYmJXFyOiIjsFwOLPQgPB8aOFX9etcpiXR2GinAB1rUQEZH9YmCxFx07ivc7dli0q0NdhKtrNVyAdS1ERGSfZILQeJqK46muroaPjw+qqqrg7e1t6+ZIV1IihhSVqn6bQiEuWWuBehb1W2ZmitObG76tmlwu9sbExFjk7YmIiCR9f7OHxR4UFDRNDWae3tyYejVcQ3Ut7GkhIiJ7wcBiD6w0vVkXQ3UtrGkhIiJ7wcBiD3RdZvnRRy02HNSYvsXlADG0xMYCK1cCGRmc+kxERLbBwGIv1JdZvv9+8fHJk1ZNB4Z6WgQBePpp4K67OPWZiIhsg4HFngQHA337ij9/+63V04GhnhY1DhMREZEtMLDYk5IS4IUX6h+b+WKIxmhurRZ1s2JjgfnzOURERETWwcBiT2wwW0iX5tZqAcRholWrOERERETWwcBiT3TNFpLLrTJbqDF1SU1Ghlhw29zquLwWERERWZJJgWXdunUICwuDh4cHYmNjkZWVpXffrVu3QiaTad08PDy09hEEAYsXL0ZgYCDatGmD+Ph4FBQUmNI0x6ZrttAdd1httpCu5owYAcyb1/yS/omJQNeuHCYiIiLLkBxYduzYgZSUFCxZsgQ5OTmIjIxEQkICKioq9B7j7e2N0tJSza2oqEjr+RUrVuD111/H+vXrcezYMXh5eSEhIQHXrl2TfkaOTt21sWqV+PjECeCLL2yeAowpyFUPEzG4EBGR2QkSDR48WJg1a5bmsVKpFIKCgoS0tDSd+2/ZskXw8fHR+3oqlUoICAgQVq5cqdlWWVkpuLu7Cx988IFRbaqqqhIACFVVVcadhCNQKgXBz08QxBwgCHK5IPz3v7ZulXD+vCDMmycICkV90/TdZDJx3/Pnbd1qIiKyR1K+vyX1sNTV1SE7Oxvx8fGabXK5HPHx8cjMzNR7XE1NDUJDQxESEoJx48bh9OnTmufOnTuHsrIyrdf08fFBbGys3te8fv06qqurtW5O58IF4Pff6x/bYMaQLsHBYk1LYaFYt2JMj0toKBeeIyKilpEUWC5dugSlUgl/f3+t7f7+/igrK9N5TK9evbB582Z88skn2LZtG1QqFYYMGYKSv7651MdJec20tDT4+PhobiEhIVJOwzEUFIjf+A3ZYMaQPs1di6ghlap+4TkOFxERkSksPksoLi4OSUlJiIqKwvDhw7Fr1y506tQJGzZsMPk1U1NTUVVVpbmdP3/ejC22Eza8vpAUyclAUZFYmNtccAFY50JERKaRFFj8/PygUChQXl6utb28vBwBAQFGvYarqysGDhyIM3/1FKiPk/Ka7u7u8Pb21ro5HfWMoYYp4PHHbdceA9TDRAwuRERkKZICi5ubG6Kjo5Genq7ZplKpkJ6ejri4OKNeQ6lU4tSpUwgMDAQAdOvWDQEBAVqvWV1djWPHjhn9mk4rORn49VegXTvx8Zo1dr1SW+PgYmjhOTVddS7Hj7PehYiItMkEoXGhhGE7duzAlClTsGHDBgwePBhr1qzBzp078fPPP8Pf3x9JSUno0qUL0tLSAADLli3DbbfdhltuuQWVlZVYuXIlPv74Y2RnZ6PvX9fNefnll7F8+XK888476NatGxYtWoSTJ0/ip59+arJmiy7V1dXw8fFBVVWV8/W2lJSI3RANPyaFQqx6tdH6LMYqKRFLbk6cABYsaLqIb3NkMmDuXODJJ+3+VImIHF5JiVg+2bYtUFMjViYATbeZ8/exlO9vF6kvnpiYiIsXL2Lx4sUoKytDVFQU9u7dqymaLS4uhrzBmMAff/yBGTNmoKysDO3bt0d0dDSOHDmiCSsA8PTTT6O2thYzZ85EZWUlbr/9duzdu9eosOL0DBXf2vm3eHBw/eJzDzwAvPYasHq18cFF3fvyyisMLkTk2NRhQFcIaHzf0n1MOX7nzqa/n2Uy8b7hV5BcLlYrJCdb7s9KH8k9LPbI6XtYQkO1/xY5SA+LLiUl0oOLmlwOLF8ODBpkubRPRK2PucKEvucahgFdIaCxlu5jzPEtYc6vICnf3wwsjmDTJvGCPepv+DVrxO4GB6YOLq++KnYYmYrDRkTOyZjhCXP0SJg7TMhklgsK9iQjQ+w9bykGFmd0/jxw553A2bPA9OnAkiVO8Q3dsM5l4ULTwwt7X4hso3GwsObwhDHPSdmHjMMelhZoFYEFAB56CNiyRfzZlgOJFqIOL15eun9hSaXufZkwgQGGCDB/r0V2dvMF9QwKjksmE2+NKxI2bDDfVw8DizNysloWY5hr2EiNvTDkKByl14Kk0xUCzL2PqcfL5UBKivifvNra+nVK1f+RVG+z1SwhBhZHkZEhrm2va7s5BhLtmLmGjXTR1QsD1BfgMcyQscxVuGnOXovWUk9hLpYMCuowoC4/bBgCGt/rCgpS9jH1eHOHEWMwsDgjXT0scrm4Slsr+lZtPGxkrt4XtYZfBI3DDHtlHJcxYcKeCjepKUv0KKiZK0w09xx/bzTFwOKsNm0Sr9is/obu0QPYuLFVf4NasvdFH11DS9ZcaMmZ6RsKsUaYYK+FZVhyeMKcPRL8N2obDCzOrKQEOHwY+Pe/639rOmEBriks3ftiDF1feoaGnSy1cJSlp4Jaoh2G1udhmLCMlvZaKBRAWhoQE2P+4Q2GiNaBgcXZlZQAISHa25y8ANcUDQNMba11e2EMscbCUcbsYy/tIOnsqdeCv3KoJSy6ND/ZgYKCptscZLl+a1JfGkBNfYkAQ70w1vhiNea1rbGPvbTD2bS0nsIWvRaGfm3wVwrZCwYWRxQeLv5XqfF/nby8bNcmB9EwxMTEiEV2jX+hA+adTk32w1EKN40NCcbsx8BBzoJDQo6qcQEuwFoWM2s8pGTM0JIxX3oknTXCBAs3iayPNSytxfHjwODB2ttYy2IV+sJM4y80fcNOll44yph97LEdjWssGCaInBtrWFqLmpqm21jLYhWN62N0PQ8YHnay5MJRllxcypLtaC5YcAiEqPViD4sj07eY3NGj4jclERGRHZPy/S23UpvIEoKDxZoVhaJ+m0oF3HabWONCRETkJBhYHF1yMpCZWT8fFxBDy8MPiz0wREREToCBxRnU1DRd6EJdy0JEROQEGFicgXpdloYUivpqRiIiIgfHwOIMdNWyjBhhs+YQERGZGwOLs0hOFtdfGTlSfJyeLs4gYvEtERE5AQYWZ5ORUf8zi2+JiMhJMLA4k4KCpkuJsviWiIicAAOLM9FVfAsAFRXsZSEiIofGwOJMdBXfAkBiIutZiIjIoTGwOBt18e3OndrbWc9CREQOjIHFGQUHA35+TbcrleKquERERA6GgcVZ6atneeABDg0REZHDYWBxVup6lsahhUNDRETkgBhYnFlyMvDBB023c6ozERE5GAYWZzdkSNNeFrkc8PKyTXuIiIhMwMDi7HRNdVapgNtuYy0LERE5DAaW1iA5WZwdJJPVb2MtCxERORAGltaipgYQBO1tnOZMREQOgoGlteA0ZyIicmAmBZZ169YhLCwMHh4eiI2NRVZWllHHbd++HTKZDPfee6/W9pqaGsyePRvBwcFo06YN+vbti/Xr15vSNNKH05yJiMiBSQ4sO3bsQEpKCpYsWYKcnBxERkYiISEBFRUVBo8rLCzEvHnzcMcddzR5LiUlBXv37sW2bduQl5eHOXPmYPbs2dizZ4/U5pEhhqY5f/ghQwsREdktyYFl9erVmDFjBqZNm6bpCfH09MTmzZv1HqNUKjFp0iQsXboU3bt3b/L8kSNHMGXKFIwYMQJhYWGYOXMmIiMjje65IQl0TXMGgJQUXiCRiIjslqTAUldXh+zsbMTHx9e/gFyO+Ph4ZBoo3ly2bBk6d+6M5ORknc8PGTIEe/bswW+//QZBEJCRkYFffvkFd999t879r1+/jurqaq0bGUnfFZ0BDg8REZHdkhRYLl26BKVSCX9/f63t/v7+KCsr03nM4cOHsWnTJmzcuFHv665duxZ9+/ZFcHAw3NzcMGrUKKxbtw7Dhg3TuX9aWhp8fHw0t5CQECmnQeorOq9e3fQ5zhwiIiI7ZNFZQleuXMHkyZOxceNG+Om6evBf1q5di6NHj2LPnj3Izs7GK6+8glmzZuGbb77RuX9qaiqqqqo0t/Pnz1vqFJxXcDBw//2cOURERA7BRcrOfn5+UCgUKC8v19peXl6OgICAJvufPXsWhYWFGDNmjGabSqUS39jFBfn5+QgKCsIzzzyD3bt3Y/To0QCAAQMGIDc3F6tWrdIaflJzd3eHu7u7lKaTLurhoZkzxeEgNfXQUEKCuA8REZGNSephcXNzQ3R0NNLT0zXbVCoV0tPTERcX12T/3r1749SpU8jNzdXcxo4dizvvvBO5ubkICQnBjRs3cOPGDcgb/U9foVBowg1ZkKGZQxwaIiIiOyGphwUQpyBPmTIFgwYNwuDBg7FmzRrU1tZi2rRpAICkpCR06dIFaWlp8PDwQP/+/bWO9/X1BQDNdjc3NwwfPhzz589HmzZtEBoaioMHD+Ldd9/Fal01FmR+6plDjQPiAw8A1dViqCEiIrIhyYElMTERFy9exOLFi1FWVoaoqCjs3btXU4hbXFzcpLekOdu3b0dqaiomTZqEy5cvIzQ0FC+++CIeeeQRqc0jU3BoiIiI7JxMEBpfYMbxVFdXw8fHB1VVVfD29rZ1cxzXzp1AYqLu7fffb/32EBGRU5Py/c1rCVE9fYvKcdYQERHZGAML1TN0vaGZM8WeFi4qR0RENsDAQtr0zRpSqcThIi7fT0RENsDAQk3pGxoCuHw/ERHZBAMLNWXoekMA12ghIiKrY2Ah3dTXG9q5k4W4RERkcwwspJ/6ekOGCnGPH7dN24iIqFVhYKHmGSrEve029rQQEZHFMbCQcfQV4rIIl4iIrICBhYyjb40WQCzC/fBDhhYiIrIYBhYyXnIycPSo7tCSksI1WoiIyGIYWEiamBj9U55ZiEtERBbCwELSqac8r17d9DkW4hIRkQUwsJBp1FOe9RXisqeFiIjMiIGFTGeoEJc9LUREZEYMLNQyhgpx2dNCRERmwsBCLacuxGVPCxERWQgDC5mHMT0tO3dyrRYiIjIJAwuZT3M9LYmJXKuFiIhMwsBC5mWopwVgXQsREZmEgYXMz9DicoAYWmJjgfnzOURERERGYWAhy1AvLrdzp+7eFkEAVq3iEBERERmFgYUsR724nL66FoBDREREZBQGFrI8Y+paOPWZiIgMYGAh6zA0gwjg1GciIjKIgYWsJzkZKCoC5s3j1GciIpKEgYWsKzgYWLmSU5+JiEgSBhayDU59JiIiCRhYyHY49ZmIiIzEwEK2xanPRERkBAYWsg/GTn1euRLIyOAwERFRK8PAQvbDmKnPTz8N3HUXh4mIiFoZBhayL81NfVbjMBERUavCwEL2x5ipzwBnEhERtSIMLGS/mpv6DGjPJGJ9CxGR0zIpsKxbtw5hYWHw8PBAbGwssrKyjDpu+/btkMlkuPfee5s8l5eXh7Fjx8LHxwdeXl6IiYlBcXGxKc0jZ6Ke+pyRIQYS1rcQEbVKkgPLjh07kJKSgiVLliAnJweRkZFISEhARUWFweMKCwsxb9483HHHHU2eO3v2LG6//Xb07t0bBw4cwMmTJ7Fo0SJ4eHhIbR45o+BgYMQIsa6luWEigPUtREROSCYIgiDlgNjYWMTExOCNN94AAKhUKoSEhODxxx/HwoULdR6jVCoxbNgwPPTQQzh06BAqKyvx8ccfa55/4IEH4Orqiv/7v/8z6SSqq6vh4+ODqqoqeHt7m/Qa5EA2bRIDiUpleD+5XBxSSk62TruIiEgSKd/fknpY6urqkJ2djfj4+PoXkMsRHx+PzMxMvcctW7YMnTt3RrKOLw6VSoXPP/8cPXv2REJCAjp37ozY2FitQNPY9evXUV1drXWjVqThTCJD9S3saSEichqSAsulS5egVCrh7++vtd3f3x9lZWU6jzl8+DA2bdqEjRs36ny+oqICNTU1WL58OUaNGoWvv/4a48ePx3333YeDBw/qPCYtLQ0+Pj6aW0hIiJTTIGegnknUXH0LZxIRETkFi84SunLlCiZPnoyNGzfCz89P5z6qv7r1x40bh6eeegpRUVFYuHAh/vGPf2D9+vU6j0lNTUVVVZXmdv78eYudA9k5Y+pbOJOIiMjhuUjZ2c/PDwqFAuXl5Vrby8vLERAQ0GT/s2fPorCwEGPGjNFsUwcUFxcX5OfnIyQkBC4uLujbt6/WsX369MHhw4d1tsPd3R3u7u5Smk6tgXoatL76FvVMIgCQyYC5c4EnnxRDDxER2TVJPSxubm6Ijo5Genq6ZptKpUJ6ejri4uKa7N+7d2+cOnUKubm5mtvYsWNx5513Ijc3FyEhIXBzc0NMTAzy8/O1jv3ll18QGhpq4mlRq9XcNYnUeCVoIiKHIqmHBQBSUlIwZcoUDBo0CIMHD8aaNWtQW1uLadOmAQCSkpLQpUsXpKWlwcPDA/3799c63tfXFwC0ts+fPx+JiYkYNmwY7rzzTuzduxeffvopDhw4YPqZUevVXE9LQ+rC3AEDxOOIiMguSa5hSUxMxKpVq7B48WJERUUhNzcXe/fu1RTiFhcXo7S0VNJrjh8/HuvXr8eKFSsQERGB//73v/joo49w++23S20ekcjYmUSAGFoGD2ZhLhGRHZO8Dos94josZFBJCXDmDHDiBLBggeFeF7kcWL4cGDQICA9nfQsRkQVJ+f5mYKHWpaQEeO01YPXq5oeLWJhLRGRRFls4jsjhGXslaKC+MLdrVw4XERHZGAMLtU7qwtzmQgvA4EJEZAcYWKj1klKYC3ABOiIiG2INCxEgrTC3Ida5EBGZjDUsRFI1XOJf3evC4SIiIrvBwELUmLow15TgwuEiIiKLYGAh0qdxcDGmzkV9vaK77mKvCxGRGTGwEDVHHVwKC8Wek5UrOVxERGRlLLolMoWUBejUGhboAkBBAVfTJaJWjSvdElmLOri8+iqgVBp/nEwm9sBwlhERtWKcJURkLS0ZLlLfc9iIiKhZ7GEhMjdThovUOGxERK0Ih4SI7EFLggvAYSMicnocEiKyB/qmRctk4q05+oaNjh/nOi9E1Oqwh4XIWtTL/99yi/i4Jb0vgFgrs3w5MGgQh42IyCFxSIjIUbR02EhNPWw0YQJQU8MAQ0QOgYGFyNE0nh6tHjIy9Z8ni3eJyAEwsBA5KnMPGzUMPizeJSI7w8BC5ExMXZxOHwYXIrITDCxEzkjd++LlBdTWAidOAAsWmKdot21b1r4QkdUxsBC1FpbqfWHxLhFZAQMLUWvTsPdl507zFe+yF4aILIiBhai1M3fxbkPshSEiM2FgIaKmzD18pMYF7IjIRAwsRKSfuvflxAlg4ULzhpfGvS8cRiIiAxhYiMg4+mpfzI29MESkAwMLEZlG19RpS/fCMMAQtVoMLERkPpbuhdE1E4lDSUStAgMLEVmOuRewM4TXRCJyagwsRGRdlpqBpKbrmkgcUiJyeAwsRGQbjXtfbNULwyElIofAwEJE9sfSvTCAGF4a/kpjbwyRXWNgISL7ZY2ZSPqwwJfIrjCwEJFj0TWUZM5rIhmDYYbI6qR8f8tNeYN169YhLCwMHh4eiI2NRVZWllHHbd++HTKZDPfee6/efR555BHIZDKsWbPGlKYRkSMKDgZGjABiYurvV64ECguBjAyguFi8zZsHKBSWaYNKBTz9NHDXXcDgwdr3XbsC8+eLwaqkRGzT8ePifUmJZdpDRFpcpB6wY8cOpKSkYP369YiNjcWaNWuQkJCA/Px8dO7cWe9xhYWFmDdvHu644w69++zevRtHjx5FUFCQ1GYRkTMKDtbu2Vi5Uiyu1XdlapnMMoW9ggCsWgW88kr9YzXWyRBZheQhodjYWMTExOCNN94AAKhUKoSEhODxxx/HwoULdR6jVCoxbNgwPPTQQzh06BAqKyvx8ccfa+3z22+/ITY2Fl999RVGjx6NOXPmYM6cOUa1iUNCRK1Y4ytTW+NSA4ZwaInIaFK+vyX1sNTV1SE7OxupqamabXK5HPHx8cjMzNR73LJly9C5c2ckJyfj0KFDTZ5XqVSYPHky5s+fj379+jXbjuvXr+P69euax9XV1VJOg4icSeNeGPXPMTHavTHWKvBVDy3pwinYRCaTFFguXboEpVIJf39/re3+/v74+eefdR5z+PBhbNq0Cbm5uXpf9+WXX4aLiwueeOIJo9qRlpaGpUuXGt1uImqlGoeZESOABx7Qv1aMpcOMemhp1Sr9U7C5qi+RTpJrWKS4cuUKJk+ejI0bN8LPz0/nPtnZ2XjttdeQk5MDmXomQDNSU1ORkpKieVxdXY2QkBCztJmInFzjEKOmL8xYqk6m8Wi8rjqZxvUxDXtjAIYaalUk1bDU1dXB09MT//vf/7Rm+kyZMgWVlZX45JNPtPbPzc3FwIEDoWhQ1a/66x+6XC5Hfn4+Pv30U6SkpEAur5+wpFQqIZfLERISgsLCwmbbxRoWIrIoe6uTMXSpAg4xkQOx6DossbGxGDx4MNauXQtADCBdu3bF7NmzmxTdXrt2DWfOnNHa9txzz+HKlSt47bXX0LNnT1y5cgWlpaVa+yQkJGDy5MmYNm0aevXq1WybGFiIyGZsuRCeISz+JQdgsaJbAEhJScGUKVMwaNAgDB48GGvWrEFtbS2mTZsGAEhKSkKXLl2QlpYGDw8P9O/fX+t4X19fANBs79ixIzp27Ki1j6urKwICAowKK0RENmVsnYy1pmCrsfiXnIzkwJKYmIiLFy9i8eLFKCsrQ1RUFPbu3aspxC0uLtYa3iEianV01ck0nLVkaGjJGqv6GrOujK4ww1BDNsSl+YmI7EHjOhlDF4q0RqhRv4+u92APDZkJryVEROQMdF1jqbbWuFBjLcZcIRtgqCGdGFiIiFoLfaHGXop/dfUGGQo1DDOtCgMLEREZdxVsSxf/GsPYadoAQ42TYWAhIiL9jFlXxl7CjJqhUKNr2InDTw6BgYWIiEyjL8w4Sg+Nruc468luMbAQEZHlSFn5l6GGDGBgISIi22hcN2NsqAEsP027OaaGmoZhpqSEdTYSMLAQEZH90hdq7GHtmeYYmvXk7w8sWCD2JvEaT0ZhYCEiIsdkytoz9jLsZAxD13hqhaGGgYWIiJxXc8NO9lwgbIxWFGoYWIiIiADHnPVkjOauxg04xOrCDCxERETGcrZQI3V1YRuGGgYWIiIiczJmKrdCAaSlARUVtr/GU3PsJNQwsBAREVlLwzDTcHqzPV/jyRi6Qo1cDrz9NpCcbJa3YGAhIiKyV/rCjKOEGoUCKCw0S0+LlO9vlxa/GxERERkvONjwl/2IEcADD5geaixdZ6NUim2zcr0LAwsREZG9aUmosfQlExSK+vewIgYWIiIiR9RcqFE/FxMjXlLAlEsmNA41CgWwYYNNpkizhoWIiIiMW5CvYWGxGbCGhYiIiKTR12NjJwvOyW3dACIiIqLmMLAQERGR3WNgISIiIrvHwEJERER2j4GFiIiI7B4DCxEREdk9BhYiIiKyewwsREREZPcYWIiIiMjuMbAQERGR3WNgISIiIrvnFNcSUl+/sbq62sYtISIiImOpv7eNuQ6zUwSWK1euAABCQkJs3BIiIiKS6sqVK/Dx8TG4j0wwJtbYOZVKhQsXLqBdu3aQyWRmfe3q6mqEhITg/PnzzV762lE5+zk6+/kBPEdn4OznB/AcnYG5z08QBFy5cgVBQUGQyw1XqThFD4tcLkewhS9/7e3t7ZR/+Rpy9nN09vMDeI7OwNnPD+A5OgNznl9zPStqLLolIiIiu8fAQkRERHaPgaUZ7u7uWLJkCdzd3W3dFItx9nN09vMDeI7OwNnPD+A5OgNbnp9TFN0SERGRc2MPCxEREdk9BhYiIiKyewwsREREZPcYWIiIiMjuMbA0Y926dQgLC4OHhwdiY2ORlZVl6yaZJC0tDTExMWjXrh06d+6Me++9F/n5+Vr7jBgxAjKZTOv2yCOP2KjF0j3//PNN2t+7d2/N89euXcOsWbPQsWNHtG3bFv/85z9RXl5uwxZLExYW1uT8ZDIZZs2aBcAxP79vv/0WY8aMQVBQEGQyGT7++GOt5wVBwOLFixEYGIg2bdogPj4eBQUFWvtcvnwZkyZNgre3N3x9fZGcnIyamhornoVhhs7xxo0bWLBgASIiIuDl5YWgoCAkJSXhwoULWq+h67Nfvny5lc9Et+Y+w6lTpzZp+6hRo7T2ceTPEIDOf5cymQwrV67U7GPPn6Ex3w/G/P4sLi7G6NGj4enpic6dO2P+/Pm4efOm2drJwGLAjh07kJKSgiVLliAnJweRkZFISEhARUWFrZsm2cGDBzFr1iwcPXoU+/btw40bN3D33XejtrZWa78ZM2agtLRUc1uxYoWNWmyafv36abX/8OHDmueeeuopfPrpp/jwww9x8OBBXLhwAffdd58NWyvN8ePHtc5t3759AID7779fs4+jfX61tbWIjIzEunXrdD6/YsUKvP7661i/fj2OHTsGLy8vJCQk4Nq1a5p9Jk2ahNOnT2Pfvn347LPP8O2332LmzJnWOoVmGTrHq1evIicnB4sWLUJOTg527dqF/Px8jB07tsm+y5Yt0/psH3/8cWs0v1nNfYYAMGrUKK22f/DBB1rPO/JnCEDr3EpLS7F582bIZDL885//1NrPXj9DY74fmvv9qVQqMXr0aNTV1eHIkSN45513sHXrVixevNh8DRVIr8GDBwuzZs3SPFYqlUJQUJCQlpZmw1aZR0VFhQBAOHjwoGbb8OHDhSeffNJ2jWqhJUuWCJGRkTqfq6ysFFxdXYUPP/xQsy0vL08AIGRmZlqpheb15JNPCj169BBUKpUgCI7/+QEQdu/erXmsUqmEgIAAYeXKlZptlZWVgru7u/DBBx8IgiAIP/30kwBAOH78uGafL7/8UpDJZMJvv/1mtbYbq/E56pKVlSUAEIqKijTbQkNDhVdffdWyjTMDXec3ZcoUYdy4cXqPccbPcNy4ccJdd92ltc1RPkNBaPr9YMzvzy+++EKQy+VCWVmZZp+33npL8Pb2Fq5fv26WdrGHRY+6ujpkZ2cjPj5es00ulyM+Ph6ZmZk2bJl5VFVVAQA6dOigtf29996Dn58f+vfvj9TUVFy9etUWzTNZQUEBgoKC0L17d0yaNAnFxcUAgOzsbNy4cUPr8+zduze6du3qkJ9nXV0dtm3bhoceekjrgp+O/vk1dO7cOZSVlWl9Zj4+PoiNjdV8ZpmZmfD19cWgQYM0+8THx0Mul+PYsWNWb7M5VFVVQSaTwdfXV2v78uXL0bFjRwwcOBArV640a1e7pR04cACdO3dGr1698Oijj+L333/XPOdsn2F5eTk+//xzJCcnN3nOUT7Dxt8Pxvz+zMzMREREBPz9/TX7JCQkoLq6GqdPnzZLu5zi4oeWcOnSJSiVSq0/fADw9/fHzz//bKNWmYdKpcKcOXMwdOhQ9O/fX7P93//+N0JDQxEUFISTJ09iwYIFyM/Px65du2zYWuPFxsZi69at6NWrF0pLS7F06VLccccd+PHHH1FWVgY3N7cmXwL+/v4oKyuzTYNb4OOPP0ZlZSWmTp2q2ebon19j6s9F179B9XNlZWXo3Lmz1vMuLi7o0KGDQ36u165dw4IFCzBx4kStC8s98cQTuPXWW9GhQwccOXIEqampKC0txerVq23YWuOMGjUK9913H7p164azZ8/imWeewT333IPMzEwoFAqn+wzfeecdtGvXrslws6N8hrq+H4z5/VlWVqbz36r6OXNgYGmFZs2ahR9//FGrvgOA1phxREQEAgMDMXLkSJw9exY9evSwdjMlu+eeezQ/DxgwALGxsQgNDcXOnTvRpk0bG7bM/DZt2oR77rkHQUFBmm2O/vm1djdu3MCECRMgCALeeustredSUlI0Pw8YMABubm54+OGHkZaWZvdLwD/wwAOanyMiIjBgwAD06NEDBw4cwMiRI23YMsvYvHkzJk2aBA8PD63tjvIZ6vt+sAccEtLDz88PCoWiSRV0eXk5AgICbNSqlps9ezY+++wzZGRkIDg42OC+sbGxAIAzZ85Yo2lm5+vri549e+LMmTMICAhAXV0dKisrtfZxxM+zqKgI33zzDaZPn25wP0f//NSfi6F/gwEBAU2K4G/evInLly871OeqDitFRUXYt2+fVu+KLrGxsbh58yYKCwut00Az6t69O/z8/DR/L53lMwSAQ4cOIT8/v9l/m4B9fob6vh+M+f0ZEBCg89+q+jlzYGDRw83NDdHR0UhPT9dsU6lUSE9PR1xcnA1bZhpBEDB79mzs3r0b+/fvR7du3Zo9Jjc3FwAQGBho4dZZRk1NDc6ePYvAwEBER0fD1dVV6/PMz89HcXGxw32eW7ZsQefOnTF69GiD+zn659etWzcEBARofWbV1dU4duyY5jOLi4tDZWUlsrOzNfvs378fKpVKE9jsnTqsFBQU4JtvvkHHjh2bPSY3NxdyubzJUIojKCkpwe+//675e+kMn6Hapk2bEB0djcjIyGb3tafPsLnvB2N+f8bFxeHUqVNa4VMdvvv27Wu2hpIe27dvF9zd3YWtW7cKP/30kzBz5kzB19dXqwraUTz66KOCj4+PcODAAaG0tFRzu3r1qiAIgnDmzBlh2bJlwokTJ4Rz584Jn3zyidC9e3dh2LBhNm658ebOnSscOHBAOHfunPDdd98J8fHxgp+fn1BRUSEIgiA88sgjQteuXYX9+/cLJ06cEOLi4oS4uDgbt1oapVIpdO3aVViwYIHWdkf9/K5cuSJ8//33wvfffy8AEFavXi18//33mhkyy5cvF3x9fYVPPvlEOHnypDBu3DihW7duwp9//ql5jVGjRgkDBw4Ujh07Jhw+fFgIDw8XJk6caKtTasLQOdbV1Qljx44VgoODhdzcXK1/m+qZFUeOHBFeffVVITc3Vzh79qywbds2oVOnTkJSUpKNz0xk6PyuXLkizJs3T8jMzBTOnTsnfPPNN8Ktt94qhIeHC9euXdO8hiN/hmpVVVWCp6en8NZbbzU53t4/w+a+HwSh+d+fN2/eFPr37y/cfffdQm5urrB3716hU6dOQmpqqtnaycDSjLVr1wpdu3YV3NzchMGDBwtHjx61dZNMAkDnbcuWLYIgCEJxcbEwbNgwoUOHDoK7u7twyy23CPPnzxeqqqps23AJEhMThcDAQMHNzU3o0qWLkJiYKJw5c0bz/J9//ik89thjQvv27QVPT09h/PjxQmlpqQ1bLN1XX30lABDy8/O1tjvq55eRkaHz7+WUKVMEQRCnNi9atEjw9/cX3N3dhZEjRzY5999//12YOHGi0LZtW8Hb21uYNm2acOXKFRucjW6GzvHcuXN6/21mZGQIgiAI2dnZQmxsrODj4yN4eHgIffr0EV566SWtL3xbMnR+V69eFe6++26hU6dOgqurqxAaGirMmDGjyX/6HPkzVNuwYYPQpk0bobKyssnx9v4ZNvf9IAjG/f4sLCwU7rnnHqFNmzaCn5+fMHfuXOHGjRtma6fsr8YSERER2S3WsBAREZHdY2AhIiIiu8fAQkRERHaPgYWIiIjsHgMLERER2T0GFiIiIrJ7DCxERERk9xhYiIiIyO4xsBAREZHdY2AhIiIiu8fAQkRERHaPgYWIiIjs3v8D+2JzX7inaSMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "superb-circus",
      "metadata": {
        "id": "superb-circus"
      },
      "source": [
        "What is your interpretation about the result of the train and validation loss?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "german-cherry",
      "metadata": {
        "id": "german-cherry"
      },
      "source": [
        "#Answer:\n",
        "Upon observing the results, it's evident that the validation loss has stabilized around 0.50. This suggests that the model has reached a point where further improvement on unseen data is limited. It could indicate that the model has maximized its ability to learn from the available data or may be beginning to overfit. The continued decrease in training loss alongside the stabilization of the validation loss implies that the model has effectively learned the patterns present in the training data which is also an indication of overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "involved-slovak",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-publisher",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epochs and network structures\n",
        "* Interpret your result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)\n",
        "\n",
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)\n",
        "\n",
        "model  = Sequential([\n",
        "    Dense(6, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(6, activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_2 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-bo2Xp6-app",
        "outputId": "3b674916-b560-4523-fcbb-6b299cd9bf05"
      },
      "id": "L-bo2Xp6-app",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 1s 12ms/step - loss: 0.6862 - accuracy: 0.5990 - val_loss: 0.6961 - val_accuracy: 0.5312\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6808 - accuracy: 0.6146 - val_loss: 0.6910 - val_accuracy: 0.5625\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6756 - accuracy: 0.6233 - val_loss: 0.6860 - val_accuracy: 0.5938\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.6354 - val_loss: 0.6811 - val_accuracy: 0.6146\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6657 - accuracy: 0.6476 - val_loss: 0.6763 - val_accuracy: 0.6302\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6608 - accuracy: 0.6528 - val_loss: 0.6715 - val_accuracy: 0.6354\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.6597 - val_loss: 0.6667 - val_accuracy: 0.6302\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.6562 - val_loss: 0.6620 - val_accuracy: 0.6354\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.6580 - val_loss: 0.6575 - val_accuracy: 0.6302\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.6597 - val_loss: 0.6530 - val_accuracy: 0.6302\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6375 - accuracy: 0.6649 - val_loss: 0.6487 - val_accuracy: 0.6354\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6328 - accuracy: 0.6667 - val_loss: 0.6444 - val_accuracy: 0.6406\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.6649 - val_loss: 0.6400 - val_accuracy: 0.6406\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6233 - accuracy: 0.6632 - val_loss: 0.6359 - val_accuracy: 0.6406\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6189 - accuracy: 0.6632 - val_loss: 0.6318 - val_accuracy: 0.6406\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.6667 - val_loss: 0.6279 - val_accuracy: 0.6406\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.6632 - val_loss: 0.6243 - val_accuracy: 0.6406\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.6649 - val_loss: 0.6207 - val_accuracy: 0.6354\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6027 - accuracy: 0.6649 - val_loss: 0.6175 - val_accuracy: 0.6354\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5991 - accuracy: 0.6667 - val_loss: 0.6144 - val_accuracy: 0.6458\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.6649 - val_loss: 0.6115 - val_accuracy: 0.6458\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5922 - accuracy: 0.6649 - val_loss: 0.6089 - val_accuracy: 0.6458\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.6667 - val_loss: 0.6064 - val_accuracy: 0.6458\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5859 - accuracy: 0.6667 - val_loss: 0.6040 - val_accuracy: 0.6458\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.6667 - val_loss: 0.6017 - val_accuracy: 0.6458\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.6684 - val_loss: 0.5995 - val_accuracy: 0.6406\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.6684 - val_loss: 0.5973 - val_accuracy: 0.6406\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5748 - accuracy: 0.6667 - val_loss: 0.5952 - val_accuracy: 0.6458\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.6649 - val_loss: 0.5932 - val_accuracy: 0.6458\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.6667 - val_loss: 0.5913 - val_accuracy: 0.6458\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.6719 - val_loss: 0.5894 - val_accuracy: 0.6510\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.6753 - val_loss: 0.5877 - val_accuracy: 0.6510\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5635 - accuracy: 0.6753 - val_loss: 0.5861 - val_accuracy: 0.6510\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5615 - accuracy: 0.6788 - val_loss: 0.5846 - val_accuracy: 0.6510\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.6736 - val_loss: 0.5831 - val_accuracy: 0.6562\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.6719 - val_loss: 0.5816 - val_accuracy: 0.6562\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.6719 - val_loss: 0.5802 - val_accuracy: 0.6562\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.6736 - val_loss: 0.5788 - val_accuracy: 0.6562\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5524 - accuracy: 0.6736 - val_loss: 0.5774 - val_accuracy: 0.6562\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.6753 - val_loss: 0.5760 - val_accuracy: 0.6615\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.6806 - val_loss: 0.5747 - val_accuracy: 0.6667\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.6858 - val_loss: 0.5734 - val_accuracy: 0.6615\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5458 - accuracy: 0.6840 - val_loss: 0.5721 - val_accuracy: 0.6615\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.6840 - val_loss: 0.5708 - val_accuracy: 0.6562\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.6892 - val_loss: 0.5695 - val_accuracy: 0.6562\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5408 - accuracy: 0.6962 - val_loss: 0.5683 - val_accuracy: 0.6615\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5391 - accuracy: 0.6979 - val_loss: 0.5671 - val_accuracy: 0.6615\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.6979 - val_loss: 0.5660 - val_accuracy: 0.6615\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.6997 - val_loss: 0.5649 - val_accuracy: 0.6667\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.6979 - val_loss: 0.5638 - val_accuracy: 0.6667\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7014 - val_loss: 0.5627 - val_accuracy: 0.6667\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7014 - val_loss: 0.5617 - val_accuracy: 0.6823\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7066 - val_loss: 0.5606 - val_accuracy: 0.6875\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7049 - val_loss: 0.5596 - val_accuracy: 0.6823\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.6979 - val_loss: 0.5587 - val_accuracy: 0.6823\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5255 - accuracy: 0.7049 - val_loss: 0.5577 - val_accuracy: 0.6823\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5242 - accuracy: 0.7083 - val_loss: 0.5568 - val_accuracy: 0.6927\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5229 - accuracy: 0.7083 - val_loss: 0.5560 - val_accuracy: 0.6927\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7118 - val_loss: 0.5552 - val_accuracy: 0.7031\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.7188 - val_loss: 0.5544 - val_accuracy: 0.7031\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.7205 - val_loss: 0.5536 - val_accuracy: 0.7031\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7222 - val_loss: 0.5528 - val_accuracy: 0.7135\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.7188 - val_loss: 0.5519 - val_accuracy: 0.7083\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5154 - accuracy: 0.7257 - val_loss: 0.5511 - val_accuracy: 0.7083\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7309 - val_loss: 0.5504 - val_accuracy: 0.7083\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5131 - accuracy: 0.7326 - val_loss: 0.5497 - val_accuracy: 0.7083\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7309 - val_loss: 0.5491 - val_accuracy: 0.7135\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5109 - accuracy: 0.7344 - val_loss: 0.5484 - val_accuracy: 0.7188\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7292 - val_loss: 0.5477 - val_accuracy: 0.7188\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5087 - accuracy: 0.7292 - val_loss: 0.5470 - val_accuracy: 0.7240\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7326 - val_loss: 0.5464 - val_accuracy: 0.7240\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5066 - accuracy: 0.7361 - val_loss: 0.5457 - val_accuracy: 0.7240\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.7396 - val_loss: 0.5451 - val_accuracy: 0.7240\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.7413 - val_loss: 0.5444 - val_accuracy: 0.7188\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7361 - val_loss: 0.5438 - val_accuracy: 0.7188\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7361 - val_loss: 0.5432 - val_accuracy: 0.7135\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7378 - val_loss: 0.5425 - val_accuracy: 0.7135\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7378 - val_loss: 0.5419 - val_accuracy: 0.7135\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7396 - val_loss: 0.5412 - val_accuracy: 0.7135\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7361 - val_loss: 0.5406 - val_accuracy: 0.7188\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7361 - val_loss: 0.5400 - val_accuracy: 0.7188\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7378 - val_loss: 0.5394 - val_accuracy: 0.7188\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4962 - accuracy: 0.7396 - val_loss: 0.5388 - val_accuracy: 0.7188\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7396 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4946 - accuracy: 0.7396 - val_loss: 0.5376 - val_accuracy: 0.7188\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7413 - val_loss: 0.5370 - val_accuracy: 0.7188\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7483 - val_loss: 0.5364 - val_accuracy: 0.7188\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7500 - val_loss: 0.5359 - val_accuracy: 0.7240\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7500 - val_loss: 0.5353 - val_accuracy: 0.7240\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7483 - val_loss: 0.5347 - val_accuracy: 0.7240\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7535 - val_loss: 0.5341 - val_accuracy: 0.7240\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7552 - val_loss: 0.5335 - val_accuracy: 0.7240\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7587 - val_loss: 0.5329 - val_accuracy: 0.7188\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7622 - val_loss: 0.5324 - val_accuracy: 0.7188\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.7622 - val_loss: 0.5318 - val_accuracy: 0.7188\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7639 - val_loss: 0.5312 - val_accuracy: 0.7240\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7639 - val_loss: 0.5307 - val_accuracy: 0.7240\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7708 - val_loss: 0.5301 - val_accuracy: 0.7292\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7726 - val_loss: 0.5295 - val_accuracy: 0.7240\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7778 - val_loss: 0.5290 - val_accuracy: 0.7240\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7743 - val_loss: 0.5284 - val_accuracy: 0.7240\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7726 - val_loss: 0.5279 - val_accuracy: 0.7240\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7743 - val_loss: 0.5274 - val_accuracy: 0.7240\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7743 - val_loss: 0.5269 - val_accuracy: 0.7240\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7760 - val_loss: 0.5264 - val_accuracy: 0.7240\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7778 - val_loss: 0.5259 - val_accuracy: 0.7240\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7743 - val_loss: 0.5254 - val_accuracy: 0.7240\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7778 - val_loss: 0.5249 - val_accuracy: 0.7240\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7778 - val_loss: 0.5245 - val_accuracy: 0.7344\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7778 - val_loss: 0.5240 - val_accuracy: 0.7292\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7743 - val_loss: 0.5235 - val_accuracy: 0.7292\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.5231 - val_accuracy: 0.7292\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7743 - val_loss: 0.5226 - val_accuracy: 0.7292\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7743 - val_loss: 0.5222 - val_accuracy: 0.7292\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7760 - val_loss: 0.5218 - val_accuracy: 0.7292\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7760 - val_loss: 0.5214 - val_accuracy: 0.7292\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7743 - val_loss: 0.5210 - val_accuracy: 0.7292\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7743 - val_loss: 0.5207 - val_accuracy: 0.7344\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7743 - val_loss: 0.5204 - val_accuracy: 0.7344\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7743 - val_loss: 0.5200 - val_accuracy: 0.7344\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4664 - accuracy: 0.7743 - val_loss: 0.5197 - val_accuracy: 0.7344\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7743 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4650 - accuracy: 0.7743 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.7743 - val_loss: 0.5187 - val_accuracy: 0.7344\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4638 - accuracy: 0.7778 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7760 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7778 - val_loss: 0.5179 - val_accuracy: 0.7396\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4607 - accuracy: 0.7795 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7812 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4592 - accuracy: 0.7812 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.7812 - val_loss: 0.5162 - val_accuracy: 0.7552\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4582 - accuracy: 0.7812 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.7830 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7812 - val_loss: 0.5157 - val_accuracy: 0.7552\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7795 - val_loss: 0.5155 - val_accuracy: 0.7552\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.5154 - val_accuracy: 0.7500\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.7795 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.7778 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.7778 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.7795 - val_loss: 0.5150 - val_accuracy: 0.7552\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.7795 - val_loss: 0.5150 - val_accuracy: 0.7604\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 0.7812 - val_loss: 0.5149 - val_accuracy: 0.7604\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4537 - accuracy: 0.7795 - val_loss: 0.5148 - val_accuracy: 0.7604\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.7778 - val_loss: 0.5148 - val_accuracy: 0.7604\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7795 - val_loss: 0.5147 - val_accuracy: 0.7604\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4527 - accuracy: 0.7812 - val_loss: 0.5147 - val_accuracy: 0.7604\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7812 - val_loss: 0.5147 - val_accuracy: 0.7604\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7812 - val_loss: 0.5146 - val_accuracy: 0.7604\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7812 - val_loss: 0.5145 - val_accuracy: 0.7604\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7812 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7830 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7847 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7865 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7847 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7882 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7882 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7882 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7882 - val_loss: 0.5143 - val_accuracy: 0.7604\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7882 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7882 - val_loss: 0.5144 - val_accuracy: 0.7604\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7882 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7708\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7882 - val_loss: 0.5146 - val_accuracy: 0.7708\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7882 - val_loss: 0.5148 - val_accuracy: 0.7708\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7882 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7865 - val_loss: 0.5151 - val_accuracy: 0.7708\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7882 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7899 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7882 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7865 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7865 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7865 - val_loss: 0.5155 - val_accuracy: 0.7708\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7899 - val_loss: 0.5155 - val_accuracy: 0.7708\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7865 - val_loss: 0.5156 - val_accuracy: 0.7708\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7865 - val_loss: 0.5158 - val_accuracy: 0.7708\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.7865 - val_loss: 0.5159 - val_accuracy: 0.7760\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7882 - val_loss: 0.5160 - val_accuracy: 0.7760\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7899 - val_loss: 0.5161 - val_accuracy: 0.7760\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.7882 - val_loss: 0.5163 - val_accuracy: 0.7812\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7899 - val_loss: 0.5165 - val_accuracy: 0.7812\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7917 - val_loss: 0.5167 - val_accuracy: 0.7865\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7847 - val_loss: 0.5170 - val_accuracy: 0.7865\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7882 - val_loss: 0.5171 - val_accuracy: 0.7812\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7917 - val_loss: 0.5173 - val_accuracy: 0.7812\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7882 - val_loss: 0.5174 - val_accuracy: 0.7812\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7934 - val_loss: 0.5175 - val_accuracy: 0.7812\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7917 - val_loss: 0.5176 - val_accuracy: 0.7812\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7917 - val_loss: 0.5177 - val_accuracy: 0.7812\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7934 - val_loss: 0.5178 - val_accuracy: 0.7760\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7812\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7969 - val_loss: 0.5181 - val_accuracy: 0.7812\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.7969 - val_loss: 0.5183 - val_accuracy: 0.7812\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7969 - val_loss: 0.5184 - val_accuracy: 0.7812\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7969 - val_loss: 0.5186 - val_accuracy: 0.7812\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7969 - val_loss: 0.5188 - val_accuracy: 0.7812\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7969 - val_loss: 0.5188 - val_accuracy: 0.7812\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.5188 - val_accuracy: 0.7812\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5189 - val_accuracy: 0.7812\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7969 - val_loss: 0.5190 - val_accuracy: 0.7812\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5190 - val_accuracy: 0.7812\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7986 - val_loss: 0.5191 - val_accuracy: 0.7812\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.7934 - val_loss: 0.5192 - val_accuracy: 0.7812\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7934 - val_loss: 0.5192 - val_accuracy: 0.7812\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7934 - val_loss: 0.5193 - val_accuracy: 0.7812\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.5194 - val_accuracy: 0.7812\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7934 - val_loss: 0.5194 - val_accuracy: 0.7865\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7951 - val_loss: 0.5196 - val_accuracy: 0.7865\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7951 - val_loss: 0.5196 - val_accuracy: 0.7865\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7969 - val_loss: 0.5196 - val_accuracy: 0.7917\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.5197 - val_accuracy: 0.7917\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7934 - val_loss: 0.5197 - val_accuracy: 0.7917\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7951 - val_loss: 0.5198 - val_accuracy: 0.7865\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5199 - val_accuracy: 0.7865\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7969 - val_loss: 0.5199 - val_accuracy: 0.7865\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7969 - val_loss: 0.5201 - val_accuracy: 0.7812\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7951 - val_loss: 0.5201 - val_accuracy: 0.7812\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.7951 - val_loss: 0.5201 - val_accuracy: 0.7812\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7969 - val_loss: 0.5203 - val_accuracy: 0.7812\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7951 - val_loss: 0.5204 - val_accuracy: 0.7812\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7969 - val_loss: 0.5205 - val_accuracy: 0.7812\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.5205 - val_accuracy: 0.7812\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7934 - val_loss: 0.5205 - val_accuracy: 0.7812\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7934 - val_loss: 0.5206 - val_accuracy: 0.7812\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7934 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7951 - val_loss: 0.5207 - val_accuracy: 0.7760\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.7951 - val_loss: 0.5208 - val_accuracy: 0.7760\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7951 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7951 - val_loss: 0.5209 - val_accuracy: 0.7760\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7951 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7951 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4322 - accuracy: 0.7934 - val_loss: 0.5211 - val_accuracy: 0.7812\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5212 - val_accuracy: 0.7812\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7951 - val_loss: 0.5212 - val_accuracy: 0.7708\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7969 - val_loss: 0.5213 - val_accuracy: 0.7708\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.7969 - val_loss: 0.5213 - val_accuracy: 0.7708\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7969 - val_loss: 0.5214 - val_accuracy: 0.7708\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7969 - val_loss: 0.5215 - val_accuracy: 0.7708\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7969 - val_loss: 0.5216 - val_accuracy: 0.7708\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7951 - val_loss: 0.5217 - val_accuracy: 0.7708\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7969 - val_loss: 0.5218 - val_accuracy: 0.7708\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.7969 - val_loss: 0.5219 - val_accuracy: 0.7708\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7969 - val_loss: 0.5220 - val_accuracy: 0.7656\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7969 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7969 - val_loss: 0.5222 - val_accuracy: 0.7656\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7969 - val_loss: 0.5223 - val_accuracy: 0.7656\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7969 - val_loss: 0.5225 - val_accuracy: 0.7656\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7969 - val_loss: 0.5226 - val_accuracy: 0.7656\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7951 - val_loss: 0.5227 - val_accuracy: 0.7656\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7969 - val_loss: 0.5228 - val_accuracy: 0.7656\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7986 - val_loss: 0.5230 - val_accuracy: 0.7656\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7969 - val_loss: 0.5231 - val_accuracy: 0.7656\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.5232 - val_accuracy: 0.7656\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7969 - val_loss: 0.5233 - val_accuracy: 0.7656\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7969 - val_loss: 0.5234 - val_accuracy: 0.7656\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7969 - val_loss: 0.5236 - val_accuracy: 0.7656\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.7951 - val_loss: 0.5237 - val_accuracy: 0.7656\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7951 - val_loss: 0.5238 - val_accuracy: 0.7656\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7934 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.7951 - val_loss: 0.5239 - val_accuracy: 0.7656\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7951 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7951 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7934 - val_loss: 0.5240 - val_accuracy: 0.7656\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7951 - val_loss: 0.5241 - val_accuracy: 0.7656\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7951 - val_loss: 0.5242 - val_accuracy: 0.7604\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7951 - val_loss: 0.5242 - val_accuracy: 0.7604\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7934 - val_loss: 0.5242 - val_accuracy: 0.7604\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7951 - val_loss: 0.5242 - val_accuracy: 0.7604\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.7934 - val_loss: 0.5241 - val_accuracy: 0.7604\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7934 - val_loss: 0.5242 - val_accuracy: 0.7604\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7951 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.7951 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4270 - accuracy: 0.7934 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.7951 - val_loss: 0.5243 - val_accuracy: 0.7604\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.7951 - val_loss: 0.5244 - val_accuracy: 0.7604\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.7986 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4266 - accuracy: 0.7934 - val_loss: 0.5244 - val_accuracy: 0.7604\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4265 - accuracy: 0.7969 - val_loss: 0.5244 - val_accuracy: 0.7604\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7969 - val_loss: 0.5245 - val_accuracy: 0.7604\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4263 - accuracy: 0.7969 - val_loss: 0.5246 - val_accuracy: 0.7708\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.5247 - val_accuracy: 0.7708\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.8003 - val_loss: 0.5247 - val_accuracy: 0.7708\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4260 - accuracy: 0.7969 - val_loss: 0.5248 - val_accuracy: 0.7708\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.7986 - val_loss: 0.5249 - val_accuracy: 0.7708\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5250 - val_accuracy: 0.7708\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.7951 - val_loss: 0.5249 - val_accuracy: 0.7708\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.7986 - val_loss: 0.5250 - val_accuracy: 0.7708\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4251 - accuracy: 0.7951 - val_loss: 0.5250 - val_accuracy: 0.7708\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7934 - val_loss: 0.5249 - val_accuracy: 0.7656\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.5249 - val_accuracy: 0.7656\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4248 - accuracy: 0.7986 - val_loss: 0.5250 - val_accuracy: 0.7656\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4246 - accuracy: 0.7969 - val_loss: 0.5251 - val_accuracy: 0.7656\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.7951 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4245 - accuracy: 0.7951 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4243 - accuracy: 0.7969 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.7951 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7969 - val_loss: 0.5252 - val_accuracy: 0.7656\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.7969 - val_loss: 0.5253 - val_accuracy: 0.7656\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.7969 - val_loss: 0.5253 - val_accuracy: 0.7656\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4239 - accuracy: 0.7969 - val_loss: 0.5254 - val_accuracy: 0.7656\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.7969 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4235 - accuracy: 0.7969 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.7951 - val_loss: 0.5256 - val_accuracy: 0.7656\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.7969 - val_loss: 0.5256 - val_accuracy: 0.7656\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.5257 - val_accuracy: 0.7656\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.7969 - val_loss: 0.5257 - val_accuracy: 0.7656\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.5258 - val_accuracy: 0.7656\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.7951 - val_loss: 0.5257 - val_accuracy: 0.7656\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7986 - val_loss: 0.5258 - val_accuracy: 0.7656\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.7969 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.7969 - val_loss: 0.5260 - val_accuracy: 0.7656\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.7986 - val_loss: 0.5260 - val_accuracy: 0.7656\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.7969 - val_loss: 0.5262 - val_accuracy: 0.7656\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7969 - val_loss: 0.5263 - val_accuracy: 0.7656\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.7969 - val_loss: 0.5263 - val_accuracy: 0.7656\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.7969 - val_loss: 0.5265 - val_accuracy: 0.7656\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.7969 - val_loss: 0.5265 - val_accuracy: 0.7656\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.7969 - val_loss: 0.5266 - val_accuracy: 0.7656\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7986 - val_loss: 0.5266 - val_accuracy: 0.7656\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7951 - val_loss: 0.5268 - val_accuracy: 0.7708\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.7969 - val_loss: 0.5268 - val_accuracy: 0.7708\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.7969 - val_loss: 0.5270 - val_accuracy: 0.7656\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.7951 - val_loss: 0.5270 - val_accuracy: 0.7656\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.5270 - val_accuracy: 0.7656\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.7951 - val_loss: 0.5271 - val_accuracy: 0.7656\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.7986 - val_loss: 0.5273 - val_accuracy: 0.7656\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4207 - accuracy: 0.7986 - val_loss: 0.5274 - val_accuracy: 0.7656\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.7969 - val_loss: 0.5274 - val_accuracy: 0.7656\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4206 - accuracy: 0.7986 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.7969 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8003 - val_loss: 0.5277 - val_accuracy: 0.7656\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7986 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7986 - val_loss: 0.5279 - val_accuracy: 0.7656\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.7969 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.8003 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.7986 - val_loss: 0.5282 - val_accuracy: 0.7656\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7969 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8021 - val_loss: 0.5285 - val_accuracy: 0.7656\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4196 - accuracy: 0.8003 - val_loss: 0.5286 - val_accuracy: 0.7708\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.7969 - val_loss: 0.5288 - val_accuracy: 0.7708\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4194 - accuracy: 0.7986 - val_loss: 0.5289 - val_accuracy: 0.7708\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4193 - accuracy: 0.8003 - val_loss: 0.5293 - val_accuracy: 0.7656\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4194 - accuracy: 0.8003 - val_loss: 0.5293 - val_accuracy: 0.7708\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8003 - val_loss: 0.5295 - val_accuracy: 0.7708\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.7951 - val_loss: 0.5297 - val_accuracy: 0.7708\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8021 - val_loss: 0.5297 - val_accuracy: 0.7708\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.7986 - val_loss: 0.5299 - val_accuracy: 0.7708\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8003 - val_loss: 0.5300 - val_accuracy: 0.7708\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8021 - val_loss: 0.5300 - val_accuracy: 0.7708\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.7986 - val_loss: 0.5302 - val_accuracy: 0.7708\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4186 - accuracy: 0.8021 - val_loss: 0.5303 - val_accuracy: 0.7708\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4185 - accuracy: 0.8003 - val_loss: 0.5304 - val_accuracy: 0.7708\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.8003 - val_loss: 0.5305 - val_accuracy: 0.7708\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4183 - accuracy: 0.7934 - val_loss: 0.5306 - val_accuracy: 0.7708\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.8021 - val_loss: 0.5307 - val_accuracy: 0.7708\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4181 - accuracy: 0.7986 - val_loss: 0.5308 - val_accuracy: 0.7708\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.7986 - val_loss: 0.5309 - val_accuracy: 0.7708\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4180 - accuracy: 0.8021 - val_loss: 0.5310 - val_accuracy: 0.7708\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8021 - val_loss: 0.5312 - val_accuracy: 0.7708\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4178 - accuracy: 0.8003 - val_loss: 0.5310 - val_accuracy: 0.7708\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5310 - val_accuracy: 0.7708\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.7986 - val_loss: 0.5312 - val_accuracy: 0.7708\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4177 - accuracy: 0.7986 - val_loss: 0.5312 - val_accuracy: 0.7708\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.5313 - val_accuracy: 0.7656\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.7986 - val_loss: 0.5313 - val_accuracy: 0.7708\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8003 - val_loss: 0.5313 - val_accuracy: 0.7708\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.7969 - val_loss: 0.5315 - val_accuracy: 0.7656\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4173 - accuracy: 0.7951 - val_loss: 0.5318 - val_accuracy: 0.7656\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.7986 - val_loss: 0.5319 - val_accuracy: 0.7656\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.7986 - val_loss: 0.5319 - val_accuracy: 0.7656\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4171 - accuracy: 0.8003 - val_loss: 0.5320 - val_accuracy: 0.7656\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.7986 - val_loss: 0.5321 - val_accuracy: 0.7656\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4170 - accuracy: 0.7969 - val_loss: 0.5323 - val_accuracy: 0.7656\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4169 - accuracy: 0.7986 - val_loss: 0.5324 - val_accuracy: 0.7656\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4169 - accuracy: 0.7986 - val_loss: 0.5326 - val_accuracy: 0.7656\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5328 - val_accuracy: 0.7656\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.7969 - val_loss: 0.5329 - val_accuracy: 0.7656\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4166 - accuracy: 0.7986 - val_loss: 0.5329 - val_accuracy: 0.7656\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.7969 - val_loss: 0.5329 - val_accuracy: 0.7656\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4167 - accuracy: 0.7986 - val_loss: 0.5331 - val_accuracy: 0.7656\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5332 - val_accuracy: 0.7656\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4163 - accuracy: 0.7986 - val_loss: 0.5331 - val_accuracy: 0.7656\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.7969 - val_loss: 0.5333 - val_accuracy: 0.7656\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.5333 - val_accuracy: 0.7656\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.7969 - val_loss: 0.5337 - val_accuracy: 0.7656\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.7951 - val_loss: 0.5338 - val_accuracy: 0.7656\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5337 - val_accuracy: 0.7656\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.5340 - val_accuracy: 0.7604\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.7986 - val_loss: 0.5340 - val_accuracy: 0.7604\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.7969 - val_loss: 0.5340 - val_accuracy: 0.7604\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4159 - accuracy: 0.7934 - val_loss: 0.5342 - val_accuracy: 0.7604\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.7986 - val_loss: 0.5341 - val_accuracy: 0.7604\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8003 - val_loss: 0.5341 - val_accuracy: 0.7604\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4159 - accuracy: 0.7951 - val_loss: 0.5344 - val_accuracy: 0.7604\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8003 - val_loss: 0.5342 - val_accuracy: 0.7604\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.7969 - val_loss: 0.5344 - val_accuracy: 0.7604\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.7951 - val_loss: 0.5344 - val_accuracy: 0.7604\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.7969 - val_loss: 0.5345 - val_accuracy: 0.7604\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.7969 - val_loss: 0.5346 - val_accuracy: 0.7552\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4152 - accuracy: 0.7986 - val_loss: 0.5347 - val_accuracy: 0.7604\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4153 - accuracy: 0.7986 - val_loss: 0.5349 - val_accuracy: 0.7604\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4152 - accuracy: 0.7969 - val_loss: 0.5349 - val_accuracy: 0.7604\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4151 - accuracy: 0.7986 - val_loss: 0.5351 - val_accuracy: 0.7604\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.7986 - val_loss: 0.5350 - val_accuracy: 0.7552\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8003 - val_loss: 0.5352 - val_accuracy: 0.7552\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.7951 - val_loss: 0.5353 - val_accuracy: 0.7552\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.7986 - val_loss: 0.5354 - val_accuracy: 0.7604\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8003 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4148 - accuracy: 0.7986 - val_loss: 0.5353 - val_accuracy: 0.7552\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4147 - accuracy: 0.7969 - val_loss: 0.5354 - val_accuracy: 0.7552\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.7986 - val_loss: 0.5356 - val_accuracy: 0.7552\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.7969 - val_loss: 0.5357 - val_accuracy: 0.7552\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.7969 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4146 - accuracy: 0.7951 - val_loss: 0.5358 - val_accuracy: 0.7552\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.7969 - val_loss: 0.5359 - val_accuracy: 0.7604\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.7986 - val_loss: 0.5360 - val_accuracy: 0.7604\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4144 - accuracy: 0.7951 - val_loss: 0.5362 - val_accuracy: 0.7604\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.7969 - val_loss: 0.5363 - val_accuracy: 0.7604\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.7969 - val_loss: 0.5363 - val_accuracy: 0.7604\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4143 - accuracy: 0.7969 - val_loss: 0.5363 - val_accuracy: 0.7604\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.7986 - val_loss: 0.5363 - val_accuracy: 0.7604\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.7969 - val_loss: 0.5365 - val_accuracy: 0.7604\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.7969 - val_loss: 0.5366 - val_accuracy: 0.7604\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5364 - val_accuracy: 0.7552\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.7986 - val_loss: 0.5365 - val_accuracy: 0.7552\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4140 - accuracy: 0.7969 - val_loss: 0.5365 - val_accuracy: 0.7552\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.7969 - val_loss: 0.5368 - val_accuracy: 0.7552\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8003 - val_loss: 0.5367 - val_accuracy: 0.7552\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.7969 - val_loss: 0.5368 - val_accuracy: 0.7552\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.7986 - val_loss: 0.5367 - val_accuracy: 0.7552\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.7986 - val_loss: 0.5368 - val_accuracy: 0.7552\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.7986 - val_loss: 0.5369 - val_accuracy: 0.7552\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.7969 - val_loss: 0.5370 - val_accuracy: 0.7552\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.7986 - val_loss: 0.5371 - val_accuracy: 0.7552\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4135 - accuracy: 0.7969 - val_loss: 0.5371 - val_accuracy: 0.7552\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4134 - accuracy: 0.7969 - val_loss: 0.5371 - val_accuracy: 0.7552\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5372 - val_accuracy: 0.7552\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5372 - val_accuracy: 0.7552\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5374 - val_accuracy: 0.7552\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.7934 - val_loss: 0.5374 - val_accuracy: 0.7552\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.7986 - val_loss: 0.5376 - val_accuracy: 0.7552\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.7986 - val_loss: 0.5376 - val_accuracy: 0.7552\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8003 - val_loss: 0.5376 - val_accuracy: 0.7552\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4131 - accuracy: 0.8003 - val_loss: 0.5376 - val_accuracy: 0.7552\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.8003 - val_loss: 0.5375 - val_accuracy: 0.7552\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.7969 - val_loss: 0.5377 - val_accuracy: 0.7552\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8003 - val_loss: 0.5378 - val_accuracy: 0.7552\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4129 - accuracy: 0.8003 - val_loss: 0.5378 - val_accuracy: 0.7552\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4128 - accuracy: 0.8021 - val_loss: 0.5379 - val_accuracy: 0.7552\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.8003 - val_loss: 0.5380 - val_accuracy: 0.7552\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.7986 - val_loss: 0.5383 - val_accuracy: 0.7552\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.7986 - val_loss: 0.5383 - val_accuracy: 0.7552\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.7986 - val_loss: 0.5384 - val_accuracy: 0.7552\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.7986 - val_loss: 0.5384 - val_accuracy: 0.7552\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8021 - val_loss: 0.5385 - val_accuracy: 0.7552\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4125 - accuracy: 0.7986 - val_loss: 0.5385 - val_accuracy: 0.7552\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4124 - accuracy: 0.8003 - val_loss: 0.5386 - val_accuracy: 0.7552\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8003 - val_loss: 0.5386 - val_accuracy: 0.7552\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4125 - accuracy: 0.8003 - val_loss: 0.5386 - val_accuracy: 0.7552\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.7986 - val_loss: 0.5387 - val_accuracy: 0.7552\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5388 - val_accuracy: 0.7552\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5389 - val_accuracy: 0.7552\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.7986 - val_loss: 0.5389 - val_accuracy: 0.7552\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8003 - val_loss: 0.5389 - val_accuracy: 0.7552\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4123 - accuracy: 0.8003 - val_loss: 0.5389 - val_accuracy: 0.7552\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.7986 - val_loss: 0.5391 - val_accuracy: 0.7552\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5393 - val_accuracy: 0.7552\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.7986 - val_loss: 0.5395 - val_accuracy: 0.7552\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8003 - val_loss: 0.5394 - val_accuracy: 0.7552\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.7986 - val_loss: 0.5396 - val_accuracy: 0.7552\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8003 - val_loss: 0.5396 - val_accuracy: 0.7552\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.7986 - val_loss: 0.5396 - val_accuracy: 0.7552\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.7986 - val_loss: 0.5397 - val_accuracy: 0.7552\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.8021 - val_loss: 0.5397 - val_accuracy: 0.7552\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8003 - val_loss: 0.5397 - val_accuracy: 0.7552\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8021 - val_loss: 0.5397 - val_accuracy: 0.7552\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8021 - val_loss: 0.5398 - val_accuracy: 0.7552\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8073 - val_loss: 0.5399 - val_accuracy: 0.7552\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8056 - val_loss: 0.5401 - val_accuracy: 0.7552\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8056 - val_loss: 0.5401 - val_accuracy: 0.7552\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8003 - val_loss: 0.5400 - val_accuracy: 0.7552\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8003 - val_loss: 0.5400 - val_accuracy: 0.7552\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8038 - val_loss: 0.5399 - val_accuracy: 0.7552\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8038 - val_loss: 0.5400 - val_accuracy: 0.7552\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8021 - val_loss: 0.5400 - val_accuracy: 0.7552\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8056 - val_loss: 0.5401 - val_accuracy: 0.7552\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8056 - val_loss: 0.5401 - val_accuracy: 0.7552\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8073 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8073 - val_loss: 0.5402 - val_accuracy: 0.7552\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8038 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8073 - val_loss: 0.5403 - val_accuracy: 0.7552\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8073 - val_loss: 0.5402 - val_accuracy: 0.7500\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8073 - val_loss: 0.5404 - val_accuracy: 0.7552\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8038 - val_loss: 0.5406 - val_accuracy: 0.7552\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8073 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8056 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8056 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8038 - val_loss: 0.5406 - val_accuracy: 0.7500\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8056 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8073 - val_loss: 0.5405 - val_accuracy: 0.7448\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8090 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8073 - val_loss: 0.5408 - val_accuracy: 0.7500\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8073 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8056 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8038 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8056 - val_loss: 0.5410 - val_accuracy: 0.7448\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8038 - val_loss: 0.5411 - val_accuracy: 0.7448\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8038 - val_loss: 0.5412 - val_accuracy: 0.7448\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4102 - accuracy: 0.8038 - val_loss: 0.5414 - val_accuracy: 0.7396\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4101 - accuracy: 0.8021 - val_loss: 0.5417 - val_accuracy: 0.7396\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8056 - val_loss: 0.5416 - val_accuracy: 0.7396\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8056 - val_loss: 0.5418 - val_accuracy: 0.7396\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8056 - val_loss: 0.5417 - val_accuracy: 0.7396\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8056 - val_loss: 0.5417 - val_accuracy: 0.7396\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4100 - accuracy: 0.8056 - val_loss: 0.5419 - val_accuracy: 0.7396\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5420 - val_accuracy: 0.7448\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5421 - val_accuracy: 0.7396\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8038 - val_loss: 0.5421 - val_accuracy: 0.7396\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8090 - val_loss: 0.5420 - val_accuracy: 0.7396\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4098 - accuracy: 0.8038 - val_loss: 0.5421 - val_accuracy: 0.7396\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5422 - val_accuracy: 0.7396\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8073 - val_loss: 0.5422 - val_accuracy: 0.7396\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8056 - val_loss: 0.5427 - val_accuracy: 0.7396\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5427 - val_accuracy: 0.7396\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5429 - val_accuracy: 0.7396\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8056 - val_loss: 0.5429 - val_accuracy: 0.7396\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4095 - accuracy: 0.8038 - val_loss: 0.5429 - val_accuracy: 0.7396\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8038 - val_loss: 0.5429 - val_accuracy: 0.7396\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.8056 - val_loss: 0.5430 - val_accuracy: 0.7396\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8073 - val_loss: 0.5431 - val_accuracy: 0.7396\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8056 - val_loss: 0.5432 - val_accuracy: 0.7396\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.8038 - val_loss: 0.5434 - val_accuracy: 0.7396\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8056 - val_loss: 0.5436 - val_accuracy: 0.7396\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8056 - val_loss: 0.5439 - val_accuracy: 0.7344\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8056 - val_loss: 0.5439 - val_accuracy: 0.7396\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8056 - val_loss: 0.5439 - val_accuracy: 0.7396\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4092 - accuracy: 0.8056 - val_loss: 0.5440 - val_accuracy: 0.7344\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8073 - val_loss: 0.5439 - val_accuracy: 0.7396\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8073 - val_loss: 0.5440 - val_accuracy: 0.7396\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8056 - val_loss: 0.5440 - val_accuracy: 0.7396\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8056 - val_loss: 0.5440 - val_accuracy: 0.7396\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8056 - val_loss: 0.5444 - val_accuracy: 0.7396\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8090 - val_loss: 0.5443 - val_accuracy: 0.7344\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8056 - val_loss: 0.5442 - val_accuracy: 0.7396\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8073 - val_loss: 0.5442 - val_accuracy: 0.7344\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8056 - val_loss: 0.5444 - val_accuracy: 0.7344\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8073 - val_loss: 0.5443 - val_accuracy: 0.7344\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8038 - val_loss: 0.5446 - val_accuracy: 0.7344\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8056 - val_loss: 0.5447 - val_accuracy: 0.7344\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8073 - val_loss: 0.5447 - val_accuracy: 0.7344\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8056 - val_loss: 0.5449 - val_accuracy: 0.7344\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8056 - val_loss: 0.5449 - val_accuracy: 0.7344\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8038 - val_loss: 0.5452 - val_accuracy: 0.7344\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8056 - val_loss: 0.5451 - val_accuracy: 0.7344\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8056 - val_loss: 0.5450 - val_accuracy: 0.7344\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8073 - val_loss: 0.5452 - val_accuracy: 0.7344\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8056 - val_loss: 0.5452 - val_accuracy: 0.7344\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8038 - val_loss: 0.5453 - val_accuracy: 0.7344\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8038 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8038 - val_loss: 0.5453 - val_accuracy: 0.7396\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8056 - val_loss: 0.5452 - val_accuracy: 0.7396\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4079 - accuracy: 0.8038 - val_loss: 0.5454 - val_accuracy: 0.7396\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8021 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8056 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8021 - val_loss: 0.5461 - val_accuracy: 0.7396\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8056 - val_loss: 0.5463 - val_accuracy: 0.7396\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8056 - val_loss: 0.5461 - val_accuracy: 0.7396\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8056 - val_loss: 0.5460 - val_accuracy: 0.7396\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8021 - val_loss: 0.5464 - val_accuracy: 0.7396\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8073 - val_loss: 0.5462 - val_accuracy: 0.7396\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8021 - val_loss: 0.5462 - val_accuracy: 0.7396\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4073 - accuracy: 0.8038 - val_loss: 0.5460 - val_accuracy: 0.7396\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.8056 - val_loss: 0.5465 - val_accuracy: 0.7396\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4073 - accuracy: 0.8021 - val_loss: 0.5466 - val_accuracy: 0.7396\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.8038 - val_loss: 0.5465 - val_accuracy: 0.7396\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4070 - accuracy: 0.8073 - val_loss: 0.5466 - val_accuracy: 0.7396\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4071 - accuracy: 0.8073 - val_loss: 0.5465 - val_accuracy: 0.7396\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4070 - accuracy: 0.8021 - val_loss: 0.5467 - val_accuracy: 0.7396\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8073 - val_loss: 0.5465 - val_accuracy: 0.7396\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.8073 - val_loss: 0.5469 - val_accuracy: 0.7396\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4070 - accuracy: 0.8038 - val_loss: 0.5472 - val_accuracy: 0.7396\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4070 - accuracy: 0.8090 - val_loss: 0.5472 - val_accuracy: 0.7396\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8073 - val_loss: 0.5473 - val_accuracy: 0.7396\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8073 - val_loss: 0.5475 - val_accuracy: 0.7396\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8056 - val_loss: 0.5477 - val_accuracy: 0.7396\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4068 - accuracy: 0.8090 - val_loss: 0.5477 - val_accuracy: 0.7396\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8090 - val_loss: 0.5477 - val_accuracy: 0.7396\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8073 - val_loss: 0.5475 - val_accuracy: 0.7396\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8056 - val_loss: 0.5478 - val_accuracy: 0.7396\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4064 - accuracy: 0.8056 - val_loss: 0.5480 - val_accuracy: 0.7396\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.5480 - val_accuracy: 0.7396\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.5479 - val_accuracy: 0.7396\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8038 - val_loss: 0.5483 - val_accuracy: 0.7396\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8073 - val_loss: 0.5482 - val_accuracy: 0.7396\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.8038 - val_loss: 0.5482 - val_accuracy: 0.7396\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8073 - val_loss: 0.5484 - val_accuracy: 0.7396\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8056 - val_loss: 0.5483 - val_accuracy: 0.7396\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8108 - val_loss: 0.5483 - val_accuracy: 0.7396\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8073 - val_loss: 0.5483 - val_accuracy: 0.7396\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4062 - accuracy: 0.8073 - val_loss: 0.5482 - val_accuracy: 0.7344\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4061 - accuracy: 0.8056 - val_loss: 0.5485 - val_accuracy: 0.7344\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8125 - val_loss: 0.5484 - val_accuracy: 0.7396\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4059 - accuracy: 0.8056 - val_loss: 0.5487 - val_accuracy: 0.7344\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4059 - accuracy: 0.8073 - val_loss: 0.5487 - val_accuracy: 0.7396\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4061 - accuracy: 0.8073 - val_loss: 0.5487 - val_accuracy: 0.7344\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8090 - val_loss: 0.5487 - val_accuracy: 0.7396\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8073 - val_loss: 0.5487 - val_accuracy: 0.7396\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8090 - val_loss: 0.5490 - val_accuracy: 0.7396\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8073 - val_loss: 0.5489 - val_accuracy: 0.7396\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4057 - accuracy: 0.8073 - val_loss: 0.5494 - val_accuracy: 0.7396\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8125 - val_loss: 0.5491 - val_accuracy: 0.7396\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4054 - accuracy: 0.8108 - val_loss: 0.5489 - val_accuracy: 0.7396\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4055 - accuracy: 0.8090 - val_loss: 0.5490 - val_accuracy: 0.7396\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8090 - val_loss: 0.5493 - val_accuracy: 0.7396\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4053 - accuracy: 0.8090 - val_loss: 0.5495 - val_accuracy: 0.7396\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8090 - val_loss: 0.5495 - val_accuracy: 0.7396\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8090 - val_loss: 0.5493 - val_accuracy: 0.7396\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8090 - val_loss: 0.5493 - val_accuracy: 0.7396\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4053 - accuracy: 0.8073 - val_loss: 0.5494 - val_accuracy: 0.7396\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.8073 - val_loss: 0.5494 - val_accuracy: 0.7396\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8090 - val_loss: 0.5495 - val_accuracy: 0.7396\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8108 - val_loss: 0.5494 - val_accuracy: 0.7396\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.8090 - val_loss: 0.5497 - val_accuracy: 0.7396\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8090 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8090 - val_loss: 0.5500 - val_accuracy: 0.7396\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4050 - accuracy: 0.8090 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4048 - accuracy: 0.8090 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8090 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8108 - val_loss: 0.5504 - val_accuracy: 0.7396\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8108 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8073 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8090 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4045 - accuracy: 0.8090 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8108 - val_loss: 0.5507 - val_accuracy: 0.7396\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8090 - val_loss: 0.5509 - val_accuracy: 0.7396\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.8090 - val_loss: 0.5509 - val_accuracy: 0.7396\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8108 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4044 - accuracy: 0.8108 - val_loss: 0.5506 - val_accuracy: 0.7396\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4044 - accuracy: 0.8090 - val_loss: 0.5507 - val_accuracy: 0.7396\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.8090 - val_loss: 0.5507 - val_accuracy: 0.7396\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8090 - val_loss: 0.5507 - val_accuracy: 0.7396\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8108 - val_loss: 0.5507 - val_accuracy: 0.7396\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8090 - val_loss: 0.5511 - val_accuracy: 0.7396\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4040 - accuracy: 0.8125 - val_loss: 0.5510 - val_accuracy: 0.7396\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8125 - val_loss: 0.5510 - val_accuracy: 0.7396\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4040 - accuracy: 0.8108 - val_loss: 0.5513 - val_accuracy: 0.7396\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5511 - val_accuracy: 0.7396\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8125 - val_loss: 0.5511 - val_accuracy: 0.7396\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.8108 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4037 - accuracy: 0.8108 - val_loss: 0.5514 - val_accuracy: 0.7396\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8108 - val_loss: 0.5511 - val_accuracy: 0.7396\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8125 - val_loss: 0.5513 - val_accuracy: 0.7396\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8108 - val_loss: 0.5517 - val_accuracy: 0.7396\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8125 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4035 - accuracy: 0.8125 - val_loss: 0.5516 - val_accuracy: 0.7396\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8125 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8090 - val_loss: 0.5514 - val_accuracy: 0.7396\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8108 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8125 - val_loss: 0.5517 - val_accuracy: 0.7396\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8125 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.8125 - val_loss: 0.5516 - val_accuracy: 0.7396\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4032 - accuracy: 0.8108 - val_loss: 0.5519 - val_accuracy: 0.7396\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8108 - val_loss: 0.5518 - val_accuracy: 0.7396\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.8108 - val_loss: 0.5520 - val_accuracy: 0.7396\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8108 - val_loss: 0.5519 - val_accuracy: 0.7396\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8125 - val_loss: 0.5521 - val_accuracy: 0.7448\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8125 - val_loss: 0.5523 - val_accuracy: 0.7396\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8125 - val_loss: 0.5522 - val_accuracy: 0.7344\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8142 - val_loss: 0.5519 - val_accuracy: 0.7396\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8108 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8125 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8125 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8108 - val_loss: 0.5525 - val_accuracy: 0.7396\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8142 - val_loss: 0.5522 - val_accuracy: 0.7344\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8108 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8108 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8090 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4026 - accuracy: 0.8108 - val_loss: 0.5525 - val_accuracy: 0.7344\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8108 - val_loss: 0.5521 - val_accuracy: 0.7344\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4024 - accuracy: 0.8108 - val_loss: 0.5522 - val_accuracy: 0.7344\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8108 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8108 - val_loss: 0.5525 - val_accuracy: 0.7344\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8090 - val_loss: 0.5525 - val_accuracy: 0.7344\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8056 - val_loss: 0.5522 - val_accuracy: 0.7344\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8073 - val_loss: 0.5520 - val_accuracy: 0.7344\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8108 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4021 - accuracy: 0.8090 - val_loss: 0.5524 - val_accuracy: 0.7344\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8073 - val_loss: 0.5522 - val_accuracy: 0.7344\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8073 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8073 - val_loss: 0.5521 - val_accuracy: 0.7344\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4019 - accuracy: 0.8090 - val_loss: 0.5524 - val_accuracy: 0.7344\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8073 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8038 - val_loss: 0.5523 - val_accuracy: 0.7344\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4016 - accuracy: 0.8073 - val_loss: 0.5526 - val_accuracy: 0.7344\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8056 - val_loss: 0.5523 - val_accuracy: 0.7396\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4015 - accuracy: 0.8056 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8056 - val_loss: 0.5523 - val_accuracy: 0.7396\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8090 - val_loss: 0.5525 - val_accuracy: 0.7344\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8038 - val_loss: 0.5526 - val_accuracy: 0.7344\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8056 - val_loss: 0.5525 - val_accuracy: 0.7396\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8038 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4013 - accuracy: 0.8038 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4014 - accuracy: 0.8056 - val_loss: 0.5525 - val_accuracy: 0.7396\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4012 - accuracy: 0.8038 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4010 - accuracy: 0.8073 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8021 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8038 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8056 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4008 - accuracy: 0.8038 - val_loss: 0.5527 - val_accuracy: 0.7396\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4010 - accuracy: 0.8038 - val_loss: 0.5526 - val_accuracy: 0.7396\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4007 - accuracy: 0.8038 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8038 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8021 - val_loss: 0.5529 - val_accuracy: 0.7396\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4006 - accuracy: 0.8021 - val_loss: 0.5530 - val_accuracy: 0.7396\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4006 - accuracy: 0.8021 - val_loss: 0.5528 - val_accuracy: 0.7396\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8021 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8056 - val_loss: 0.5533 - val_accuracy: 0.7396\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.8038 - val_loss: 0.5531 - val_accuracy: 0.7396\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4005 - accuracy: 0.8038 - val_loss: 0.5532 - val_accuracy: 0.7396\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8021 - val_loss: 0.5533 - val_accuracy: 0.7396\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8003 - val_loss: 0.5534 - val_accuracy: 0.7396\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8038 - val_loss: 0.5534 - val_accuracy: 0.7396\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4002 - accuracy: 0.8038 - val_loss: 0.5534 - val_accuracy: 0.7396\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8021 - val_loss: 0.5538 - val_accuracy: 0.7396\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8038 - val_loss: 0.5537 - val_accuracy: 0.7396\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8021 - val_loss: 0.5537 - val_accuracy: 0.7396\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8021 - val_loss: 0.5539 - val_accuracy: 0.7396\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8003 - val_loss: 0.5541 - val_accuracy: 0.7396\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8021 - val_loss: 0.5544 - val_accuracy: 0.7344\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4000 - accuracy: 0.8021 - val_loss: 0.5545 - val_accuracy: 0.7396\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3999 - accuracy: 0.8038 - val_loss: 0.5545 - val_accuracy: 0.7396\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3999 - accuracy: 0.8038 - val_loss: 0.5544 - val_accuracy: 0.7396\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3997 - accuracy: 0.8038 - val_loss: 0.5544 - val_accuracy: 0.7344\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8038 - val_loss: 0.5543 - val_accuracy: 0.7396\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8003 - val_loss: 0.5547 - val_accuracy: 0.7396\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8003 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3997 - accuracy: 0.8021 - val_loss: 0.5547 - val_accuracy: 0.7344\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8021 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3994 - accuracy: 0.8021 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8021 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8056 - val_loss: 0.5548 - val_accuracy: 0.7396\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8038 - val_loss: 0.5547 - val_accuracy: 0.7396\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8038 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8021 - val_loss: 0.5546 - val_accuracy: 0.7396\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8003 - val_loss: 0.5546 - val_accuracy: 0.7344\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8003 - val_loss: 0.5546 - val_accuracy: 0.7344\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8073 - val_loss: 0.5547 - val_accuracy: 0.7344\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8038 - val_loss: 0.5546 - val_accuracy: 0.7344\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3992 - accuracy: 0.8021 - val_loss: 0.5546 - val_accuracy: 0.7344\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3991 - accuracy: 0.8038 - val_loss: 0.5548 - val_accuracy: 0.7344\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8021 - val_loss: 0.5550 - val_accuracy: 0.7396\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3990 - accuracy: 0.8073 - val_loss: 0.5550 - val_accuracy: 0.7344\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8038 - val_loss: 0.5550 - val_accuracy: 0.7344\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3988 - accuracy: 0.8056 - val_loss: 0.5548 - val_accuracy: 0.7344\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8038 - val_loss: 0.5548 - val_accuracy: 0.7344\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8056 - val_loss: 0.5547 - val_accuracy: 0.7344\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8038 - val_loss: 0.5550 - val_accuracy: 0.7344\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8038 - val_loss: 0.5551 - val_accuracy: 0.7292\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8056 - val_loss: 0.5554 - val_accuracy: 0.7344\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3987 - accuracy: 0.8056 - val_loss: 0.5552 - val_accuracy: 0.7344\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8038 - val_loss: 0.5554 - val_accuracy: 0.7292\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8038 - val_loss: 0.5557 - val_accuracy: 0.7292\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8038 - val_loss: 0.5555 - val_accuracy: 0.7292\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8038 - val_loss: 0.5556 - val_accuracy: 0.7292\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8038 - val_loss: 0.5556 - val_accuracy: 0.7292\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8038 - val_loss: 0.5556 - val_accuracy: 0.7344\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8038 - val_loss: 0.5556 - val_accuracy: 0.7396\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3984 - accuracy: 0.8073 - val_loss: 0.5560 - val_accuracy: 0.7292\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8038 - val_loss: 0.5564 - val_accuracy: 0.7292\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8073 - val_loss: 0.5562 - val_accuracy: 0.7292\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8038 - val_loss: 0.5565 - val_accuracy: 0.7292\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3982 - accuracy: 0.8056 - val_loss: 0.5562 - val_accuracy: 0.7292\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8038 - val_loss: 0.5563 - val_accuracy: 0.7292\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3981 - accuracy: 0.8073 - val_loss: 0.5563 - val_accuracy: 0.7292\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8021 - val_loss: 0.5566 - val_accuracy: 0.7292\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8038 - val_loss: 0.5564 - val_accuracy: 0.7292\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3980 - accuracy: 0.8073 - val_loss: 0.5564 - val_accuracy: 0.7292\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8056 - val_loss: 0.5563 - val_accuracy: 0.7292\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8038 - val_loss: 0.5565 - val_accuracy: 0.7292\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8056 - val_loss: 0.5564 - val_accuracy: 0.7292\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8056 - val_loss: 0.5562 - val_accuracy: 0.7344\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8056 - val_loss: 0.5563 - val_accuracy: 0.7344\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8056 - val_loss: 0.5563 - val_accuracy: 0.7344\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8073 - val_loss: 0.5563 - val_accuracy: 0.7344\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.8038 - val_loss: 0.5563 - val_accuracy: 0.7396\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8056 - val_loss: 0.5563 - val_accuracy: 0.7396\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3978 - accuracy: 0.8056 - val_loss: 0.5566 - val_accuracy: 0.7344\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8073 - val_loss: 0.5567 - val_accuracy: 0.7344\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8056 - val_loss: 0.5565 - val_accuracy: 0.7344\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3976 - accuracy: 0.8056 - val_loss: 0.5567 - val_accuracy: 0.7344\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8056 - val_loss: 0.5570 - val_accuracy: 0.7344\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.8056 - val_loss: 0.5570 - val_accuracy: 0.7344\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3976 - accuracy: 0.8056 - val_loss: 0.5570 - val_accuracy: 0.7344\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8056 - val_loss: 0.5573 - val_accuracy: 0.7344\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8090 - val_loss: 0.5569 - val_accuracy: 0.7344\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8056 - val_loss: 0.5572 - val_accuracy: 0.7344\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3974 - accuracy: 0.8073 - val_loss: 0.5570 - val_accuracy: 0.7344\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8056 - val_loss: 0.5571 - val_accuracy: 0.7396\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3975 - accuracy: 0.8073 - val_loss: 0.5571 - val_accuracy: 0.7344\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3973 - accuracy: 0.8021 - val_loss: 0.5573 - val_accuracy: 0.7344\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8073 - val_loss: 0.5574 - val_accuracy: 0.7344\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8038 - val_loss: 0.5576 - val_accuracy: 0.7344\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.8090 - val_loss: 0.5575 - val_accuracy: 0.7344\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8056 - val_loss: 0.5573 - val_accuracy: 0.7344\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8073 - val_loss: 0.5578 - val_accuracy: 0.7344\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8073 - val_loss: 0.5578 - val_accuracy: 0.7344\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3972 - accuracy: 0.8073 - val_loss: 0.5578 - val_accuracy: 0.7344\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8038 - val_loss: 0.5579 - val_accuracy: 0.7344\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8056 - val_loss: 0.5579 - val_accuracy: 0.7344\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8038 - val_loss: 0.5583 - val_accuracy: 0.7344\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8073 - val_loss: 0.5582 - val_accuracy: 0.7344\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8038 - val_loss: 0.5584 - val_accuracy: 0.7344\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3970 - accuracy: 0.8073 - val_loss: 0.5583 - val_accuracy: 0.7344\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8108 - val_loss: 0.5582 - val_accuracy: 0.7344\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8038 - val_loss: 0.5580 - val_accuracy: 0.7344\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8073 - val_loss: 0.5581 - val_accuracy: 0.7344\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8038 - val_loss: 0.5583 - val_accuracy: 0.7344\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3968 - accuracy: 0.8056 - val_loss: 0.5584 - val_accuracy: 0.7344\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8090 - val_loss: 0.5584 - val_accuracy: 0.7344\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8073 - val_loss: 0.5583 - val_accuracy: 0.7344\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3969 - accuracy: 0.8038 - val_loss: 0.5586 - val_accuracy: 0.7344\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8038 - val_loss: 0.5588 - val_accuracy: 0.7344\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8056 - val_loss: 0.5586 - val_accuracy: 0.7344\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8056 - val_loss: 0.5589 - val_accuracy: 0.7344\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8021 - val_loss: 0.5589 - val_accuracy: 0.7344\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8090 - val_loss: 0.5588 - val_accuracy: 0.7344\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8056 - val_loss: 0.5588 - val_accuracy: 0.7344\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8056 - val_loss: 0.5590 - val_accuracy: 0.7344\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8073 - val_loss: 0.5590 - val_accuracy: 0.7344\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3965 - accuracy: 0.8038 - val_loss: 0.5589 - val_accuracy: 0.7344\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8056 - val_loss: 0.5592 - val_accuracy: 0.7344\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3966 - accuracy: 0.8056 - val_loss: 0.5590 - val_accuracy: 0.7344\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8090 - val_loss: 0.5593 - val_accuracy: 0.7344\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8056 - val_loss: 0.5594 - val_accuracy: 0.7344\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8073 - val_loss: 0.5592 - val_accuracy: 0.7344\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8038 - val_loss: 0.5595 - val_accuracy: 0.7344\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8003 - val_loss: 0.5596 - val_accuracy: 0.7344\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3964 - accuracy: 0.8073 - val_loss: 0.5601 - val_accuracy: 0.7344\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8090 - val_loss: 0.5597 - val_accuracy: 0.7344\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8073 - val_loss: 0.5599 - val_accuracy: 0.7344\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3963 - accuracy: 0.8056 - val_loss: 0.5597 - val_accuracy: 0.7396\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.8038 - val_loss: 0.5603 - val_accuracy: 0.7396\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8021 - val_loss: 0.5603 - val_accuracy: 0.7396\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8090 - val_loss: 0.5601 - val_accuracy: 0.7344\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8056 - val_loss: 0.5601 - val_accuracy: 0.7396\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8038 - val_loss: 0.5598 - val_accuracy: 0.7344\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8038 - val_loss: 0.5601 - val_accuracy: 0.7344\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8056 - val_loss: 0.5603 - val_accuracy: 0.7344\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8038 - val_loss: 0.5607 - val_accuracy: 0.7396\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8056 - val_loss: 0.5606 - val_accuracy: 0.7396\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8108 - val_loss: 0.5603 - val_accuracy: 0.7396\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8073 - val_loss: 0.5607 - val_accuracy: 0.7396\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3959 - accuracy: 0.8090 - val_loss: 0.5606 - val_accuracy: 0.7396\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8056 - val_loss: 0.5607 - val_accuracy: 0.7396\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8038 - val_loss: 0.5609 - val_accuracy: 0.7396\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3958 - accuracy: 0.8056 - val_loss: 0.5609 - val_accuracy: 0.7396\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8073 - val_loss: 0.5606 - val_accuracy: 0.7396\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.8056 - val_loss: 0.5608 - val_accuracy: 0.7344\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8038 - val_loss: 0.5614 - val_accuracy: 0.7396\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.8073 - val_loss: 0.5611 - val_accuracy: 0.7396\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3957 - accuracy: 0.8038 - val_loss: 0.5613 - val_accuracy: 0.7396\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8056 - val_loss: 0.5615 - val_accuracy: 0.7396\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3959 - accuracy: 0.8056 - val_loss: 0.5615 - val_accuracy: 0.7396\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8038 - val_loss: 0.5618 - val_accuracy: 0.7396\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8056 - val_loss: 0.5617 - val_accuracy: 0.7396\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8056 - val_loss: 0.5615 - val_accuracy: 0.7396\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8038 - val_loss: 0.5616 - val_accuracy: 0.7396\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8038 - val_loss: 0.5616 - val_accuracy: 0.7396\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8073 - val_loss: 0.5620 - val_accuracy: 0.7396\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3954 - accuracy: 0.8038 - val_loss: 0.5618 - val_accuracy: 0.7396\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8038 - val_loss: 0.5615 - val_accuracy: 0.7500\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8038 - val_loss: 0.5617 - val_accuracy: 0.7500\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8056 - val_loss: 0.5618 - val_accuracy: 0.7500\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8038 - val_loss: 0.5622 - val_accuracy: 0.7448\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8073 - val_loss: 0.5621 - val_accuracy: 0.7448\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8038 - val_loss: 0.5618 - val_accuracy: 0.7448\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3953 - accuracy: 0.8056 - val_loss: 0.5620 - val_accuracy: 0.7448\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8056 - val_loss: 0.5622 - val_accuracy: 0.7500\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8056 - val_loss: 0.5628 - val_accuracy: 0.7448\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8021 - val_loss: 0.5625 - val_accuracy: 0.7500\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8038 - val_loss: 0.5626 - val_accuracy: 0.7500\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.8108 - val_loss: 0.5628 - val_accuracy: 0.7448\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3952 - accuracy: 0.8073 - val_loss: 0.5625 - val_accuracy: 0.7448\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8038 - val_loss: 0.5628 - val_accuracy: 0.7500\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8073 - val_loss: 0.5626 - val_accuracy: 0.7448\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8073 - val_loss: 0.5632 - val_accuracy: 0.7448\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8056 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8090 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8073 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8056 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8090 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3950 - accuracy: 0.8056 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8038 - val_loss: 0.5630 - val_accuracy: 0.7500\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3951 - accuracy: 0.8073 - val_loss: 0.5631 - val_accuracy: 0.7552\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3949 - accuracy: 0.8073 - val_loss: 0.5636 - val_accuracy: 0.7500\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8056 - val_loss: 0.5633 - val_accuracy: 0.7500\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8056 - val_loss: 0.5634 - val_accuracy: 0.7552\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8073 - val_loss: 0.5634 - val_accuracy: 0.7552\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8073 - val_loss: 0.5632 - val_accuracy: 0.7500\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8021 - val_loss: 0.5638 - val_accuracy: 0.7500\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8038 - val_loss: 0.5640 - val_accuracy: 0.7500\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3949 - accuracy: 0.8021 - val_loss: 0.5638 - val_accuracy: 0.7500\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.8056 - val_loss: 0.5638 - val_accuracy: 0.7500\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8073 - val_loss: 0.5636 - val_accuracy: 0.7500\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.8090 - val_loss: 0.5638 - val_accuracy: 0.7500\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8038 - val_loss: 0.5636 - val_accuracy: 0.7500\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8056 - val_loss: 0.5641 - val_accuracy: 0.7500\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.8056 - val_loss: 0.5641 - val_accuracy: 0.7500\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.8056 - val_loss: 0.5641 - val_accuracy: 0.7552\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8056 - val_loss: 0.5646 - val_accuracy: 0.7552\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8038 - val_loss: 0.5644 - val_accuracy: 0.7552\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8038 - val_loss: 0.5643 - val_accuracy: 0.7500\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.8073 - val_loss: 0.5640 - val_accuracy: 0.7500\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8056 - val_loss: 0.5643 - val_accuracy: 0.7552\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8038 - val_loss: 0.5643 - val_accuracy: 0.7552\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8056 - val_loss: 0.5645 - val_accuracy: 0.7552\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8073 - val_loss: 0.5648 - val_accuracy: 0.7552\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8056 - val_loss: 0.5646 - val_accuracy: 0.7500\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8056 - val_loss: 0.5645 - val_accuracy: 0.7500\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8056 - val_loss: 0.5645 - val_accuracy: 0.7500\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8073 - val_loss: 0.5644 - val_accuracy: 0.7500\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8038 - val_loss: 0.5641 - val_accuracy: 0.7500\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8038 - val_loss: 0.5647 - val_accuracy: 0.7500\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8073 - val_loss: 0.5647 - val_accuracy: 0.7500\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8056 - val_loss: 0.5649 - val_accuracy: 0.7500\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8056 - val_loss: 0.5648 - val_accuracy: 0.7500\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3944 - accuracy: 0.8038 - val_loss: 0.5654 - val_accuracy: 0.7552\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8056 - val_loss: 0.5652 - val_accuracy: 0.7500\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8056 - val_loss: 0.5653 - val_accuracy: 0.7500\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8056 - val_loss: 0.5655 - val_accuracy: 0.7552\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8056 - val_loss: 0.5653 - val_accuracy: 0.7552\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8056 - val_loss: 0.5651 - val_accuracy: 0.7552\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3941 - accuracy: 0.8038 - val_loss: 0.5653 - val_accuracy: 0.7552\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8073 - val_loss: 0.5656 - val_accuracy: 0.7552\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8056 - val_loss: 0.5657 - val_accuracy: 0.7552\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8073 - val_loss: 0.5659 - val_accuracy: 0.7552\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8090 - val_loss: 0.5657 - val_accuracy: 0.7552\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8056 - val_loss: 0.5662 - val_accuracy: 0.7552\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8056 - val_loss: 0.5662 - val_accuracy: 0.7552\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3940 - accuracy: 0.8056 - val_loss: 0.5665 - val_accuracy: 0.7552\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3940 - accuracy: 0.8073 - val_loss: 0.5662 - val_accuracy: 0.7552\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8090 - val_loss: 0.5660 - val_accuracy: 0.7552\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8038 - val_loss: 0.5663 - val_accuracy: 0.7552\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8038 - val_loss: 0.5663 - val_accuracy: 0.7552\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8038 - val_loss: 0.5663 - val_accuracy: 0.7552\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.8073 - val_loss: 0.5665 - val_accuracy: 0.7552\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8038 - val_loss: 0.5665 - val_accuracy: 0.7552\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.8090 - val_loss: 0.5661 - val_accuracy: 0.7552\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8056 - val_loss: 0.5660 - val_accuracy: 0.7552\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8073 - val_loss: 0.5667 - val_accuracy: 0.7552\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8073 - val_loss: 0.5664 - val_accuracy: 0.7552\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8056 - val_loss: 0.5660 - val_accuracy: 0.7552\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8056 - val_loss: 0.5665 - val_accuracy: 0.7552\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.8038 - val_loss: 0.5666 - val_accuracy: 0.7552\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8090 - val_loss: 0.5664 - val_accuracy: 0.7552\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3938 - accuracy: 0.8038 - val_loss: 0.5667 - val_accuracy: 0.7552\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8090 - val_loss: 0.5668 - val_accuracy: 0.7552\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8073 - val_loss: 0.5669 - val_accuracy: 0.7552\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8073 - val_loss: 0.5668 - val_accuracy: 0.7552\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8090 - val_loss: 0.5666 - val_accuracy: 0.7552\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8090 - val_loss: 0.5670 - val_accuracy: 0.7552\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8090 - val_loss: 0.5668 - val_accuracy: 0.7552\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8073 - val_loss: 0.5668 - val_accuracy: 0.7552\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8090 - val_loss: 0.5669 - val_accuracy: 0.7552\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3936 - accuracy: 0.8073 - val_loss: 0.5670 - val_accuracy: 0.7552\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8073 - val_loss: 0.5669 - val_accuracy: 0.7552\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8073 - val_loss: 0.5669 - val_accuracy: 0.7552\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8090 - val_loss: 0.5670 - val_accuracy: 0.7552\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8038 - val_loss: 0.5675 - val_accuracy: 0.7552\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8090 - val_loss: 0.5674 - val_accuracy: 0.7552\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8090 - val_loss: 0.5677 - val_accuracy: 0.7552\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8073 - val_loss: 0.5676 - val_accuracy: 0.7552\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3937 - accuracy: 0.8073 - val_loss: 0.5677 - val_accuracy: 0.7552\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8056 - val_loss: 0.5679 - val_accuracy: 0.7552\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8073 - val_loss: 0.5681 - val_accuracy: 0.7552\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8090 - val_loss: 0.5679 - val_accuracy: 0.7552\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8090 - val_loss: 0.5679 - val_accuracy: 0.7552\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8090 - val_loss: 0.5680 - val_accuracy: 0.7552\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8108 - val_loss: 0.5681 - val_accuracy: 0.7552\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8073 - val_loss: 0.5680 - val_accuracy: 0.7552\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.8108 - val_loss: 0.5677 - val_accuracy: 0.7552\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8038 - val_loss: 0.5681 - val_accuracy: 0.7552\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8038 - val_loss: 0.5684 - val_accuracy: 0.7552\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3934 - accuracy: 0.8090 - val_loss: 0.5686 - val_accuracy: 0.7552\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8056 - val_loss: 0.5686 - val_accuracy: 0.7552\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.8073 - val_loss: 0.5684 - val_accuracy: 0.7552\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8056 - val_loss: 0.5683 - val_accuracy: 0.7552\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8073 - val_loss: 0.5684 - val_accuracy: 0.7552\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8090 - val_loss: 0.5685 - val_accuracy: 0.7552\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8090 - val_loss: 0.5684 - val_accuracy: 0.7552\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.8038 - val_loss: 0.5687 - val_accuracy: 0.7552\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8090 - val_loss: 0.5686 - val_accuracy: 0.7552\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8090 - val_loss: 0.5688 - val_accuracy: 0.7552\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8073 - val_loss: 0.5685 - val_accuracy: 0.7552\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8073 - val_loss: 0.5687 - val_accuracy: 0.7552\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8073 - val_loss: 0.5690 - val_accuracy: 0.7552\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8108 - val_loss: 0.5687 - val_accuracy: 0.7552\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8073 - val_loss: 0.5687 - val_accuracy: 0.7552\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.8090 - val_loss: 0.5688 - val_accuracy: 0.7552\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8090 - val_loss: 0.5689 - val_accuracy: 0.7552\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8108 - val_loss: 0.5693 - val_accuracy: 0.7552\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3929 - accuracy: 0.8090 - val_loss: 0.5691 - val_accuracy: 0.7552\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3931 - accuracy: 0.8038 - val_loss: 0.5690 - val_accuracy: 0.7552\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3930 - accuracy: 0.8073 - val_loss: 0.5691 - val_accuracy: 0.7552\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8090 - val_loss: 0.5691 - val_accuracy: 0.7500\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8090 - val_loss: 0.5691 - val_accuracy: 0.7500\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8090 - val_loss: 0.5690 - val_accuracy: 0.7500\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8090 - val_loss: 0.5694 - val_accuracy: 0.7500\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8090 - val_loss: 0.5696 - val_accuracy: 0.7552\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3929 - accuracy: 0.8108 - val_loss: 0.5695 - val_accuracy: 0.7500\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8073 - val_loss: 0.5698 - val_accuracy: 0.7500\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8125 - val_loss: 0.5695 - val_accuracy: 0.7500\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8108 - val_loss: 0.5695 - val_accuracy: 0.7448\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8073 - val_loss: 0.5695 - val_accuracy: 0.7448\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.8108 - val_loss: 0.5693 - val_accuracy: 0.7448\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3926 - accuracy: 0.8108 - val_loss: 0.5696 - val_accuracy: 0.7448\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8090 - val_loss: 0.5701 - val_accuracy: 0.7500\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8108 - val_loss: 0.5696 - val_accuracy: 0.7500\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8108 - val_loss: 0.5693 - val_accuracy: 0.7500\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8090 - val_loss: 0.5694 - val_accuracy: 0.7500\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8108 - val_loss: 0.5693 - val_accuracy: 0.7500\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8073 - val_loss: 0.5694 - val_accuracy: 0.7500\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8090 - val_loss: 0.5695 - val_accuracy: 0.7500\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3923 - accuracy: 0.8108 - val_loss: 0.5692 - val_accuracy: 0.7500\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3925 - accuracy: 0.8108 - val_loss: 0.5694 - val_accuracy: 0.7500\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.8108 - val_loss: 0.5695 - val_accuracy: 0.7500\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.8108 - val_loss: 0.5699 - val_accuracy: 0.7500\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8090 - val_loss: 0.5697 - val_accuracy: 0.7500\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8108 - val_loss: 0.5697 - val_accuracy: 0.7500\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8090 - val_loss: 0.5700 - val_accuracy: 0.7500\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.8125 - val_loss: 0.5703 - val_accuracy: 0.7500\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8073 - val_loss: 0.5700 - val_accuracy: 0.7500\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3922 - accuracy: 0.8108 - val_loss: 0.5700 - val_accuracy: 0.7500\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3921 - accuracy: 0.8108 - val_loss: 0.5700 - val_accuracy: 0.7500\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8090 - val_loss: 0.5701 - val_accuracy: 0.7500\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8090 - val_loss: 0.5704 - val_accuracy: 0.7500\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8090 - val_loss: 0.5704 - val_accuracy: 0.7500\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8090 - val_loss: 0.5701 - val_accuracy: 0.7500\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.8090 - val_loss: 0.5701 - val_accuracy: 0.7500\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.8125 - val_loss: 0.5700 - val_accuracy: 0.7500\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8073 - val_loss: 0.5701 - val_accuracy: 0.7500\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3921 - accuracy: 0.8090 - val_loss: 0.5704 - val_accuracy: 0.7500\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3921 - accuracy: 0.8125 - val_loss: 0.5702 - val_accuracy: 0.7500\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8108 - val_loss: 0.5703 - val_accuracy: 0.7500\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8108 - val_loss: 0.5703 - val_accuracy: 0.7500\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8108 - val_loss: 0.5702 - val_accuracy: 0.7500\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8108 - val_loss: 0.5702 - val_accuracy: 0.7500\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8108 - val_loss: 0.5707 - val_accuracy: 0.7500\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.8090 - val_loss: 0.5708 - val_accuracy: 0.7500\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3920 - accuracy: 0.8090 - val_loss: 0.5706 - val_accuracy: 0.7500\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8090 - val_loss: 0.5708 - val_accuracy: 0.7500\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8090 - val_loss: 0.5709 - val_accuracy: 0.7500\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8090 - val_loss: 0.5709 - val_accuracy: 0.7500\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8125 - val_loss: 0.5706 - val_accuracy: 0.7500\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8090 - val_loss: 0.5706 - val_accuracy: 0.7500\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8108 - val_loss: 0.5711 - val_accuracy: 0.7500\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8108 - val_loss: 0.5710 - val_accuracy: 0.7500\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8108 - val_loss: 0.5717 - val_accuracy: 0.7500\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.8090 - val_loss: 0.5712 - val_accuracy: 0.7500\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.8073 - val_loss: 0.5710 - val_accuracy: 0.7500\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8090 - val_loss: 0.5712 - val_accuracy: 0.7500\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8090 - val_loss: 0.5714 - val_accuracy: 0.7500\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8073 - val_loss: 0.5714 - val_accuracy: 0.7500\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8090 - val_loss: 0.5714 - val_accuracy: 0.7500\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8125 - val_loss: 0.5715 - val_accuracy: 0.7500\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8090 - val_loss: 0.5717 - val_accuracy: 0.7500\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8108 - val_loss: 0.5715 - val_accuracy: 0.7500\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.8108 - val_loss: 0.5719 - val_accuracy: 0.7500\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8073 - val_loss: 0.5718 - val_accuracy: 0.7500\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8090 - val_loss: 0.5720 - val_accuracy: 0.7500\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8090 - val_loss: 0.5723 - val_accuracy: 0.7500\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8073 - val_loss: 0.5723 - val_accuracy: 0.7500\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8090 - val_loss: 0.5719 - val_accuracy: 0.7500\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8090 - val_loss: 0.5724 - val_accuracy: 0.7500\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8056 - val_loss: 0.5725 - val_accuracy: 0.7500\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3912 - accuracy: 0.8073 - val_loss: 0.5722 - val_accuracy: 0.7500\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3912 - accuracy: 0.8056 - val_loss: 0.5721 - val_accuracy: 0.7500\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.8073 - val_loss: 0.5723 - val_accuracy: 0.7500\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8073 - val_loss: 0.5723 - val_accuracy: 0.7500\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8090 - val_loss: 0.5725 - val_accuracy: 0.7500\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8090 - val_loss: 0.5724 - val_accuracy: 0.7500\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8073 - val_loss: 0.5725 - val_accuracy: 0.7500\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8090 - val_loss: 0.5728 - val_accuracy: 0.7500\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8038 - val_loss: 0.5727 - val_accuracy: 0.7500\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8073 - val_loss: 0.5732 - val_accuracy: 0.7500\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3911 - accuracy: 0.8056 - val_loss: 0.5727 - val_accuracy: 0.7500\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8073 - val_loss: 0.5729 - val_accuracy: 0.7500\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3909 - accuracy: 0.8038 - val_loss: 0.5732 - val_accuracy: 0.7500\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8073 - val_loss: 0.5731 - val_accuracy: 0.7500\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8073 - val_loss: 0.5731 - val_accuracy: 0.7500\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8056 - val_loss: 0.5732 - val_accuracy: 0.7500\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8056 - val_loss: 0.5734 - val_accuracy: 0.7500\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8056 - val_loss: 0.5735 - val_accuracy: 0.7500\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8056 - val_loss: 0.5732 - val_accuracy: 0.7500\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3910 - accuracy: 0.8073 - val_loss: 0.5734 - val_accuracy: 0.7500\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8056 - val_loss: 0.5733 - val_accuracy: 0.7500\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8038 - val_loss: 0.5737 - val_accuracy: 0.7500\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3909 - accuracy: 0.8056 - val_loss: 0.5737 - val_accuracy: 0.7500\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8056 - val_loss: 0.5734 - val_accuracy: 0.7500\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8073 - val_loss: 0.5733 - val_accuracy: 0.7500\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8073 - val_loss: 0.5734 - val_accuracy: 0.7500\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8056 - val_loss: 0.5734 - val_accuracy: 0.7500\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8056 - val_loss: 0.5738 - val_accuracy: 0.7500\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3909 - accuracy: 0.8021 - val_loss: 0.5735 - val_accuracy: 0.7500\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3906 - accuracy: 0.8038 - val_loss: 0.5739 - val_accuracy: 0.7500\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8073 - val_loss: 0.5738 - val_accuracy: 0.7500\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3907 - accuracy: 0.8073 - val_loss: 0.5740 - val_accuracy: 0.7500\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3907 - accuracy: 0.8056 - val_loss: 0.5742 - val_accuracy: 0.7500\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8038 - val_loss: 0.5742 - val_accuracy: 0.7500\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3905 - accuracy: 0.8073 - val_loss: 0.5741 - val_accuracy: 0.7500\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8056 - val_loss: 0.5743 - val_accuracy: 0.7500\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8056 - val_loss: 0.5742 - val_accuracy: 0.7500\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8073 - val_loss: 0.5740 - val_accuracy: 0.7500\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8090 - val_loss: 0.5737 - val_accuracy: 0.7500\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8056 - val_loss: 0.5741 - val_accuracy: 0.7500\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8038 - val_loss: 0.5739 - val_accuracy: 0.7500\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8073 - val_loss: 0.5740 - val_accuracy: 0.7500\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8056 - val_loss: 0.5740 - val_accuracy: 0.7500\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8038 - val_loss: 0.5740 - val_accuracy: 0.7500\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8056 - val_loss: 0.5743 - val_accuracy: 0.7500\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3904 - accuracy: 0.8056 - val_loss: 0.5740 - val_accuracy: 0.7500\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8056 - val_loss: 0.5742 - val_accuracy: 0.7500\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8038 - val_loss: 0.5746 - val_accuracy: 0.7500\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8056 - val_loss: 0.5744 - val_accuracy: 0.7500\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8056 - val_loss: 0.5745 - val_accuracy: 0.7500\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8038 - val_loss: 0.5744 - val_accuracy: 0.7500\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8056 - val_loss: 0.5753 - val_accuracy: 0.7500\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.8038 - val_loss: 0.5751 - val_accuracy: 0.7500\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3902 - accuracy: 0.8021 - val_loss: 0.5752 - val_accuracy: 0.7500\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8038 - val_loss: 0.5745 - val_accuracy: 0.7552\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3903 - accuracy: 0.8038 - val_loss: 0.5750 - val_accuracy: 0.7500\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3903 - accuracy: 0.8056 - val_loss: 0.5749 - val_accuracy: 0.7500\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3905 - accuracy: 0.8021 - val_loss: 0.5747 - val_accuracy: 0.7552\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3903 - accuracy: 0.8056 - val_loss: 0.5751 - val_accuracy: 0.7500\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8056 - val_loss: 0.5751 - val_accuracy: 0.7552\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8056 - val_loss: 0.5754 - val_accuracy: 0.7500\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8056 - val_loss: 0.5751 - val_accuracy: 0.7552\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8038 - val_loss: 0.5752 - val_accuracy: 0.7552\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3900 - accuracy: 0.8038 - val_loss: 0.5751 - val_accuracy: 0.7552\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8038 - val_loss: 0.5749 - val_accuracy: 0.7552\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8038 - val_loss: 0.5748 - val_accuracy: 0.7552\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8038 - val_loss: 0.5749 - val_accuracy: 0.7552\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.8038 - val_loss: 0.5752 - val_accuracy: 0.7552\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3901 - accuracy: 0.8038 - val_loss: 0.5755 - val_accuracy: 0.7552\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8056 - val_loss: 0.5754 - val_accuracy: 0.7552\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3899 - accuracy: 0.8038 - val_loss: 0.5749 - val_accuracy: 0.7552\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8038 - val_loss: 0.5755 - val_accuracy: 0.7552\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8073 - val_loss: 0.5752 - val_accuracy: 0.7552\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.8038 - val_loss: 0.5753 - val_accuracy: 0.7552\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3899 - accuracy: 0.8038 - val_loss: 0.5755 - val_accuracy: 0.7552\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3898 - accuracy: 0.8038 - val_loss: 0.5757 - val_accuracy: 0.7552\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8021 - val_loss: 0.5755 - val_accuracy: 0.7552\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.8038 - val_loss: 0.5755 - val_accuracy: 0.7552\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3898 - accuracy: 0.8003 - val_loss: 0.5755 - val_accuracy: 0.7552\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8073 - val_loss: 0.5750 - val_accuracy: 0.7552\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3897 - accuracy: 0.8021 - val_loss: 0.5756 - val_accuracy: 0.7552\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8038 - val_loss: 0.5757 - val_accuracy: 0.7552\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3897 - accuracy: 0.8021 - val_loss: 0.5757 - val_accuracy: 0.7552\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3898 - accuracy: 0.8038 - val_loss: 0.5756 - val_accuracy: 0.7552\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8038 - val_loss: 0.5758 - val_accuracy: 0.7552\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8021 - val_loss: 0.5757 - val_accuracy: 0.7552\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3896 - accuracy: 0.8021 - val_loss: 0.5758 - val_accuracy: 0.7552\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8021 - val_loss: 0.5760 - val_accuracy: 0.7552\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3898 - accuracy: 0.8021 - val_loss: 0.5758 - val_accuracy: 0.7552\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3898 - accuracy: 0.8003 - val_loss: 0.5760 - val_accuracy: 0.7552\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8038 - val_loss: 0.5760 - val_accuracy: 0.7552\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8003 - val_loss: 0.5761 - val_accuracy: 0.7552\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8038 - val_loss: 0.5761 - val_accuracy: 0.7552\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3895 - accuracy: 0.8003 - val_loss: 0.5766 - val_accuracy: 0.7552\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3895 - accuracy: 0.8021 - val_loss: 0.5763 - val_accuracy: 0.7552\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3895 - accuracy: 0.8003 - val_loss: 0.5766 - val_accuracy: 0.7552\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8038 - val_loss: 0.5763 - val_accuracy: 0.7552\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8021 - val_loss: 0.5764 - val_accuracy: 0.7552\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8038 - val_loss: 0.5766 - val_accuracy: 0.7552\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3895 - accuracy: 0.8021 - val_loss: 0.5764 - val_accuracy: 0.7552\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8056 - val_loss: 0.5768 - val_accuracy: 0.7552\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3894 - accuracy: 0.8038 - val_loss: 0.5766 - val_accuracy: 0.7552\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3896 - accuracy: 0.8021 - val_loss: 0.5769 - val_accuracy: 0.7552\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3896 - accuracy: 0.8038 - val_loss: 0.5768 - val_accuracy: 0.7552\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8003 - val_loss: 0.5766 - val_accuracy: 0.7552\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.8003 - val_loss: 0.5765 - val_accuracy: 0.7552\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8021 - val_loss: 0.5765 - val_accuracy: 0.7552\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8003 - val_loss: 0.5772 - val_accuracy: 0.7552\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3895 - accuracy: 0.8038 - val_loss: 0.5765 - val_accuracy: 0.7552\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8021 - val_loss: 0.5765 - val_accuracy: 0.7552\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.7986 - val_loss: 0.5772 - val_accuracy: 0.7552\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8021 - val_loss: 0.5767 - val_accuracy: 0.7552\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8021 - val_loss: 0.5766 - val_accuracy: 0.7552\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8021 - val_loss: 0.5767 - val_accuracy: 0.7552\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8038 - val_loss: 0.5766 - val_accuracy: 0.7552\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8038 - val_loss: 0.5764 - val_accuracy: 0.7552\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8021 - val_loss: 0.5764 - val_accuracy: 0.7552\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.8003 - val_loss: 0.5765 - val_accuracy: 0.7552\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8003 - val_loss: 0.5763 - val_accuracy: 0.7552\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8003 - val_loss: 0.5768 - val_accuracy: 0.7552\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8003 - val_loss: 0.5770 - val_accuracy: 0.7552\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.8038 - val_loss: 0.5768 - val_accuracy: 0.7552\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8003 - val_loss: 0.5768 - val_accuracy: 0.7552\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8021 - val_loss: 0.5766 - val_accuracy: 0.7552\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8003 - val_loss: 0.5765 - val_accuracy: 0.7552\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8021 - val_loss: 0.5762 - val_accuracy: 0.7552\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8021 - val_loss: 0.5769 - val_accuracy: 0.7552\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8021 - val_loss: 0.5770 - val_accuracy: 0.7552\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8021 - val_loss: 0.5765 - val_accuracy: 0.7552\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8021 - val_loss: 0.5767 - val_accuracy: 0.7552\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3889 - accuracy: 0.8021 - val_loss: 0.5766 - val_accuracy: 0.7552\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3888 - accuracy: 0.8003 - val_loss: 0.5767 - val_accuracy: 0.7552\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8021 - val_loss: 0.5765 - val_accuracy: 0.7552\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8038 - val_loss: 0.5767 - val_accuracy: 0.7552\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8021 - val_loss: 0.5766 - val_accuracy: 0.7552\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8003 - val_loss: 0.5765 - val_accuracy: 0.7552\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.8021 - val_loss: 0.5768 - val_accuracy: 0.7552\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8003 - val_loss: 0.5766 - val_accuracy: 0.7552\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3885 - accuracy: 0.8003 - val_loss: 0.5766 - val_accuracy: 0.7552\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8003 - val_loss: 0.5767 - val_accuracy: 0.7552\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8021 - val_loss: 0.5766 - val_accuracy: 0.7552\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8021 - val_loss: 0.5767 - val_accuracy: 0.7552\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8038 - val_loss: 0.5768 - val_accuracy: 0.7552\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8021 - val_loss: 0.5772 - val_accuracy: 0.7552\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8021 - val_loss: 0.5772 - val_accuracy: 0.7552\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8021 - val_loss: 0.5771 - val_accuracy: 0.7552\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8021 - val_loss: 0.5772 - val_accuracy: 0.7552\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8021 - val_loss: 0.5772 - val_accuracy: 0.7552\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8021 - val_loss: 0.5770 - val_accuracy: 0.7552\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8038 - val_loss: 0.5773 - val_accuracy: 0.7552\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8021 - val_loss: 0.5773 - val_accuracy: 0.7552\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8056 - val_loss: 0.5780 - val_accuracy: 0.7552\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8021 - val_loss: 0.5779 - val_accuracy: 0.7552\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8038 - val_loss: 0.5776 - val_accuracy: 0.7552\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8021 - val_loss: 0.5779 - val_accuracy: 0.7552\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8038 - val_loss: 0.5775 - val_accuracy: 0.7552\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8021 - val_loss: 0.5781 - val_accuracy: 0.7552\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8056 - val_loss: 0.5781 - val_accuracy: 0.7552\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8038 - val_loss: 0.5783 - val_accuracy: 0.7552\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3882 - accuracy: 0.8038 - val_loss: 0.5779 - val_accuracy: 0.7552\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8021 - val_loss: 0.5781 - val_accuracy: 0.7552\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.8021 - val_loss: 0.5780 - val_accuracy: 0.7552\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.8056 - val_loss: 0.5783 - val_accuracy: 0.7552\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8038 - val_loss: 0.5782 - val_accuracy: 0.7552\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8021 - val_loss: 0.5783 - val_accuracy: 0.7552\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8038 - val_loss: 0.5783 - val_accuracy: 0.7552\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8056 - val_loss: 0.5781 - val_accuracy: 0.7552\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8056 - val_loss: 0.5782 - val_accuracy: 0.7552\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8038 - val_loss: 0.5784 - val_accuracy: 0.7552\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8056 - val_loss: 0.5784 - val_accuracy: 0.7552\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8056 - val_loss: 0.5784 - val_accuracy: 0.7500\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8038 - val_loss: 0.5783 - val_accuracy: 0.7500\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8038 - val_loss: 0.5789 - val_accuracy: 0.7552\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8056 - val_loss: 0.5784 - val_accuracy: 0.7500\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8021 - val_loss: 0.5790 - val_accuracy: 0.7552\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8056 - val_loss: 0.5787 - val_accuracy: 0.7552\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8038 - val_loss: 0.5788 - val_accuracy: 0.7552\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8038 - val_loss: 0.5791 - val_accuracy: 0.7552\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8090 - val_loss: 0.5789 - val_accuracy: 0.7552\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8056 - val_loss: 0.5790 - val_accuracy: 0.7552\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8056 - val_loss: 0.5791 - val_accuracy: 0.7500\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8021 - val_loss: 0.5790 - val_accuracy: 0.7552\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8038 - val_loss: 0.5791 - val_accuracy: 0.7552\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8038 - val_loss: 0.5791 - val_accuracy: 0.7552\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8056 - val_loss: 0.5788 - val_accuracy: 0.7500\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8038 - val_loss: 0.5789 - val_accuracy: 0.7500\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.8021 - val_loss: 0.5792 - val_accuracy: 0.7500\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8038 - val_loss: 0.5795 - val_accuracy: 0.7500\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8038 - val_loss: 0.5792 - val_accuracy: 0.7500\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8056 - val_loss: 0.5794 - val_accuracy: 0.7500\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8056 - val_loss: 0.5792 - val_accuracy: 0.7500\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8038 - val_loss: 0.5793 - val_accuracy: 0.7500\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8056 - val_loss: 0.5794 - val_accuracy: 0.7552\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8038 - val_loss: 0.5794 - val_accuracy: 0.7552\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3877 - accuracy: 0.8038 - val_loss: 0.5795 - val_accuracy: 0.7500\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8038 - val_loss: 0.5794 - val_accuracy: 0.7500\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3878 - accuracy: 0.8038 - val_loss: 0.5794 - val_accuracy: 0.7448\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8038 - val_loss: 0.5799 - val_accuracy: 0.7500\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8038 - val_loss: 0.5797 - val_accuracy: 0.7500\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3876 - accuracy: 0.8038 - val_loss: 0.5801 - val_accuracy: 0.7500\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8056 - val_loss: 0.5798 - val_accuracy: 0.7448\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8021 - val_loss: 0.5798 - val_accuracy: 0.7448\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8038 - val_loss: 0.5798 - val_accuracy: 0.7448\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.8056 - val_loss: 0.5798 - val_accuracy: 0.7500\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8038 - val_loss: 0.5799 - val_accuracy: 0.7448\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8038 - val_loss: 0.5803 - val_accuracy: 0.7500\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8038 - val_loss: 0.5802 - val_accuracy: 0.7500\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3876 - accuracy: 0.8038 - val_loss: 0.5802 - val_accuracy: 0.7500\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8038 - val_loss: 0.5803 - val_accuracy: 0.7500\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8038 - val_loss: 0.5802 - val_accuracy: 0.7500\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8038 - val_loss: 0.5799 - val_accuracy: 0.7500\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8056 - val_loss: 0.5797 - val_accuracy: 0.7500\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3873 - accuracy: 0.8038 - val_loss: 0.5799 - val_accuracy: 0.7500\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.8021 - val_loss: 0.5807 - val_accuracy: 0.7500\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.8038 - val_loss: 0.5804 - val_accuracy: 0.7500\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.8056 - val_loss: 0.5806 - val_accuracy: 0.7500\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3873 - accuracy: 0.8056 - val_loss: 0.5806 - val_accuracy: 0.7500\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8021 - val_loss: 0.5806 - val_accuracy: 0.7500\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.8056 - val_loss: 0.5807 - val_accuracy: 0.7500\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8056 - val_loss: 0.5807 - val_accuracy: 0.7500\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.8038 - val_loss: 0.5807 - val_accuracy: 0.7500\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8056 - val_loss: 0.5805 - val_accuracy: 0.7500\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3872 - accuracy: 0.8038 - val_loss: 0.5808 - val_accuracy: 0.7500\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.8021 - val_loss: 0.5807 - val_accuracy: 0.7500\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.8038 - val_loss: 0.5808 - val_accuracy: 0.7500\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3872 - accuracy: 0.8056 - val_loss: 0.5808 - val_accuracy: 0.7500\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.8056 - val_loss: 0.5810 - val_accuracy: 0.7500\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.8038 - val_loss: 0.5807 - val_accuracy: 0.7500\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8038 - val_loss: 0.5807 - val_accuracy: 0.7500\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8021 - val_loss: 0.5809 - val_accuracy: 0.7500\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3870 - accuracy: 0.8038 - val_loss: 0.5813 - val_accuracy: 0.7500\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.8038 - val_loss: 0.5812 - val_accuracy: 0.7500\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8038 - val_loss: 0.5808 - val_accuracy: 0.7500\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8038 - val_loss: 0.5812 - val_accuracy: 0.7500\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.8021 - val_loss: 0.5816 - val_accuracy: 0.7500\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8038 - val_loss: 0.5814 - val_accuracy: 0.7500\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8038 - val_loss: 0.5815 - val_accuracy: 0.7500\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3869 - accuracy: 0.8003 - val_loss: 0.5812 - val_accuracy: 0.7500\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3870 - accuracy: 0.8021 - val_loss: 0.5815 - val_accuracy: 0.7500\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3870 - accuracy: 0.8003 - val_loss: 0.5817 - val_accuracy: 0.7500\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8021 - val_loss: 0.5819 - val_accuracy: 0.7500\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3867 - accuracy: 0.8056 - val_loss: 0.5819 - val_accuracy: 0.7500\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8021 - val_loss: 0.5818 - val_accuracy: 0.7500\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.8038 - val_loss: 0.5815 - val_accuracy: 0.7500\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3868 - accuracy: 0.8021 - val_loss: 0.5818 - val_accuracy: 0.7500\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8003 - val_loss: 0.5815 - val_accuracy: 0.7500\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8038 - val_loss: 0.5814 - val_accuracy: 0.7500\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.8056 - val_loss: 0.5819 - val_accuracy: 0.7500\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8056 - val_loss: 0.5823 - val_accuracy: 0.7500\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3868 - accuracy: 0.8038 - val_loss: 0.5824 - val_accuracy: 0.7500\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8038 - val_loss: 0.5820 - val_accuracy: 0.7500\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8003 - val_loss: 0.5820 - val_accuracy: 0.7500\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8021 - val_loss: 0.5822 - val_accuracy: 0.7500\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8003 - val_loss: 0.5817 - val_accuracy: 0.7500\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3867 - accuracy: 0.8021 - val_loss: 0.5815 - val_accuracy: 0.7500\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8003 - val_loss: 0.5818 - val_accuracy: 0.7500\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8021 - val_loss: 0.5819 - val_accuracy: 0.7500\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8038 - val_loss: 0.5821 - val_accuracy: 0.7500\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8021 - val_loss: 0.5822 - val_accuracy: 0.7500\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8038 - val_loss: 0.5820 - val_accuracy: 0.7500\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8021 - val_loss: 0.5819 - val_accuracy: 0.7500\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8003 - val_loss: 0.5822 - val_accuracy: 0.7500\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8038 - val_loss: 0.5825 - val_accuracy: 0.7500\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8003 - val_loss: 0.5822 - val_accuracy: 0.7500\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3867 - accuracy: 0.8038 - val_loss: 0.5824 - val_accuracy: 0.7500\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8003 - val_loss: 0.5826 - val_accuracy: 0.7500\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8021 - val_loss: 0.5827 - val_accuracy: 0.7500\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8021 - val_loss: 0.5830 - val_accuracy: 0.7500\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8021 - val_loss: 0.5832 - val_accuracy: 0.7500\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8003 - val_loss: 0.5830 - val_accuracy: 0.7500\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8021 - val_loss: 0.5833 - val_accuracy: 0.7500\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8038 - val_loss: 0.5832 - val_accuracy: 0.7500\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8038 - val_loss: 0.5829 - val_accuracy: 0.7500\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8003 - val_loss: 0.5830 - val_accuracy: 0.7500\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8021 - val_loss: 0.5830 - val_accuracy: 0.7500\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8003 - val_loss: 0.5829 - val_accuracy: 0.7500\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8021 - val_loss: 0.5830 - val_accuracy: 0.7500\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8003 - val_loss: 0.5830 - val_accuracy: 0.7500\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3865 - accuracy: 0.8038 - val_loss: 0.5830 - val_accuracy: 0.7500\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3865 - accuracy: 0.8038 - val_loss: 0.5828 - val_accuracy: 0.7500\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8021 - val_loss: 0.5829 - val_accuracy: 0.7500\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8021 - val_loss: 0.5827 - val_accuracy: 0.7500\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8021 - val_loss: 0.5833 - val_accuracy: 0.7500\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8003 - val_loss: 0.5835 - val_accuracy: 0.7500\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8021 - val_loss: 0.5830 - val_accuracy: 0.7500\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8021 - val_loss: 0.5832 - val_accuracy: 0.7500\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8021 - val_loss: 0.5829 - val_accuracy: 0.7552\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8038 - val_loss: 0.5831 - val_accuracy: 0.7500\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3865 - accuracy: 0.8021 - val_loss: 0.5838 - val_accuracy: 0.7500\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8003 - val_loss: 0.5835 - val_accuracy: 0.7500\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8021 - val_loss: 0.5834 - val_accuracy: 0.7500\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8038 - val_loss: 0.5835 - val_accuracy: 0.7500\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8021 - val_loss: 0.5838 - val_accuracy: 0.7500\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3867 - accuracy: 0.8021 - val_loss: 0.5835 - val_accuracy: 0.7552\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8021 - val_loss: 0.5834 - val_accuracy: 0.7500\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8021 - val_loss: 0.5839 - val_accuracy: 0.7500\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3865 - accuracy: 0.8056 - val_loss: 0.5837 - val_accuracy: 0.7500\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8003 - val_loss: 0.5835 - val_accuracy: 0.7500\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8021 - val_loss: 0.5834 - val_accuracy: 0.7500\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3865 - accuracy: 0.8003 - val_loss: 0.5839 - val_accuracy: 0.7500\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8021 - val_loss: 0.5837 - val_accuracy: 0.7500\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8021 - val_loss: 0.5839 - val_accuracy: 0.7500\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8038 - val_loss: 0.5839 - val_accuracy: 0.7500\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8038 - val_loss: 0.5842 - val_accuracy: 0.7500\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8021 - val_loss: 0.5838 - val_accuracy: 0.7500\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3865 - accuracy: 0.8021 - val_loss: 0.5839 - val_accuracy: 0.7500\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8003 - val_loss: 0.5839 - val_accuracy: 0.7500\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8021 - val_loss: 0.5838 - val_accuracy: 0.7500\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8021 - val_loss: 0.5844 - val_accuracy: 0.7500\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8038 - val_loss: 0.5842 - val_accuracy: 0.7500\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8021 - val_loss: 0.5846 - val_accuracy: 0.7500\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8003 - val_loss: 0.5844 - val_accuracy: 0.7500\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8056 - val_loss: 0.5846 - val_accuracy: 0.7500\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8021 - val_loss: 0.5844 - val_accuracy: 0.7500\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8003 - val_loss: 0.5845 - val_accuracy: 0.7500\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.8003 - val_loss: 0.5844 - val_accuracy: 0.7552\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8038 - val_loss: 0.5844 - val_accuracy: 0.7500\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8056 - val_loss: 0.5850 - val_accuracy: 0.7500\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.8038 - val_loss: 0.5846 - val_accuracy: 0.7500\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.8003 - val_loss: 0.5848 - val_accuracy: 0.7500\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8038 - val_loss: 0.5848 - val_accuracy: 0.7500\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8003 - val_loss: 0.5845 - val_accuracy: 0.7500\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8056 - val_loss: 0.5846 - val_accuracy: 0.7500\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.7986 - val_loss: 0.5845 - val_accuracy: 0.7500\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3864 - accuracy: 0.8003 - val_loss: 0.5850 - val_accuracy: 0.7500\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8021 - val_loss: 0.5851 - val_accuracy: 0.7500\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8038 - val_loss: 0.5850 - val_accuracy: 0.7500\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8021 - val_loss: 0.5847 - val_accuracy: 0.7552\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3863 - accuracy: 0.8038 - val_loss: 0.5851 - val_accuracy: 0.7500\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.7986 - val_loss: 0.5853 - val_accuracy: 0.7500\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8021 - val_loss: 0.5856 - val_accuracy: 0.7500\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8021 - val_loss: 0.5851 - val_accuracy: 0.7500\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.8021 - val_loss: 0.5850 - val_accuracy: 0.7500\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8021 - val_loss: 0.5851 - val_accuracy: 0.7500\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8038 - val_loss: 0.5852 - val_accuracy: 0.7500\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8003 - val_loss: 0.5848 - val_accuracy: 0.7448\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8038 - val_loss: 0.5848 - val_accuracy: 0.7448\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8038 - val_loss: 0.5852 - val_accuracy: 0.7448\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8056 - val_loss: 0.5848 - val_accuracy: 0.7500\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8003 - val_loss: 0.5855 - val_accuracy: 0.7500\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8021 - val_loss: 0.5853 - val_accuracy: 0.7500\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.8021 - val_loss: 0.5852 - val_accuracy: 0.7448\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8021 - val_loss: 0.5852 - val_accuracy: 0.7448\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8003 - val_loss: 0.5852 - val_accuracy: 0.7448\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8021 - val_loss: 0.5852 - val_accuracy: 0.7448\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.8003 - val_loss: 0.5851 - val_accuracy: 0.7448\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8021 - val_loss: 0.5854 - val_accuracy: 0.7448\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8038 - val_loss: 0.5856 - val_accuracy: 0.7448\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8003 - val_loss: 0.5855 - val_accuracy: 0.7500\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8021 - val_loss: 0.5855 - val_accuracy: 0.7448\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8021 - val_loss: 0.5854 - val_accuracy: 0.7448\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8056 - val_loss: 0.5853 - val_accuracy: 0.7448\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8056 - val_loss: 0.5859 - val_accuracy: 0.7448\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8021 - val_loss: 0.5856 - val_accuracy: 0.7448\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8038 - val_loss: 0.5856 - val_accuracy: 0.7448\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.8003 - val_loss: 0.5857 - val_accuracy: 0.7448\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3860 - accuracy: 0.8038 - val_loss: 0.5860 - val_accuracy: 0.7448\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3857 - accuracy: 0.8003 - val_loss: 0.5858 - val_accuracy: 0.7448\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3858 - accuracy: 0.8021 - val_loss: 0.5858 - val_accuracy: 0.7448\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3859 - accuracy: 0.7986 - val_loss: 0.5856 - val_accuracy: 0.7448\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3858 - accuracy: 0.8003 - val_loss: 0.5860 - val_accuracy: 0.7448\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.8021 - val_loss: 0.5859 - val_accuracy: 0.7500\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8003 - val_loss: 0.5860 - val_accuracy: 0.7500\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3860 - accuracy: 0.8021 - val_loss: 0.5861 - val_accuracy: 0.7448\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3860 - accuracy: 0.8056 - val_loss: 0.5859 - val_accuracy: 0.7500\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.8021 - val_loss: 0.5859 - val_accuracy: 0.7448\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8056 - val_loss: 0.5858 - val_accuracy: 0.7500\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8021 - val_loss: 0.5855 - val_accuracy: 0.7500\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.8021 - val_loss: 0.5860 - val_accuracy: 0.7500\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8003 - val_loss: 0.5863 - val_accuracy: 0.7500\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3857 - accuracy: 0.8003 - val_loss: 0.5863 - val_accuracy: 0.7500\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3856 - accuracy: 0.8038 - val_loss: 0.5864 - val_accuracy: 0.7500\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3856 - accuracy: 0.8021 - val_loss: 0.5864 - val_accuracy: 0.7500\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3856 - accuracy: 0.8021 - val_loss: 0.5865 - val_accuracy: 0.7500\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3857 - accuracy: 0.8021 - val_loss: 0.5861 - val_accuracy: 0.7500\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3859 - accuracy: 0.8056 - val_loss: 0.5864 - val_accuracy: 0.7500\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3856 - accuracy: 0.8038 - val_loss: 0.5861 - val_accuracy: 0.7500\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3856 - accuracy: 0.8038 - val_loss: 0.5866 - val_accuracy: 0.7500\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8056 - val_loss: 0.5866 - val_accuracy: 0.7500\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8021 - val_loss: 0.5864 - val_accuracy: 0.7500\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.8038 - val_loss: 0.5867 - val_accuracy: 0.7500\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8056 - val_loss: 0.5866 - val_accuracy: 0.7500\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8021 - val_loss: 0.5865 - val_accuracy: 0.7500\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3857 - accuracy: 0.8038 - val_loss: 0.5867 - val_accuracy: 0.7448\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8021 - val_loss: 0.5867 - val_accuracy: 0.7500\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.8038 - val_loss: 0.5865 - val_accuracy: 0.7500\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.8021 - val_loss: 0.5875 - val_accuracy: 0.7500\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8021 - val_loss: 0.5872 - val_accuracy: 0.7500\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8021 - val_loss: 0.5872 - val_accuracy: 0.7500\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8003 - val_loss: 0.5870 - val_accuracy: 0.7500\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8038 - val_loss: 0.5870 - val_accuracy: 0.7500\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8038 - val_loss: 0.5865 - val_accuracy: 0.7500\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3857 - accuracy: 0.8021 - val_loss: 0.5871 - val_accuracy: 0.7500\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8021 - val_loss: 0.5870 - val_accuracy: 0.7500\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8021 - val_loss: 0.5873 - val_accuracy: 0.7500\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8021 - val_loss: 0.5874 - val_accuracy: 0.7500\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.8038 - val_loss: 0.5877 - val_accuracy: 0.7500\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8021 - val_loss: 0.5877 - val_accuracy: 0.7500\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8021 - val_loss: 0.5873 - val_accuracy: 0.7500\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.8021 - val_loss: 0.5875 - val_accuracy: 0.7500\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8021 - val_loss: 0.5879 - val_accuracy: 0.7500\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.8056 - val_loss: 0.5875 - val_accuracy: 0.7500\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8021 - val_loss: 0.5873 - val_accuracy: 0.7500\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.8021 - val_loss: 0.5874 - val_accuracy: 0.7500\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8056 - val_loss: 0.5876 - val_accuracy: 0.7500\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.8056 - val_loss: 0.5871 - val_accuracy: 0.7500\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8038 - val_loss: 0.5871 - val_accuracy: 0.7500\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.8056 - val_loss: 0.5877 - val_accuracy: 0.7500\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.8056 - val_loss: 0.5876 - val_accuracy: 0.7500\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8038 - val_loss: 0.5878 - val_accuracy: 0.7500\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.8038 - val_loss: 0.5874 - val_accuracy: 0.7500\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.8021 - val_loss: 0.5879 - val_accuracy: 0.7500\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.8003 - val_loss: 0.5878 - val_accuracy: 0.7500\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8038 - val_loss: 0.5881 - val_accuracy: 0.7500\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.8038 - val_loss: 0.5881 - val_accuracy: 0.7500\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3853 - accuracy: 0.8021 - val_loss: 0.5882 - val_accuracy: 0.7500\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.8056 - val_loss: 0.5882 - val_accuracy: 0.7500\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8038 - val_loss: 0.5881 - val_accuracy: 0.7500\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3854 - accuracy: 0.8003 - val_loss: 0.5887 - val_accuracy: 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSZ9JHBFAv_a",
        "outputId": "be074d56-1416-47fd-8c40-1b602ec5b2a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n",
            "accuracy is 0.641\n",
            "roc-auc is 0.783\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAKqCAYAAADsTEzZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABy6UlEQVR4nO3deZyNdeP/8ffsCwYxxlqWyFYRkeJGYSoplYwlW9ZQaopsEWJERHaFKYwZSVLNjYncJaQspexb1rEzzJj1XL8/+s75NWYx+3WW1/Px6HHfc811nfMen3N4z+dzXddxMQzDEAAAAGASV7MDAAAAwLlRSAEAAGAqCikAAABMRSEFAACAqSikAAAAMBWFFAAAAKaikAIAAMBUFFIAAACYikIKAAAAU1FIAWRq6tSpqlq1qtzc3FSvXj2z48CG9OzZU5UrV06zzcXFRe+9916OHys0NFQuLi767bff8iecE2nRooXq1q17x/1OnDghFxcXhYaGFnwoIBcopLBZqf9Ipf7n7u6uChUqqGfPnjpz5kyGxxiGoaVLl+o///mPSpQoIV9fX91///0aP368YmNjM32ur776Sk899ZRKly4tT09PlS9fXh07dtSmTZuylTU+Pl4fffSRGjdurOLFi8vb21s1atTQ4MGDdejQoVz9/GbbsGGDhg0bpscee0xLlizRpEmTCvT5evbsKRcXFz3wwAPK6BONXVxcNHjwYOvXqf/Auri46Msvv0y3/3vvvScXFxddunSpQHNnV2qe1P98fX1Vu3ZtjR49WjExMdb9Mipnqce6urrq1KlT6R47JiZGPj4+6f6M/m3//v1ycXGRt7e3rl27lu8/n62JjIzMVTkGYA53swMAdzJ+/HhVqVJF8fHx2r59u0JDQ7Vlyxb9+eef8vb2tu6XkpKiLl26aOXKlWrWrJnee+89+fr66qefftK4ceP0xRdf6Pvvv1dAQID1GMMw9Morryg0NFT169dXcHCwypYtq3Pnzumrr77SE088oZ9//lmPPvpopvkuXbqkJ598Ujt37tQzzzyjLl26qGjRojp48KDCw8O1cOFCJSYmFuifUUHYtGmTXF1dtWjRInl6ehba8+7du1erV6/Wiy++mO1jxo8frxdeeEEuLi4FmCx/zJs3T0WLFtXNmze1YcMGTZw4UZs2bdLPP/98x/xeXl5asWKFhg0blmb76tWr7/i8y5YtU9myZXX16lWtWrVKffr0ydPPkZFbt27J3d02/lmJjIzUnDlzKKWAnbCNvzmALDz11FNq2LChJKlPnz4qXbq0PvjgA61du1YdO3a07jdlyhStXLlSb7/9tqZOnWrd3q9fP3Xs2FHt27dXz5499d///tf6vWnTpik0NFRvvPGGpk+fnqYQjBo1SkuXLr3jP7A9e/bU7t27tWrVqnQlasKECRo1alSefv5UycnJslgshVYOL1y4IB8fn3x7PsMwFB8fLx8fn0z38fHxUaVKlXJUMOvVq6c9e/boq6++0gsvvJAvWQtShw4dVLp0aUnSgAED9OKLL2r16tXavn27mjRpkuWxTz/9dIaFNCwsTG3bts1wplj6588+LCxMXbp00fHjx7V8+fICKaT//gURuRMbG6siRYqYHQModCzZw+40a9ZMknT06FHrtlu3bmnq1KmqUaOGQkJC0h3Trl079ejRQ+vWrdP27dutx4SEhKhmzZr68MMPMyw/3bp1U6NGjTLN8ssvv+i7775T7969M5zR8/Ly0ocffmj9ukWLFmrRokW6/W4/Hy91OfrDDz/UjBkzVK1aNXl5eWn37t1yd3fXuHHj0j3GwYMH5eLiotmzZ1u3Xbt2TW+88YYqVaokLy8v3Xvvvfrggw9ksVgy/Zmkf5bHlyxZotjYWOsSc+q5Z8nJyZowYYI1U+XKlTVy5EglJCSkeYzKlSvrmWee0fr169WwYUP5+PhowYIFWT6vq6urRo8erT/++ENfffVVlvum6tSpk2rUqKHx48dnuNSfHbt379ZTTz0lPz8/FS1aVE888YT1dZIqdSn9559/VnBwsPz9/VWkSBE9//zzunjxYq6eV5Ief/xxSdLx48fvuG+XLl20Z88eHThwwLotOjpamzZtUpcuXTI97ueff9aJEyfUqVMnderUST/++KNOnz6d7Yxr1qxR3bp15e3trbp162Y6NrefQ/r3339r4MCBuu++++Tj46NSpUrppZde0okTJzI8Pi4uTv3791epUqXk5+en7t276+rVq+n2++9//6tmzZqpSJEiKlasmNq2bau//vrL+v2ePXtqzpw51kyp/6WyWCyaMWOG6tSpI29vbwUEBKh///7pnuu3335TYGCgSpcuLR8fH1WpUkWvvPLKHf+8Ul/7GzZsUL169eTt7a3atWunm8lOfU3973//08CBA1WmTBlVrFjR+v25c+eqTp068vLyUvny5TVo0KBMT7fYuXOnHn30UWvO+fPn3zGnJB04cEAdOnTQXXfdJW9vbzVs2FBr167NMOeWLVv0+uuvy9/fXyVKlFD//v2VmJioa9euqXv37ipZsqRKliypYcOG5fq9COdFIYXdSf3HrGTJktZtW7Zs0dWrV9WlS5dMZzS7d+8uSfr222+tx1y5ckVdunSRm5tbrrKk/sXdrVu3XB1/J0uWLNGsWbPUr18/TZs2TeXKlVPz5s21cuXKdPtGRETIzc1NL730kqR//nFv3ry5li1bpu7du+vjjz/WY489phEjRig4ODjL5126dKmaNWsmLy8vLV261HpervTPLPWYMWP00EMP6aOPPlLz5s0VEhKiTp06pXucgwcPqnPnzmrdurVmzpyZrQujunTpourVq2e7YLq5uWn06NH6/fffs11i/+2vv/5Ss2bN9Pvvv2vYsGF69913dfz4cbVo0UK//PJLuv1fe+01/f777xo7dqxeffVVffPNN5met5kdqb9YlSpV6o77/uc//1HFihUVFhZm3RYREaGiRYuqbdu2mR63fPlyVatWTQ8//LDatWsnX19frVixIlv5NmzYoBdffFEuLi4KCQlR+/bt1atXr2xdgPTrr79q69at6tSpkz7++GMNGDBAGzduVIsWLRQXF5du/8GDB2v//v1677331L17dy1fvlzt27dP8zpYunSp2rZtq6JFi+qDDz7Qu+++q3379qlp06bWvxv69++v1q1bW/dP/S9V//79NXToUD322GOaOXOmevXqpeXLlyswMFBJSUmS/lkhaNOmjU6cOKHhw4dr1qxZ6tq1a7pfVDJz+PBhBQUF6amnnlJISIjc3d310ksvKSoqKt2+AwcO1L59+zRmzBgNHz5c0j/nDQ8aNEjly5fXtGnT9OKLL2rBggVq06aNNWOqq1ev6umnn1aDBg00ZcoUVaxYUa+++qoWL16cZca//vpLjzzyiPbv36/hw4dr2rRpKlKkiNq3b5/he+m1117T4cOHNW7cOD377LNauHCh3n33XbVr104pKSmaNGmSmjZtqqlTp6b58wayxQBs1JIlSwxJxvfff29cvHjROHXqlLFq1SrD39/f8PLyMk6dOmXdd8aMGYYk46uvvsr08a5cuWJIMl544QXDMAxj5syZdzzmTp5//nlDknH16tVs7d+8eXOjefPm6bb36NHDuOeee6xfHz9+3JBk+Pn5GRcuXEiz74IFCwxJxt69e9Nsr127tvH4449bv54wYYJRpEgR49ChQ2n2Gz58uOHm5macPHkyy6w9evQwihQpkmbbnj17DElGnz590mx/++23DUnGpk2brNvuueceQ5Kxbt26LJ8no+f77LPPDEnG6tWrrd+XZAwaNMj6deqf0dSpU43k5GSjevXqxoMPPmhYLBbDMAxj7NixhiTj4sWLWT5v+/btDU9PT+Po0aPWbWfPnjWKFStm/Oc//7FuS309tmrVyvochmEYb775puHm5mZcu3Yty+dJzXPw4EHj4sWLxvHjx40FCxYYXl5eRkBAgBEbG5vmeX799dd0x168eNF4++23jXvvvdf6vYcfftjo1atXhn9GhmEYiYmJRqlSpYxRo0ZZt3Xp0sV48MEHs8ybql69eka5cuXS/HwbNmwwJKV5zaY+/9ixY61fx8XFpXu8bdu2GZKMzz//3Lot9Wdu0KCBkZiYaN0+ZcoUQ5Lx9ddfG4ZhGDdu3DBKlChh9O3bN81jRkdHG8WLF0+zfdCgQUZG/8T99NNPhiRj+fLlabavW7cuzfavvvoq3ThkV+pr/8svv7Ruu379ulGuXDmjfv366X7upk2bGsnJydbtFy5cMDw9PY02bdoYKSkp1u2zZ882JBmLFy+2bmvevLkhyZg2bZp1W0JCglGvXj2jTJky1j/P1PfLkiVLrPs98cQTxv3332/Ex8dbt1ksFuPRRx81qlevni5nYGBgmtd+kyZNDBcXF2PAgAHWbcnJyUbFihUz/HsOyAozpLB5rVq1kr+/vypVqqQOHTqoSJEiWrt2bZqlrRs3bkiSihUrlunjpH4v9Yrm1P/N6pg7yY/HyMqLL74of3//NNteeOEFubu7KyIiwrrtzz//1L59+xQUFGTd9sUXX6hZs2YqWbKkLl26ZP2vVatWSklJ0Y8//pjjPJGRkZKUbob1rbfekiR99913abZXqVJFgYGBOX6erl275nqWdM2aNdl+npSUFG3YsEHt27dX1apVrdvLlSunLl26aMuWLWmugJf+OSf538u/zZo1U0pKiv7+++9sPed9990nf39/ValSRf3799e9996r7777Tr6+vtk6vkuXLjpy5Ih+/fVX6/9mtVz/3//+V5cvX1bnzp2t2zp37qzff/89zTJ3Rs6dO6c9e/aoR48eKl68uHV769atVbt27Ttm/ff5wklJSbp8+bLuvfdelShRQrt27Uq3f79+/eTh4WH9+tVXX5W7u7v1dRcVFaVr166pc+fOaV7Tbm5uaty4sX744Yc7Zvriiy9UvHhxtW7dOs1jNGjQQEWLFrU+RokSJST9s6Jy+4xkdpQvX17PP/+89evUUxB2796t6OjoNPv27ds3zSrN999/r8TERL3xxhtydXVNs5+fn1+695m7u7v69+9v/drT01P9+/fXhQsXtHPnzgzzXblyRZs2bVLHjh1148YN65/D5cuXFRgYqMOHD6e7m0nv3r3TvPYbN24swzDUu3dv6zY3Nzc1bNhQx44dy84fE2BFIYXNmzNnjqKiorRq1So9/fTTunTpkry8vNLsk1oIU4tpRm4vrX5+fnc85k7y4zGyUqVKlXTbSpcurSeeeCLNsn1ERITc3d3TXNRz+PBhrVu3Tv7+/mn+a9WqlaR/liRz6u+//5arq6vuvffeNNvLli2rEiVKpCtlGeXPjtSCuWfPnmwXzK5du+ree+/N0bmkFy9eVFxcnO67775036tVq5YsFku62yzdfffdab5OPXUko3MdM/Lll18qKipKmzdv1pEjR/Tnn3+qQYMG2TpWkurXr6+aNWsqLCxMy5cvV9myZa3noWZk2bJlqlKliry8vHTkyBEdOXJE1apVk6+vr5YvX57lc6WOZ/Xq1dN9L6M/s9vdunVLY8aMsZ7DXLp0afn7++vatWu6fv16uv1vf56iRYuqXLly1qX4w4cPS/rnvNvbX9cbNmzI1mv68OHDun79usqUKZPuMW7evGl9jObNm+vFF1/UuHHjVLp0aT333HNasmRJunOlM3PvvfemOy+9Ro0akpTuHNrb3yepf+63/xl7enqqatWq6d5n5cuXT3chVGbPlerIkSMyDEPvvvtuuj+HsWPHSkr/d8Ttr/3UX1IqVaqUbnt23w9AKq6yh81r1KiR9Sr79u3bq2nTpurSpYsOHjyookWLSvqnPEjSH3/8ofbt22f4OH/88YckWWd2atasKemf2wxldsyd/PsxUi+2yoqLi0uGZSklJSXD/TO7Ir1Tp07q1auX9uzZo3r16mnlypV64oknrFdvS/9cuNG6det0V2SnSv0HKzeye3ulrK6ov5OuXbtqwoQJGj9+fLbGJ7XE9uzZU19//XWunzc7z5OR7Jbg//znP2nGKTe6dOmiefPmqVixYgoKCkozi/ZvMTEx+uabbxQfH59hqQwLC9PEiRML7HZZr732mpYsWaI33nhDTZo0UfHixeXi4qJOnTrd8cK6jKQes3TpUpUtWzbd97NzyymLxaIyZcpkWsZTVyRcXFy0atUqbd++Xd98843Wr1+vV155RdOmTdP27dutf/fkh7y8T3Ir9c/y7bffznQV4/ZfPDN77We0PbvvByAVhRR2xc3NTSEhIWrZsqVmz55tvQCgadOmKlGihMLCwjRq1KgM/4L8/PPPJUnPPPOM9ZiSJUtqxYoVGjlyZK4ubGrXrp1CQkK0bNmybBXSkiVLZriUld3l3lTt27dX//79rcv2hw4d0ogRI9LsU61aNd28edM6I5of7rnnHlksFh0+fNj6S4AknT9/XteuXdM999yTb8+Vm4L58ssv6/3337dedHEn/v7+8vX11cGDB9N978CBA3J1dU03+2MLunTpojFjxujcuXNZXjyyevVqxcfHa968eelK8MGDBzV69Gj9/PPPatq0aYbHp45n6szk7cffyapVq9SjRw9NmzbNui0+Pj7TK8UPHz6sli1bWr++efOmzp07p6efflrSP69pSSpTpswdX9eZlexq1arp+++/12OPPZatIvjII4/okUce0cSJExUWFqauXbsqPDz8jrfNSp2B/HeO1A/JuP0Trm6X+ud+8ODBNKeSJCYm6vjx4+l+9rNnz6a7XdSdniv1cT08PPL17wggt1iyh91p0aKFGjVqpBkzZig+Pl6S5Ovrq7ffflsHDx7M8L6f3333nUJDQxUYGKhHHnnEesw777yj/fv365133snwN/ply5Zpx44dmWZp0qSJnnzySX366acZLi0nJibq7bfftn5drVo1HThwIM1tgn7//Xf9/PPP2f75pX/ObwsMDNTKlSsVHh4uT0/PdLOIHTt21LZt27R+/fp0x1+7dk3Jyck5ek5J1mIwY8aMNNunT58uSVle6Z0bL7/8su69994Mb3OVkX8v9d9+65rM9m/Tpo2+/vrrNEub58+fV1hYmJo2bWo9LcOWVKtWTTNmzFBISEiWtyVbtmyZqlatqgEDBqhDhw5p/nv77bdVtGjRLJfty5Urp3r16umzzz5Ls8QeFRWlffv23TGnm5tbuvfVrFmzMl0RWLhwYZrzNefNm6fk5GQ99dRTkqTAwED5+flp0qRJGZ7X+e/3VWo5u738duzYUSkpKZowYUK645OTk637X716NV321LtEZGfZ/uzZs2muVI+JidHnn3+uevXqZTi7+2+tWrWSp6enPv744zQZFi1apOvXr6d7nyUnJ6e5pVpiYqIWLFggf3//TE8HKVOmjFq0aKEFCxbo3Llz6b6fl1uZAbnBDCns0tChQ/XSSy8pNDRUAwYMkCQNHz5cu3fv1gcffKBt27bpxRdflI+Pj7Zs2aJly5apVq1a+uyzz9I9zl9//aVp06bphx9+UIcOHVS2bFlFR0drzZo12rFjh7Zu3Zplls8//1xt2rTRCy+8oHbt2umJJ55QkSJFdPjwYYWHh+vcuXPWe5G+8sormj59ugIDA9W7d29duHBB8+fPV506ddJdPHMnQUFBevnllzV37lwFBgZaL8L498+2du1aPfPMM+rZs6caNGig2NhY7d27V6tWrdKJEydyvHT84IMPqkePHlq4cKGuXbum5s2ba8eOHfrss8/Uvn37NLNb+cHNzU2jRo1Sr169sn1M6lL/nj17srX/+++/r6ioKDVt2lQDBw6Uu7u7FixYoISEBE2ZMiWXyQvekCFDsvz+2bNn9cMPP+j111/P8PteXl4KDAzUF198oY8//jjNxUT/FhISorZt26pp06Z65ZVXdOXKFc2aNUt16tTRzZs3s8zwzDPPaOnSpSpevLhq166tbdu26fvvv8/0FleJiYl64okn1LFjRx08eFBz585V06ZNrbPdfn5+mjdvnrp166aHHnpInTp1kr+/v06ePKnvvvtOjz32mPU+vKlF7PXXX1dgYKDc3NzUqVMnNW/eXP3791dISIj27NmjNm3ayMPDQ4cPH9YXX3yhmTNnqkOHDvrss880d+5cPf/886pWrZpu3LihTz75RH5+ftZfzLJSo0YN9e7dW7/++qsCAgK0ePFinT9/XkuWLLnjsf7+/hoxYoTGjRunJ598Us8++6z1z+Phhx/Wyy+/nGb/8uXL64MPPtCJEydUo0YNRUREaM+ePVq4cGGm4yr9c35+06ZNdf/996tv376qWrWqzp8/r23btun06dP6/fff75gVyDfmXNwP3FlGt79JlZKSYlSrVs2oVq1amtulpKSkGEuWLDEee+wxw8/Pz/D29jbq1KljjBs3zrh582amz7Vq1SqjTZs2xl133WW4u7sb5cqVM4KCgozNmzdnK2tcXJzx4YcfGg8//LBRtGhRw9PT06hevbrx2muvGUeOHEmz77Jly4yqVasanp6eRr169Yz169dnetunqVOnZvqcMTExho+PjyHJWLZsWYb73LhxwxgxYoRx7733Gp6enkbp0qWNRx991Pjwww/T3F4nIxnd9skwDCMpKckYN26cUaVKFcPDw8OoVKmSMWLEiDS3jjGMf25907Zt2yyfI7vPV61atSxv+3S71NeOsnHbJ8MwjF27dhmBgYFG0aJFDV9fX6Nly5bG1q1bM3zM21+PP/zwgyHJ+OGHH7J8juzehupOt33Kyr//jKZNm2ZIMjZu3Jjp/qGhoWluq5SZL7/80qhVq5bh5eVl1K5d21i9enW612zq8//7tk9Xr141evXqZZQuXdooWrSoERgYaBw4cMC45557jB49eqT7mf/3v/8Z/fr1M0qWLGkULVrU6Nq1q3H58uV0eX744QcjMDDQKF68uOHt7W1Uq1bN6Nmzp/Hbb79Z90lOTjZee+01w9/f33BxcUl3C6iFCxcaDRo0MHx8fIxixYoZ999/vzFs2DDj7NmzhmH885ro3LmzcffddxteXl5GmTJljGeeeSbNc2Qm9bW/fv1644EHHjC8vLyMmjVrGl988UWa/bL6O84w/rnNU82aNQ0PDw8jICDAePXVV9PdYq558+ZGnTp1jN9++81o0qSJ4e3tbdxzzz3G7Nmz0+yX0W2fDMMwjh49anTv3t0oW7as4eHhYVSoUMF45plnjFWrVt0xZ2avy8zey0BWXAyDM48BAMgvlStXVt26da0fwgHgzjiHFAAAAKaikAIAAMBUFFIAAACYinNIAQAAYCpmSAEAAGAqCikAAABMZRc3xrdYLDp79qyKFStWYJ+5DAAAgNwzDEM3btxQ+fLl5eqaszlPuyikZ8+etcnPkwYAAEBap06dUsWKFXN0jF0U0mLFikn65wf89+dKJyUlacOGDdaPfoPjYYydA+PsHBhnx8cYO4fMxjkmJkaVKlWy9racyHEh/fHHHzV16lTt3LlT586d01dffaX27dtneczmzZsVHBysv/76S5UqVdLo0aPVs2fPbD9n6jK9n59fukLq6+srPz8/XvgOijF2Doyzc2CcHR9j7BzuNM65Ob0yxxc1xcbG6sEHH9ScOXOytf/x48fVtm1btWzZUnv27NEbb7yhPn36aP369TkOCwAAAMeT4xnSp556Sk899VS2958/f76qVKmiadOmSZJq1aqlLVu26KOPPlJgYGBOnx4AAAAOpsDPId22bZtatWqVZltgYKDeeOONTI9JSEhQQkKC9euYmBhJ/0wRJyUlWben/v9/b4NjYYydA+PsHBhnx/fvMZ49e7YiIyNNToSCYLFY5O/vr9atW6fZnpf3doEX0ujoaAUEBKTZFhAQoJiYGN26dUs+Pj7pjgkJCdG4cePSbd+wYYN8fX3TbY+Kisq/wLBJjLFzYJydA+Ps+KKiojR06FClpKSYHQUFpHHjxuney3Fxcbl+PJu8yn7EiBEKDg62fp161VabNm3SXdQUFRWl1q1bc/K0g2KMnQPj7BwYZ8f37zFOLaMff/xxrq66hu2Jjo7WZ599pj59+ig+Pj7dezl1RTs3CryQli1bVufPn0+z7fz58/Lz88twdlSSvLy85OXllW67h4dHhn+JZbYdjoMxdg6Ms3NgnB3fv8e3U6dO8vf3NzEN8oNhGPrmm2+0adMmlS5dWpGRkeney3l5Xxf4R4c2adJEGzduTLMtKipKTZo0KeinBgAAQB4dOHBAXbt21bPPPqty5coVyHPkuJDevHlTe/bs0Z49eyT9c1unPXv26OTJk5L+WW7v3r27df8BAwbo2LFjGjZsmA4cOKC5c+dq5cqVevPNN/PnJwAAAECBOHfunAYNGqTp06cX6PPkuJD+9ttvql+/vurXry9JCg4OVv369TVmzBhJ/wRPLaeSVKVKFX333XeKiorSgw8+qGnTpunTTz/llk8AAAA27ODBg/Ly8tLq1atVtmzZAn2uHJ9D2qJFCxmGken3Q0NDMzxm9+7dOX0qAAAAmOCvv/7SkCFDFBYWprvuuqvAn6/AzyEFAACAfVm5cqXCwsJUpkyZQnk+m7ztEwAAsE1vvfWW5syZk+lqqcVikasr8132au/evYqKisrwfvAFiUIKAACybeXKlWk+TTEr1atXV8mSJQs4EfLL3r17FRwcrBUrVhT6c1NIAQBAjn333Xd64IEH0mxLSkrSpk2b9Pjjj8vDw0MBAQFyd6dq2INLly6pRIkSWrFihUqXLl3oz8+rBAAA5FhAQIAqVqyYZltSUpJKly6tihUr8uEHdmTPnj0aOnSovv322ww/mKgwcJIHAACAk0pMTNSECRMUERFhWhmVmCEFAABwSrt27VJsbKxWrVolFxcXU7MwQwoAAOBkdu7cqeHDh6tu3bqml1GJGVIAAACnYrFYdPr0aa1cuVIlSpQwO44kCikAAMhEYmKi9uzZI4vFYt2W3Vs+wTb9+uuvmjt3rpYsWWJ2lDQopAAAIENBQUFas2ZNht+zhWVe5MyxY8f07rvvKiIiwuwo6VBIAQBAhg4fPixJKlu2rHx9fa3ba9asqfvvv9+sWMiF3bt3q0qVKvryyy9VpEgRs+OkQyEFAABZWr58uR5//HGzYyCXtm3bpvHjxysiIsImy6jEVfYAAAAObd26dYqIiJCfn5/ZUTLFDCkAAIAD2rp1q3bt2qVx48aZHeWOKKQAAAAOZtu2bZo4caLCw8PNjpItFFIAAAAHEh0drfLlyysiIkJFixY1O062cA4pAACAg/jxxx/Vt29fVahQwW7KqMQMKQAATuf06dOKiIhQUlJSlvtdvHixkBIhP8TGxmrOnDkKDw+Xu7t9VTz7SgsAAPLsnXfeUVhYWLb39/HxKcA0yA+bN2+Wr6+vTd70PjsopAAAOJmrV69Kkpo2barq1atnuW+VKlXUqFGjwoiFXPrhhx/00Ucf2c0FTBmhkAIA4KT69OmjHj16mB0DeZCcnKwbN24oPDw8zadp2RsKKQAAgB36/vvvtXr1as2dO9fsKHlGIQUAALAzf/75p2bPnq0VK1aYHSVfcNsnAAAAO7J161bdfffdCg8Pd5gLziikAAAAdmL9+vX68MMP5enpKW9vb7Pj5BsKKQAAgB0wDEPbtm1TWFiYQ5VRiXNIAQBwGH/++afGjh2ruLi4LPf77bffCikR8ktkZKTOnj2r9957z+woBYJCCgCAg1iwYIFWr16d7f3Lli1bgGmQX9avX68lS5Zo2bJlZkcpMBRSAAAcROpHgT7//PNq3759lvsGBASodevWhZAKeXHq1CnVqlVLy5Ytk5eXl9lxCgyFFAAAB1O/fn11797d7BjIo7Vr1yosLEwrVqyQi4uL2XEKFBc1AQAA2JgrV65o9erV+vzzzx2+jErMkAIAANiUNWvWqEqVKgoNDTU7SqFhhhQAAMBGrF69WhEREapdu7bZUQoVhRQAAMAGJCYmytPTU59//rk8PDzMjlOoWLIHAAAw2apVq/TLL79o6tSpZkcxBYUUAADARNu3b9eaNWuc6pzR27FkDwAAYJLvv/9ederUUWhoqNzdnXeekEIKAABgghUrVujzzz+Xj4+PU5dRiUIKAABQ6FJSUnT8+HEtXrzY6cuoxDmkAAAAhWr58uVycXHRyJEjzY5iM5ghBQAAKCQRERHauHGjgoKCzI5iU5ghBQAAKATHjh3TY489pg4dOsjNzc3sODaFGVIAAIACFhoaqsmTJ6tixYqU0QwwQwoAgI05evSoLl++nOPjLly4UABpkFfnzp3Tr7/+qvnz55sdxWZRSAEAsCFRUVFq06ZNnh7DxcUln9Igrz777DM1adJEc+bMMTuKTaOQAgBgQw4dOiRJ8vHxUZkyZXJ8fIkSJfTss8/mdyzkwqeffqrffvtN3bp1MzuKzaOQAgBgg5555hmtXLnS7BjIpfj4eFWsWFGvvPKKXF25ZOdOKKQAAAD5aMGCBTp//rzGjBljdhS7QSEFAADIJ1FRUdq7d69mzZpldhS7QiEFAADIB19//bVat26tVq1acWFZDnFSAwAAQB7NmTNHmzZtko+PD2U0FyikAAAAeZCYmKj4+HjNmDGDMppLLNkDAPJdbGyswsLCdO3aNeu2lJQUHThwQPv37+eTarLw888/mx0BOTBz5kxVrlxZb731ltlR7BqFFACQ75YsWaLXXnvN7Bh2zcfHx+wIuIMFCxbo5MmTev31182OYvcopACAfHf16lVJUo0aNdSkSRNJksVi0enTp1WxYkXuy3gHXl5eGjJkiNkxkIUDBw6oXbt2KleuHMv0+YBCCgAoMC1btrR+fndSUpIiIyP19NNPy8PDw+RkQO5NmzZNFy9e1OTJk82O4jD4FRUAACCbjh49qitXrigkJMTsKA6FQgoAAJANM2bMkKenpyZOnMgyfT5jyR4AAOAOJk+erBs3bqhixYpmR3FIFFIAAIAsxMbGqnHjxmrRogUzowWEQgoAAJCJ999/X35+ftzaqYBxDikAAEAGVq1apaSkJO6pWwiYIQUAALjNihUr9OKLL6pDhw5mR3EKFFIAAIB/ee+99+Tq6ipPT0+zozgNCikAAIAkwzAUFxencuXKqX///mbHcSqcQwoAAJyeYRgaM2aMduzYQRk1AYUUAAA4vcmTJ8vX11ctW7Y0O4pTYskeAAA4LcMwtHfvXvXp00f+/v5mx3FazJACAACnZBiGRowYofXr11NGTcYMKQAAcEp79+6Vv7+/3nrrLbOjOD1mSAEAgFMxDEPjxo1TuXLlKKM2gkIKAACchmEYGjp0qPz8/FimtyEs2QMAAKdgGIZu3LihF154QY8++qjZcfAvzJACAACHZxiGgoOD9fXXX1NGbRCFFAAAOLwlS5aoatWq6tatm9lRkAGW7AEAgMMyDEOLFy9Wz5495ebmZnYcZIIZUgAA4JAMw9Drr7+uxMREyqiNY4YUAAA4HMMwdP36dTVp0kRdunQxOw7ugEIKAHlkGIb+/PNPJSYmmh3FZpw5c8bsCHBiFotFgwcP1iuvvEIZtRMUUgDIo9GjR2vSpElmx7BJLi4uZkeAExo+fLjq16+vhg0bmh0F2UQhBYA8OnDggCSpRIkSKlasmMlpbIevr686duxodgw4EYvFol27dmn48OG66667zI6DHKCQAkA+mTRpkl599VWzYwBOyWKxaMCAAWrSpAkzo3aIq+wBAIDd++WXX9SkSRP16tXL7CjIBQopAACwWykpKXr77bdVp04dyqgdo5ACAAC7ZLFY1K9fPz344IPy8/MzOw7ygHNIAQCA3UlJSdGNGzc0cOBANWjQwOw4yCNmSAEAgF1JSUlR79699dNPP1FGHQSFFAAA2JXZs2erTZs2ateundlRkE9YsgcAAHYhOTlZn3zyiV5//XU+dMHBMEMKAABsXnJysnr16qW77rqLMuqAmCEFAAA2zWKx6OrVq+rYsSPL9A6KGVIAAGCzkpKS1K1bN12+fJky6sAopAAAwGa99tpreuGFF1SzZk2zo6AAsWQPAABsTlJSknbt2qUpU6Zw03snwAwpAACwKYmJiXr55Zd17tw5yqiTYIYUAADYlJ9++kldunTRc889Z3YUFBIKKQBIOnnypEaNGqXr16/n+Nhff/21ABIBzicxMVFvvvmmpk2bJm9vb7PjoBBRSAFA0rJly7Rs2bI8PUaZMmXyKQ3gfJKSkvTyyy+re/fulFEnRCEFAP0zMyNJLVq00Msvv5zj4/39/fX000/ndyzAKSQkJCguLk5jxoxR3bp1zY4DE1BIAeBfateurd69e5sdA3Aa8fHx6tq1q1577TW1aNHC7DgwCVfZAwAA03z00Ufq06cPZdTJMUMKAAAKXXx8vBYtWqThw4fz2fRghhQAABSu+Ph4de7cWdWrV6eMQhIzpAAAoBClpKToypUrev3119WyZUuz48BGMEMKAAAKRVxcnF544QUlJydTRpEGhRQAABSKfv36aciQIbr77rvNjgIbw5I9AAAoUHFxcdqzZ48WLFigIkWKmB0HNogZUgAAUGBiY2MVFBSkpKQkyigyRSEFAAAF5ocfftDbb7+t5s2bmx0FNixXhXTOnDmqXLmyvL291bhxY+3YsSPL/WfMmKH77rtPPj4+qlSpkt58803Fx8fnKjAAALB9N2/eVN++ffXkk09SRnFHOS6kERERCg4O1tixY7Vr1y49+OCDCgwM1IULFzLcPywsTMOHD9fYsWO1f/9+LVq0SBERERo5cmSewwMAANtz69YtderUST169JC7O5er4M5yXEinT5+uvn37qlevXqpdu7bmz58vX19fLV68OMP9t27dqscee0xdunRR5cqV1aZNG3Xu3PmOs6oAAMD+3Lp1SwkJCZo+fbqaNm1qdhzYiRz92pKYmKidO3dqxIgR1m2urq5q1aqVtm3bluExjz76qJYtW6YdO3aoUaNGOnbsmCIjI9WtW7dMnychIUEJCQnWr2NiYiRJSUlJSkpKsm5P/f//3gbHwhg7B1sY55SUFEmSxWLh9VZAbGGcUbCuXLmiqVOnqlKlSmrUqBFj7aAyey/nZbxzVEgvXbqklJQUBQQEpNkeEBCgAwcOZHhMly5ddOnSJTVt2lSGYSg5OVkDBgzIcsk+JCRE48aNS7d9w4YN8vX1Tbc9KioqJz8G7BBj7BwKapwvXbpk/cU2M6mrNn///bciIyMLJAf+wfvZca1YsUIdO3bUpUuXeB85gdvfy3Fxcbl+rAI/sWPz5s2aNGmS5s6dq8aNG+vIkSMaMmSIJkyYoHfffTfDY0aMGKHg4GDr1zExMapUqZLatGkjPz8/6/akpCRFRUWpdevW8vDwKOgfBSZgjJ1DQY7z1q1b9fzzz8swjGztX7lyZT399NP5mgH/4P3suK5fv65ly5Zp8eLFjLETyOy9fKdf/LOSo0JaunRpubm56fz582m2nz9/XmXLls3wmHfffVfdunVTnz59JEn333+/YmNj1a9fP40aNUqurulPY/Xy8pKXl1e67R4eHhm+wDPbDsfBGDuHghjno0ePyjAMeXl5qVSpUlnuW6RIEb300ku81goY72fHcv36db388ssaP368dVwZY+dw+zjnZcxzVEg9PT3VoEEDbdy4Ue3bt5f0z/lWGzdu1ODBgzM8Ji4uLl3pdHNzk6Rsz1gAQF61bt1a33zzjdkxAIeSlJSka9eu6f3331fDhg05ZxS5luOr7IODg/XJJ5/os88+0/79+/Xqq68qNjZWvXr1kiR17949zUVP7dq107x58xQeHq7jx48rKipK7777rtq1a2ctpgAAwL5cu3ZNzzzzjHx9fdWwYUOz48DO5fgc0qCgIF28eFFjxoxRdHS06tWrp3Xr1lkvdDp58mSaGdHRo0fLxcVFo0eP1pkzZ+Tv76927dpp4sSJ+fdTAACAQmMYhl555RVNnDhR/v7+ZseBA8jVRU2DBw/OdIl+8+bNaZ/A3V1jx47V2LFjc/NUAADAhly9elX79+9XWFiYvL29zY4DB8Fn2QMAgGy5cuWKgoKC5O3tTRlFvuLzvAAAQLZs3rxZH3zwgerXr292FDgYCimAArFnz550p/BkJiUlRfv27dORI0fy/WLH7du35+vjAc7o8uXLGjp0qBYtWiQXFxez48ABUUgBFIinnnpK0dHRZsewYnkRyJ3r16+rU6dOmjZtGmUUBYZCCqBAXL58WZLUvn37DD/y998sFovOnj2r8uXLZ/hhGXnl6emp119/Pd8fF3B0ly5dkoeHhz799FPdc889ZseBA6OQAihQs2bNUsWKFbPcJykpSZGRkXr66af5dBfARly8eFGdO3fW7NmzVbNmTbPjwMFxlT0AAEjno48+0owZMyijKBTMkAIAAKsLFy5o5cqVmjRpktlR4ESYIQUAAJKk8+fPq3Pnznr88cfNjgInwwwpAABQQkKCbt68qdmzZ6tWrVpmx4GTYYYUAAAnd+7cObVt21b+/v6UUZiCGVIAmdqwYYMWLlyolJSUHB+blJRUAIkA5DeLxaK+fftqzpw58vPzMzsOnBSFFECmxo4dm6dPOvL09OQfOMCGnT17Vn///bdWr14tT09Ps+PAiVFIAWQqMTFRkvTaa6+pbt26OT6+Xr16FFLARp05c0bdunXTggULKKMwHYUUwB09/fTTevLJJ82OASAfbdmyRQsWLFD16tXNjgJwURMAAM7k9OnT6t27tzp27EgZhc1ghhQAACdx4cIFde/eXZ988olcXFzMjgNYUUgBAHACp0+flp+fn5YvX65y5cqZHQdIgyV7AAAc3N9//63u3bvr2rVrlFHYJAopAAAObvbs2Vq8eLHuvvtus6MAGWLJHsijpKQktWrVSn/88YfZUfJdTEyM2REA5MGJEycUGRmpqVOnmh0FyBKFFMijI0eO6McffzQ7RoHx8vLSfffdZ3YMADl0/Phx9e7dW6GhoWZHAe6IQgrkk+LFi+uXX34xO0a+K1OmjEqWLGl2DAA5EBcXp8TERIWGhrJMD7tAIQXyibu7OzOJAEx39OhR9e/fX99++628vb3NjgNkCxc1AQDgIJKSkvTaa68pNDSUMgq7wgwpAAAO4PDhw7p69arWrl0rd3f+eYd9YYYUAAA7d/jwYfXv318VKlSgjMIu8aoFAMCOGYahX3/9VcuWLVP58uXNjgPkCoUUyEJsbKyOHj2a5T7Hjh0rpDQAkNbBgwc1bdo0LVy40OwoQJ5QSIFMpKSk6P7779fx48eztb+Li0sBJwKA/+/kyZMaOHCgli9fbnYUIM8opEAm4uPjrWU0ICDgjoWzV69ehRELAHT06FGVKVNGK1euVKlSpcyOA+QZhRTIhmPHjsnX19fsGACgffv26bXXXlN4eLj8/f3NjgPkC66yBwDAjixatEgrVqygjMKhMEMKAIAd+PPPP7Vt2zZNmzbN7ChAvmOGFAAAG7d371698cYbat++vdlRgALBDCkAADbsxo0bcnd3V3h4uEqXLm12HKBAMEMKAICN+v3339WhQwdVr16dMgqHxgwpnNK+ffu0cePGLPdJSEgopDQAkF5cXJxGjhypsLAwPg4UDo9XOJzSc889pyNHjmRrXzc3N7m5uRVwIgD4/3bv3i1J+uabb+TqymImHB+FFE7p8uXLkqSnnnpKfn5+We77xBNPyMvLqzBiAYB27dql4cOHKzw8nDIKp0EhhVObPn26atasaXYMAJAkGYahffv2KSIiQiVLljQ7DlBoKKQAANiA3377TUuWLNGcOXPMjgIUOgopAAAmO3DggEaNGqWIiAizowCm4OQUAABM9Ndff6lChQr64osvVKJECbPjAKagkAIAYJJffvlFb7/9tgzDuOMFloAjo5ACAGACwzAUERGhiIgIyiicHueQAgBQyLZt26aDBw9q+vTpZkcBbAIzpAAAFKKtW7dqwoQJevHFF82OAtgMCikAAIXk6tWrKlGihCIiIlSsWDGz4wA2g0IKAEAh+Omnn9SzZ0/VrFmTMgrchkIKAEABu3btmqZPn67ly5fzcaBABrioCQCAAvS///1PpUuX1urVq+Xi4mJ2HMAm8WsaAAAFZPPmzfrwww9VuXJlyiiQBWZIAQAoABaLRWfOnFFERIR8fX3NjgPYNAopAAD5bOPGjYqMjNS0adPMjgLYBQopHN64ceM0e/ZsGYZh3Xb16lUTEwFwZDt37tTHH3+s8PBws6MAdoNCCocXGhqqS5cupdtesmRJVahQwYREABzVb7/9ppo1ayo8PFw+Pj5mxwHsBoUUTmPFihV68MEHrV9XrFiRewECyDfr16/X/PnztWLFCnl7e5sdB7ArFFI4jSpVqqhWrVpmxwDggCwWi77//nvKKJBLFFIAAPJg3bp1unbtmqZOnWp2FMBucR9SAABy6b///a8+/fRTPf/882ZHAewahRQAgFy4ePGiKleurOXLl8vLy8vsOIBdo5ACAJBD33zzjYYMGaKaNWtSRoF8wDmksAuGYejQoUNKTEzM8bG5OQYAMhMdHa0VK1YoNDSUjwMF8gmFFHbh3Xff1ZQpU8yOAcDJffvtt6pZs6aWL19OGQXyEYUUduGvv/6SJBUtWjRXN5uuUaNGmnuQAkBOffXVV4qIiNDSpUspo0A+o5DCrsyYMUO9e/c2OwYAJ5OSkqL4+HgtXbpUHh4eZscBHA6FFACALHz55Zfas2ePJkyYYHYUwGFRSAEAyMT//vc/rV69WqGhoWZHARwahRQAgAxs2bJFDRo00GeffSZ3d/65BAoS9yEFAOA2ERERWrhwoby9vSmjQCGgkAIA8C9JSUn6448/tHjxYsooUEh4pwEA8H/CwsJUtGhRTZw40ewogFNhhhQAAEkrVqxQVFSU2rZta3YUwOkwQwoAcHpnz57VQw89pI4dO8rNzc3sOIDToZACAJza559/rq1bt2r+/PlmRwGcFoUUAOC0jh8/rp9//llz5841Owrg1DiHFADglJYvXy53d3ctWLCAZXrAZBRSAIDTWbx4sX766SdVqFDB7CgARCEFADiZ5ORk+fn5ae7cuXJ15Z9BwBZwDikAwGksXLhQ165d07Bhw8yOAuBfKKQw1eHDhzVp0iTFxsZm+H2LxaJz587p+PHjhZwMgKP55ptv9Pvvv2vWrFlmRwFwGwopTDV//nyFhoZme//SpUsXXBgADisqKkqPP/642rZtyzI9YIMopDBVQkKCJOnJJ5/UM888k+77KSkp+uuvv1SnTh2VK1eOT1ABkGNz587V/v371apVK7m4uJgdB0AGKKSwCY0aNdKgQYPSbU9KSlJkZKSefvppeXh4mJAMgD2Li4vT1atX9fHHH1NGARtGIQUAOKTZs2erVq1aGjVqlNlRANwBJ9IAABzO3LlzdezYMT3++ONmRwGQDcyQAgAcysmTJxUYGKhXX32VZXrATjBDCgBwGB999JHmz5+vatWqUUYBO8IMKQDAIfz55586f/68QkJCzI4CIIeYIQUA2L158+apTJkymjx5MjOjgB1ihhQAYNemTJmiq1evyt/f3+woAHKJQgoAsFsJCQmqWbOm2rVrx8woYMcopAAAuzRp0iSVKlVK/fv3NzsKgDziHFIAgN1ZunSp4uPj1a9fP7OjAMgHzJACAOzK2rVr9dJLL8nLy4tlesBBMEMKALAb48eP1+7du+Xt7U0ZBRwIM6QAALtw7do1FS9eXEOGDDE7CoB8xgwpAMCmGYah9957T4cOHaKMAg6KQgpTJSQkmB0BgI2bOHGiPDw81KhRI7OjACggLNnDNHFxcVq9erUkqX79+ianAWBrDMPQ0aNH1b17d919991mxwFQgJghhWlCQ0N15coVVa1aVe3atTM7DgAbYhiGRo0apa+//poyCjgBCilMkZKSounTp0uSgoOD5ebmZnIiALbkl19+UYkSJfTWW2+ZHQVAIaCQwhRr167V0aNHVbJkSfXs2dPsOABshGEYmjx5smrVqqVhw4aZHQdAIaGQwhQffvihJGngwIEqUqSIyWkA2ALDMPTOO+/I09NTxYsXNzsOgELERU0odNu2bdPWrVvl6empwYMHmx0HgA0wDEO3bt1Sq1at1KZNG7PjAChkFFIUumnTpkmSXn75ZZUtW9bkNADMZhiG3nrrLTVu3FhBQUFmxwFgApbsUaiOHj1qvdVTcHCwyWkA2II5c+aocuXKlFHAiTFDikI1Y8YMGYahp556SnXq1DE7DgATGYahL774QgMGDJC7O/8cAc4sVzOkqb/Nent7q3HjxtqxY0eW+1+7dk2DBg1SuXLl5OXlpRo1aigyMjJXgWG/Ll++rMWLF0uS3n77bZPTADCTYRgaMmSILl68SBkFkPMZ0oiICAUHB2v+/Plq3LixZsyYocDAQB08eFBlypRJt39iYqJat26tMmXKaNWqVapQoYL+/vtvlShRIj/yw47Mnz9fcXFxql+/vlq2bGl2HAAmunDhgurXr69evXqZHQWADcjxDOn06dPVt29f9erVS7Vr19b8+fPl6+trnfm63eLFi3XlyhWtWbNGjz32mCpXrqzmzZvrwQcfzHN42I+EhATNmjVLkvTWW2/JxcXF5EQAzGCxWPTGG2/o8uXLlFEAVjkqpImJidq5c6datWr1/x/A1VWtWrXStm3bMjxm7dq1atKkiQYNGqSAgADVrVtXkyZNUkpKSt6Sw64sX75c58+fV8WKFdWxY0ez4wAwSWhoqOrWravatWubHQWADcnRkv2lS5eUkpKigICANNsDAgJ04MCBDI85duyYNm3apK5duyoyMlJHjhzRwIEDlZSUpLFjx2Z4TEJCghISEqxfx8TESJKSkpKUlJRk3Z76//+9DbbHMAzrjfBT7zua3TFjjJ0D4+z4LBaL9u3bp/bt2ysoKIixdlC8l51DZuOcl3Ev8DPJLRaLypQpo4ULF8rNzU0NGjTQmTNnNHXq1EwLaUhIiMaNG5du+4YNG+Tr65tue1RUVL7nRv7ZuXOn9u/fLx8fH1WqVClXF7Qxxs6BcXZMFotFCxYsUI0aNfTEE08wzk6AMXYOt49zXFxcrh8rR4W0dOnScnNz0/nz59NsP3/+fKY3OC9Xrpw8PDzk5uZm3VarVi1FR0crMTFRnp6e6Y4ZMWJEmntUxsTEqFKlSmrTpo38/Pys25OSkhQVFaXWrVvLw8MjJz8KCtHMmTMlSQMGDNBLL72Uo2MZY+fAODu2jRs36sUXX1TXrl0ZZwfHe9k5ZDbOqSvauZGjQurp6akGDRpo48aNat++vaR/fvPduHFjph8B+dhjjyksLEwWi0Wurv+csnro0CGVK1cuwzIqSV5eXvLy8kq33cPDI8MXeGbbYb7du3frhx9+kJubm954441cjxNj7BwYZ8disVg0duxYjRw5Uj4+PtblPMbZ8THGzuH2cc7LmOf4Kvvg4GB98skn+uyzz7R//369+uqrio2NtV4t2b17d40YMcK6/6uvvqorV65oyJAhOnTokL777jtNmjRJgwYNynVo2I/UjwkNCgrS3XffbXIaAIUlJSVF/fr107333isfHx+z4wCwcTk+hzQoKEgXL17UmDFjFB0drXr16mndunXWC51OnjxpnQmVpEqVKmn9+vV688039cADD6hChQoaMmSI3nnnnfz7KWCTTp06pfDwcEn/3OoJgHNISUnRrVu31KNHDzVr1szsOADsQK4uaho8eHCmS/SbN29Ot61Jkybavn17bp4Kduzjjz9WSkqKWrZsqYceesjsOAAKQUpKivr06aOgoCA9+eSTZscBYCdy9dGhwJ1cv35dCxYskMTHhALOZMqUKWrVqhVlFECO8AHCKBCffvqpbty4oVq1avEPE+AEkpOTFRERoWHDhqW5qwoAZAczpMh3SUlJ1ls9vfXWW2nOKQbgeJKTk/XKK6/Izc2NMgogV5ghRb774osvdOrUKQUEBKhr165mxwFQgAzD0Llz5/Tcc8/pxRdfNDsOADvF1BXy1e0fE+rt7W1yIgAFJTk5WT169JDFYqGMAsgTCiny1ebNm7V79275+Pjo1VdfNTsOgALUv39/Pfvss7rnnnvMjgLAzrFkj3yVOjvaq1cvlSpVyuQ0AApCUlKSDh06pMmTJ8vf39/sOAAcADOkyDf79u1TZGSkXFxc9Oabb5odB0ABSEpKUvfu3XX48GHKKIB8QyFFvpk+fbok6fnnn9e9995rchoABSEyMlJBQUFq37692VEAOBCW7JEvoqOjtXTpUkl8TCjgiBITEzVy5EhNnjxZ7u780wEgfzFDinwxZ84cJSYmqkmTJnr00UfNjgMgHyUmJurll19W8+bNKaMACgR/syDPYmNjNXfuXEl8TCjgaBISEpSYmKihQ4fq4YcfNjsOAAfFDCnyLDQ0VFeuXFG1atX03HPPmR0HQD5JSEhQ165d9ccff1BGARQoCinyJCUlRR999JEk6c033+RjAwEHMmHCBL3yyit67LHHzI4CwMGxZI88+frrr3X06FGVLFlSPXv2NDsOgHwQHx+viIgITZgwQS4uLmbHAeAEmCFFnkybNk2SNHDgQBUpUsTkNADyKj4+Xp07d1bZsmUpowAKDTOkyLWtW7dq69at8vT01ODBg82OAyCPDMPQ6dOnNXDgQLVu3drsOACcCDOkyLXU2dGXX35ZZcuWNTkNgLy4deuWOnToID8/P8oogEJHIUWuHD16VF999ZUkKTg42OQ0APLCMAz16NFDAwcOVJkyZcyOA8AJsWSPXPnoo49kGIaeeuop1alTx+w4AHIpLi5OR48e1cKFC1WiRAmz4wBwUsyQIscuX76sxYsXS+JG+IA9i42NVVBQkC5dukQZBWAqZkiRY/Pnz9etW7dUv359tWzZ0uw4AHLpm2++0VtvvaUWLVqYHQWAk6OQIlOGYWj9+vU6efJkmu2zZs2SJL311lvcFgawQ7GxsRo1apSmT58uV1cWygCYj0KKTP3222966qmnMvxexYoV1bFjx0JOBCCvUpfp33nnHcooAJtBIUWmLl68KEkqXrx4miU9Nzc3DRw4UB4eHiYlA5AbN2/elCSFhITo/vvvNzkNAPx/FFLc0b333qs1a9aYHQNAHty4cUNBQUEKCQnRgw8+aHYcAEiD9RoAcALjxo3T6NGjKaMAbBIzpADgwGJiYrR69WpNnTqVixAB2CxmSAHAQV2/fl0dO3ZUzZo1KaMAbBozpADggCwWi86cOaNx48apcePGZscBgCwxQwoADubatWtq166dKlSoQBkFYBeYIYWkf2ZTxo0bpyNHjli3nTlzxsREAHLDYrHo5Zdf1nvvvafixYubHQcAsoVCCknS7t27NX78+Ay/V6pUqUJOAyA3rl69qlOnTmnFihUqVqyY2XEAINsopJAkxcfHS5JKly6tUaNGWbe7ubnpueeeMysWgGy6evWqgoKCNHnyZMooALtDIUUaJUuW1BtvvGF2DAA5tHbtWk2ePFkPPfSQ2VEAIMcopABgx65cuaL33ntPM2fO5NZOAOwWV9kDgJ26evWqOnXqpN69e1NGAdg1ZkgBwA5duXJFHh4emjNnjqpXr252HADIE2ZIAcDOXLp0SR07dlR0dDRlFIBDoJACgJ0ZN26cPvroI8ooAIfBkj0A2IkLFy4oMjJSH3/8MeeMAnAozJACgB24cOGCOnfurEaNGlFGATgcCikA2Ljk5GSdO3dOs2bNUu3atc2OAwD5jkIKADYsOjpabdu2VY0aNSijABwWhRQAbFRSUpJ69OihmTNnysfHx+w4AFBguKgJAGzQuXPndPnyZX311Vfy9fU1Ow4AFChmSAHAxpw9e1Zdu3aVp6cnZRSAU2CGFABsTGRkpBYsWMB9RgE4DQqpE7h165bOnDmT5T6nT58upDQAMnPmzBlNmTJFM2fONDsKABQqCqmDS0hI0L333quzZ8+aHQVAFs6dO6du3bpp4cKFZkcBgEJHIXVwFy5csJZRPz+/LPd1cXFR165dCyMWgH+Jjo5W0aJFFRoaqrvvvtvsOABQ6CikTsLLy0vXr183OwaA25w8eVI9evTQsmXLKKMAnBZX2QOAiUJCQrR48WJVqFDB7CgAYBpmSAHABH///bd+/PFHzZs3z+woAGA6ZkgBoJCdOHFCvXr10n/+8x+zowCATaCQAkAhSkxM1OXLl7VkyRLdc889ZscBAJtAIQWAQnLs2DE9++yzeuCBByijAPAvnEMKAIXg1q1b6t+/vxYvXiwPDw+z4wCATaGQAkABO3LkiJKSkvTtt9/Ky8vL7DgAYHNYsgeAAnTkyBH1799ffn5+lFEAyASFFAAK0MaNG/X5559zn1EAyAJL9gBQAA4dOqQFCxZo2rRpZkcBAJtHIQWAfHbs2DG9+uqrWrZsmdlRAMAuUEgBIB+dPHlS/v7+CgsLU0BAgNlxAMAucA4pAOST/fv3q1evXkpMTKSMAkAOUEgBIB8YhqGPPvpIYWFhKlWqlNlxAMCusGQPAHn0119/6Y8//tDChQvNjgIAdokZUgDIgz///FNDhgxRq1atzI4CAHaLQgoAuRQfH6+4uDitWLFC/v7+ZscBALtFIQWAXPjjjz/UoUMHNWzYkDIKAHnEOaQAkEPXr1/X0KFDFRYWJldXfq8HgLyikAJADuzZs0dFihTRt99+Kw8PD7PjAIBD4Fd7AMim3bt3a9iwYSpVqhRlFADyEYUUALLpl19+UXh4uO666y6zowCAQ2HJHgDuYOfOnfriiy80efJks6MAgEOikAJAFv7880+NHDlSERERZkcBAIfFkj0AZOLw4cO6++67FRERoRIlSpgdBwAcFoUUADKwY8cODR48WC4uLpRRAChgFFIAuI3FYtGiRYu0cuVKFStWzOw4AODwOIcUAP5l+/btOnPmjBYsWGB2FABwGsyQAsD/2bZtm8aPH6/WrVubHQUAnAozpAAgKTY2Vm5uboqIiGCZHgAKGTOkAJzeli1b1KNHDz388MOUUQAwATOkAJzahQsX9MEHH2jFihVycXExOw4AOCVmSAE4rS1btiguLk5r1qxR0aJFzY4DAE6LQgrAKf3vf//TBx98IH9/f7m5uZkdBwCcGoUUgNMxDEP79+9XeHi4ihQpYnYcAHB6nEMKwKn88MMP2rx5s8aNG2d2FADA/6GQAnAa27dv14wZM7RixQqzowAA/oUlewBO4c8//1StWrW0YsUK+fr6mh0HAPAvFFIADi8qKkrvvvuuvLy8KKMAYIMopAAcWnJystasWaMVK1bI29vb7DgAgAxwDikAh7V+/XolJSVpzpw5ZkcBAGSBGVIADmndunVauHChWrVqZXYUAMAdMEMKwOHExMSoVKlSCgsLk5eXl9lxAAB3wAwpAIfy7bff6rXXXtPDDz9MGQUAO8EMKQCH8ffff+vzzz/X0qVLzY4CAMgBZkgBOIT//ve/cnd3V3h4ODOjAGBnKKQA7N7XX3+tzz77TP7+/nJ15a81ALA3/M0NwK4ZhqHz58/r888/l6enp9lxAAC5wDmkAOzW6tWrdejQIQ0fPtzsKACAPKCQOpglS5bof//7n/Xr2NhYE9MABScqKkqrVq3SZ599ZnYUAEAeUUgdSFxcnPr27auUlJR037vrrrtMSAQUjJ07d6pRo0Zq0aKFPDw8zI4DAMgjCqkDSU5OtpbRSZMmyd39/w/v448/blYsIF+tXLlSa9euVWhoaJrXOADAfvG3uYMKDg7m1jdwOLdu3dL27dspowDgYPgbHYBdCA8PV5kyZTR9+nSzowAA8hm3fQJg81asWKF169bpP//5j9lRAAAFgBlSADbtypUrqlmzpjp27Cg3Nzez4wAACgCFFIDNWrp0qX755RfNnj3b7CgAgAJEIQVgk/bt26fNmzdr4cKFZkcBABSwXBXSOXPmaOrUqYqOjtaDDz6oWbNmqVGjRnc8Ljw8XJ07d9Zzzz2nNWvW5Oap7VpoaKgmTpyo5OTkAnl8i8VSII8LFLYvvvhCLVq00KeffioXFxez4wAACliOC2lERISCg4M1f/58NW7cWDNmzFBgYKAOHjyoMmXKZHrciRMn9Pbbb6tZs2Z5CmzPFi1apCNHjhT481SuXJmbhcNuLVmyRNu2bdOLL75IGQUAJ5HjQjp9+nT17dtXvXr1kiTNnz9f3333nRYvXpzp50mnpKSoa9euGjdunH766Sddu3YtT6HtlWEYkqTJkyerZcuWBfY8tWrVkqsrN1CA/Umd5Z8/fz6vYQBwIjkqpImJidq5c6dGjBhh3ebq6qpWrVpp27ZtmR43fvx4lSlTRr1799ZPP/2U+7QOonr16tk6xQFwJlFRUTp+/LjeeOMNs6MAAApZjgrppUuXlJKSooCAgDTbAwICdODAgQyP2bJlixYtWqQ9e/Zk+3kSEhKUkJBg/TomJkaSlJSUpKSkJOv21P//7222LHWGNDk52W4ym83exhi5s3LlSh09elSTJ09mrB0Y72fHxxg7h8zGOS/jXqBX2d+4cUPdunXTJ598otKlS2f7uJCQEI0bNy7d9g0bNsjX1zfd9qioqDzlLCxXr16VJO3atYuP9cwhexlj5NyBAwd09913q1+/ftq4caPZcVAIeD87PsbYOdw+znFxcbl+rBwV0tKlS8vNzU3nz59Ps/38+fMqW7Zsuv2PHj2qEydOqF27dtZtqeeIubu76+DBg6pWrVq640aMGKHg4GDr1zExMapUqZLatGkjPz8/6/akpCRFRUWpdevWdnERz5QpUyRJDz30kJ5++mmT09gHextj5MzChQv1999/a/Dgwfr+++8ZZwfH+9nxMcbOIbNxTl3Rzo0cFVJPT081aNBAGzduVPv27SX9UzA3btyowYMHp9u/Zs2a2rt3b5pto0eP1o0bNzRz5kxVqlQpw+fx8vLKcAbRw8Mjwxd4ZtttTeoVw+7u7naR15bYyxgj+65fv65z585pzpw51luhMc7OgXF2fIyxc7h9nPMy5jlesg8ODlaPHj3UsGFDNWrUSDNmzFBsbKz1qvvu3burQoUKCgkJkbe3t+rWrZvm+BIlSkhSuu0AnMfcuXPVoEEDvf/++2ZHAQDYgBwX0qCgIF28eFFjxoxRdHS06tWrp3Xr1lkvdDp58iS3awGQqTlz5ujw4cN69dVXzY4CALARubqoafDgwRku0UvS5s2bszw2NDQ0N08JwAFcuHBBzZo108CBA7npPQDAis+yB1AoZsyYoUuXLrFMDwBIh0IKoMDt2LFDp0+f1tSpU82OAgCwQZzsCaBALVq0SPfdd5+mTp3KMj0AIEPMkAIoMFOnTtXly5fl5+dHGQUAZIpCCqBAJCcnq3z58nr77bcpowCALFFIAeS7yZMnq1y5curRo4fZUQAAdoBCmg9u3Lih//73v4qPj89yv9s/chVwRIsWLVJsbKy6d+9udhQAgJ2gkOaDMWPGaMaMGdnen49Tg6PatGmTOnXqJF9fX5bpAQDZRiHNB6kznzVr1lTlypWz3LdChQp6/PHHCyEVULgmTJiglJQUXt8AgByjkOajAQMGaMiQIWbHAArdhQsX5OXlpWHDhpkdBQBgh7gPKYA8GT9+vC5cuEAZBQDkGoUUQK6NHz9erq6uqlu3rtlRAAB2jCV7ADlmGIbOnTunjh07qmbNmmbHAQDYOWZIAeSIYRh69913FR4eThkFAOQLCimAHNm4caOKFi2q4OBgs6MAABwES/ZZOHv2rD744APduHEjy/22b99eSIkA8xiGoZkzZ6p///5q1aqV2XEAAA6EQpqFTz75RB9//HG29y9ZsmQBpgHMYxiGhg8fLn9/f/n4+JgdBwDgYCikWbh165YkqWnTpmrbtm2W+5YqVUodO3YsjFhAoTIMQwkJCWrSpInat29vdhwAgAOikGZDo0aNNHz4cLNjAIXOMAwNHTpUTZs2pYwCAAoMFzUByNT06dNVqVIlyigAoEAxQwogHcMwtG7dOg0aNEje3t5mxwEAODhmSAGkYRiG3njjDR09epQyCgAoFMyQAkjj5MmTqlOnjvr162d2FACAk2CGFICkf2ZG33zzTVksFsooAKBQUUgBSJLefPNN3XfffapSpYrZUQAAToYle8DJWSwWnT59Wq+//rqqVq1qdhwAgBNihhRwYhaLRYMGDdKmTZsoowAA01BIASe2du1aNWjQQD179jQ7CgDAibFkDzghi8WikJAQDRs2TB4eHmbHAQA4OWZIASdjsVjUv39/VahQgTIKALAJzJACTiQlJUXx8fHq0KGDAgMDzY4DAIAkZkgBp5GSkqK+fftqx44dlFEAgE1hhvRfrl27pps3b1q/jomJMTENkL/GjRunxx9/XC1btjQ7CgAAaVBI/8/69evVtm1bpaSkmB0FyFcpKSn67rvvNHr0aHl6epodBwCAdFiy/z+7du1SSkqKXFxc5Onpaf3vrrvu0pNPPml2PCBXkpOT9corryg2NpYyCgCwWcyQ3uaVV17Rp59+anYMIF8cPXpUbdu2VceOHc2OAgBAppghBRxQcnKyevfureLFi1NGAQA2j0IKOBjDMNS7d289+eSTKlu2rNlxAAC4I5bsAQeSlJSk06dP6/3331elSpXMjgMAQLYwQwo4iKSkJHXv3l2///47ZRQAYFcopICDWLlypV566SW1b9/e7CgAAOQIS/aAnUtMTNTEiRM1duxYubryOyYAwP7wrxdgxxITE9WtWzc99NBDlFEAgN1ihhSwU4mJiUpISNDgwYPVrFkzs+MAAJBrTKkAdighIUFdu3bVgQMHKKMAALtHIQXs0MiRI9WzZ089/PDDZkcBACDPWLIH7Eh8fLwiIyP1wQcfyN2dty8AwDEwQwrYifj4eHXp0kW+vr6UUQCAQ+FfNcBOHDp0SP3791dgYKDZUQAAyFfMkAI27tatW+rUqZPuvvtuyigAwCFRSAEbZrFY1LVrV/Xu3VslSpQwOw4AAAWCJXvARsXFxSk6Olpz585V2bJlzY4DAECBYYYUsEFxcXHq3Lmz/v77b8ooAMDhUUgBGxQWFqYhQ4aoZcuWZkcBAKDAsWQP2JDY2FhNmjRJ77//vlxcXMyOAwBAoWCGFLARsbGxCgoKUps2bSijAACnwgwpYAPi4uKUkpKi9957Tw0bNjQ7DgAAhYoZUsBkN2/e1EsvvaQzZ85QRgEATolCCphs6NChGjlypGrVqmV2FAAATMGSPWCSGzduaMOGDZozZ45cXfndEADgvPhXEDBBTEyMOnbsqPLly1NGAQBOjxlSoJAZhqEDBw5o7NixeuSRR8yOAwCA6ZiaAQrR9evX9cILL6hu3bqUUQAA/g+FFCgkycnJ6tSpk0aMGCFfX1+z4wAAYDNYsgcKwbVr13TlyhUtXbpUpUuXNjsOAAA2hRlSoIBdvXpVHTt21JUrVyijAABkgBlSoICtWLFCISEhatCggdlRAACwSRRSoIBcuXJF06ZN08SJE82OAgCATWPJHigAV65cUadOndShQwezowAAYPOYIQXyWUxMjNzc3DRjxgzVrl3b7DgAANg8ZkiBfHTp0iW98MILunr1KmUUAIBsopAC+WjYsGGaPn26KleubHYUAADsBkv2QD64ePGifvzxRy1atEguLi5mxwEAwK4wQwrk0YULF9SpUyfdd999lFEAAHKBGVIgDwzD0KFDh/Txxx+rTp06ZscBAMAuMUMK5NL58+f13HPPqXHjxpRRAADygBlSIBfi4+PVtWtXzZo1Sx4eHmbHAQDArlFIgRw6d+6cEhIStGrVKpUoUcLsOAAA2D2W7IEcOHfunLp27aqEhATKKAAA+YRCCuRARESE5s2bp/vuu8/sKAAAOAyW7IFsOHPmjObNm6f333/f7CgAADgcZkiBOzh79qy6d++unj17mh0FAACHxAwpkIXLly/Lx8dHn3zyiapWrWp2HAAAHBIzpEAmTp06pZdeekmJiYmUUQAAChCFFMiAYRgaOXKkPv30UwUEBJgdBwAAh8aSPXCbv//+W7t27dLnn3/OZ9MDAFAImCEF/uXEiRPq1auX6tevTxkFAKCQUEiB/5OSkqITJ05o8eLFqly5stlxAABwGhRSQNLx48f1wgsv6D//+Q9lFACAQsY5pHB6MTEx6t27t0JDQ+Xqyu9oAAAUNgopnNrRo0fl6emptWvXqmjRombHAQDAKTEdBKd15MgR9evXT66urpRRAABMRCGF0/r666/1+eefq0KFCmZHAQDAqbFkD6dz+PBhLVu2TOPGjTM7CgAAEIUUTubIkSMaMGCAli5danYUAADwfyikcBrR0dG66667tGzZMpUrV87sOAAA4P9wDimcwoEDB9SlSxe5urpSRgEAsDEUUjg8wzA0YcIEhYWFqUSJEmbHAQAAt2HJHg5t3759Onr0qJYvX252FAAAkAlmSOGw/vrrL73++utq3Lix2VEAAEAWKKRwSMnJyTp//rzCwsJUpkwZs+MAAIAsUEjhcPbu3atOnTqpZcuWlFEAAOwA55DCoVy8eFHBwcFasWKFXFxczI4DAACygRlSOIy9e/cqKSlJa9euVenSpc2OAwAAsolCCoewZ88evfXWW/Ly8pKPj4/ZcQAAQA6wZA+HEBUVpfDwcN11111mRwEAADlEIYVd27VrlyIjIzV69GizowAAgFyikMJu/f777xoxYoTCw8PNjgIAAPKAc0hhl06dOqXy5csrPDxcJUuWNDsOAADIAwop7M6vv/6qPn36qEiRIpRRAAAcQK4K6Zw5c1S5cmV5e3urcePG2rFjR6b7fvLJJ2rWrJlKliypkiVLqlWrVlnuD2QlOTlZM2fO1MqVK+Xr62t2HAAAkA9yfA5pRESEgoODNX/+fDVu3FgzZsxQYGCgDh48mOGn4mzevFmdO3fWo48+Km9vb33wwQdq06aN/vrrL1WoUCFffoicslgs+uGHH3Tp0iXrtj/++MOULMi+X375RdeuXdOyZcvMjgIAAPJRjgvp9OnT1bdvX/Xq1UuSNH/+fH333XdavHixhg8fnm7/5cuXp/n6008/1ZdffqmNGzeqe/fuuYydN2vXrtXzzz+f4ffc3bnOyxb98ssvmjhxoiIiIsyOAgAA8lmO2ldiYqJ27typESNGWLe5urqqVatW2rZtW7YeIy4uTklJSVneLzIhIUEJCQnWr2NiYiRJSUlJSkpKsm5P/f//3pYdp06dkiSVLl1aderUsW738fHRK6+8kuPHQ8FJHfPr169r2bJl8vHxYXwcUG7fy7AvjLPjY4ydQ2bjnJdxz1EhvXTpklJSUhQQEJBme0BAgA4cOJCtx3jnnXdUvnx5tWrVKtN9QkJCNG7cuHTbN2zYkOF5g1FRUdl67lR//vmnJKlGjRp6880303zv3LlzOnfuXI4eDwXnwIEDioyMVHBwsLZs2WJ2HBSwnL6XYZ8YZ8fHGDuH28c5Li4u149VqOvTkydPVnh4uDZv3ixvb+9M9xsxYoSCg4OtX8fExKhSpUpq06aN/Pz8rNuTkpIUFRWl1q1by8PDI9s5Tp48KUkqW7asnn766Vz8JCgMJ0+e1Lx58/Tqq6/meIxhX3L7XoZ9YZwdH2PsHDIb59QV7dzIUSEtXbq03NzcdP78+TTbz58/r7Jly2Z57IcffqjJkyfr+++/1wMPPJDlvl5eXvLy8kq33cPDI8MXeGbbM+Pm5ibpn9MNeMPYpu3bt6tq1apatWqVNm7cmOMxhn1inJ0D4+z4GGPncPs452XMc3TbJ09PTzVo0EAbN260brNYLNq4caOaNGmS6XFTpkzRhAkTtG7dOjVs2DDXYeEcfvzxR02cOFFFihTJ8BcTAADgWHK8ZB8cHKwePXqoYcOGatSokWbMmKHY2FjrVffdu3dXhQoVFBISIkn64IMPNGbMGIWFhaly5cqKjo6WJBUtWlRFixbNxx8FjmLHjh0KDw9XkSJFODEeAAAnkONCGhQUpIsXL2rMmDGKjo5WvXr1tG7dOuuFTidPnpSr6/+feJ03b54SExPVoUOHNI8zduxYvffee3lLD4eyefNm/frrrxo6dKjZUQAAQCHK1UVNgwcP1uDBgzP83ubNm9N8feLEidw8Rb65deuWpk6dap2Zlf7/VfawHVu2bNH06dMVHh5udhQAAFDIHP4u8OvWrdPYsWMz/F7x4sULOQ0ycvToUd13330KDw/n40ABAHBCDl9IU++JVbVq1TSfDOXl5aVu3bqZFQv/5/vvv9esWbO0atUqrsgEAMBJOXwhTVWtWrVMZ0phjvj4eIWFhSk8PJwyCgCAE3OaQgrbsmHDBnl5eWnx4sVmRwEAACbL0X1Igfywfv16zZ8/X40bNzY7CgAAsAEUUhSq+Ph4eXp6KiwsLMuPjwUAAM6DJXsUmsjISK1Zs0YLFy40OwoAALAhFFIUigMHDmjJkiVatmyZ2VEAAICNcahCev36dQUFBenUqVPWbdeuXTMvECRJGzduVL169bRixQq5uzvUSw4AAOQDh2oHW7Zs0fr16zP8XpUqVQo5DSRp7dq1WrZsmZYtW0YZBQAAGXKohmCxWCRJNWvW1Lx586zbPTw81KhRI7NiOS3DMHTkyBEtW7ZMnp6eZscBAAA2yqEKaSo/Pz+1aNHC7BhObc2aNTp16pSCg4PNjgIAAGycQxZSmCsyMlIRERH6/PPPzY4CAADsAIUU+Wr//v16+OGH1bp1az4OFAAAZAs3xke+WbVqld5//32VKlWKMgoAALKNQop8ERMTo02bNumzzz6TqysvKwAAkH0s2SPPIiIiVKVKFc2dO9fsKAAAwA4xlYU8CQ8P13fffaeHHnrI7CgAAMBOUUiRazdv3lT58uW1ePFibnoPAAByjRaBXFm2bJl27dql6dOnmx0FAADYOQopcuy3337Tpk2b9Mknn5gdBQAAOACW7JEjX3/9tapXr65PPvlEbm5uZscBAAAOgEKKbAsNDdW3336rYsWKUUYBAEC+oZAiWywWi2JiYrRgwQLuMwoAAPIV55DijhYvXixJev31101OAgAAHBFTXcjSihUrtGPHDvXs2dPsKAAAwEExQ4pM/f7772rdurWCgoJYpgcAAAWGloEMLViwQAsXLlSpUqUoowAAoEDRNJDOxYsXdfToUc2ePVsuLi5mxwEAAA6OQoo05s+fr+joaE2ZMoUyCgAACgWFFFZz5szR/v37VbduXbOjAAAAJ8JFTZAkXb9+XQ899JAGDhzIzCgAAChUFFJo5syZunbtmsaOHWt2FAAA4IQopE7uhx9+0MmTJ/Xhhx+aHQUAADgpCqkTW758udq3b68WLVqwTA8AAEzDRU1Oatq0afr999/l6+tLGQUAAKZihtQJJSUlyc/PT8HBwZRRAABgOgqpk5kyZYqqVKmivn37mh0FAABAEkv2TmXevHm6fv26OnToYHYUAAAAK2ZIncSvv/6qTp06qUSJEizTAwAAm8IMqROYOHGi1q5dq5IlS1JGAQCAzaGQOriTJ09KksaPH29yEgAAgIxRSB1YSEiIkpOTNWrUKGZGAQCAzbLbc0jj4+P10ksv6Y8//rAWrpiYGLNj2Yxx48bJxcVFVatWNTsKAABAluy2kP7222/69ttvM/xe5cqVCzeMDTEMQ1euXNEzzzyjBg0amB0HAADgjuy2kFosFklSqVKltHz5crm7//OjuLm56ZFHHjEzmmkMw9CYMWPk7++v119/3ew4AAAA2WK3hTSVt7e3Hn/8cXl4eJgdxXRr166Vr68vZRQAANgVuy+k+GdmdOHCherVq5eee+45s+MAAADkCFfZ2znDMDRixAjFxMTI09PT7DgAAAA5xgypHTMMQ/Hx8br//vvVtWtXs+MAAADkCjOkdsowDL3zzjv68ccfKaMAAMCuUUjtVEhIiMqVK6fAwECzowAAAOQJS/Z2xjAM/fzzzxo8eLD8/PzMjgMAAJBnzJDaEcMwFBwcrF27dlFGAQCAw2CG1I4cOnRI1atX18CBA82OAgAAkG+YIbUDhmFo2LBh8vPzo4wCAACHQyG1cYZhaMiQIapSpYrKlStndhwAAIB8x5K9DbNYLLp06ZL69eununXrmh0HAACgQDBDaqMsFosGDx6s9evXU0YBAIBDo5DaqLCwMNWvX1/dunUzOwoAAECBYsnexlgsFn388cd6/fXX5erK7wsAAMDx0XhsiMVi0YABA+Tn50cZBQAAToMZUhthsVgUGxurtm3b6rnnnjM7DgAAQKFhGs4GpKSkqF+/fvrzzz8powAAwOlQSG3AyJEj1bx5czVp0sTsKAAAAIWOJXsTpaSk6Mcff9TYsWPl6+trdhwAAABTMENqkpSUFPXp00dnz56ljAIAAKfGDKlJ9u7dqzZt2qhz585mRwEAADAVM6SFLDk5Wa+++qruueceyigAAIAopIXKMAz16tVLLVq0UMmSJc2OAwAAYBNYsi8kycnJunTpkkaPHq377rvP7DgAAAA2gxnSQpCUlKQePXro119/pYwCAADchkJaCBYvXqwXXnhB7dq1MzsKAACAzWHJvgAlJSXpo48+0tChQ+Xi4mJ2HAAAAJvEDGkBSUxMVLdu3VSjRg3KKAAAQBaYIS0ASUlJiouLU58+fdSqVSuz4wAAANg0ZkjzWWJiorp27apTp05RRgEAALKBQprP3nzzTXXv3l3333+/2VEAAADsAkv2+SQhIUE//vijpk2bJm9vb7PjAAAA2A1mSPNBQkKCunbtquTkZMooAABADjFDmg927typPn366MknnzQ7CgAAgN1hhjQP4uPj1bNnTz344IOUUQAAgFyikOZScnKyOnfurC5duqhIkSJmxwEAALBbLNnnwq1bt3T9+nVNnz5dVapUMTsOAACAXWOGNIfi4uLUqVMnHTx4kDIKAACQDyikObRw4UK9/vrrat68udlRAAAAHAJL9tkUGxurjz/+WCNGjDA7CgAAgENhhjQbYmNj1alTJzVp0sTsKAAAAA6HGdI7SEhIUHx8vEaOHEkhBQAAKADMkGbh5s2bevHFF3X9+nXKKAAAQAGhkGZh8ODBGj58uKpWrWp2FAAAAIfFkn0Gbty4oW3btumTTz6Rh4eH2XEAAAAcGjOkt7lx44aCgoJUtGhRyigAAEAhYIb0Nr/++qveffddzhkFAAAoJBTS/xMTE6MBAwYoNDRUnp6eZscBAABwGizZS4qPj1fHjh31xhtvUEYBAAAKmdPPkF67dk0JCQlatGiRKlSoYHYcAAAAp+PUM6TXrl1TUFCQzpw5QxkFAAAwiVMX0gULFmjixIl66KGHzI4CAADgtJxyyf7q1auaP3++RowYYXYUAAAAp+d0M6RXrlxRUFCQAgMDzY4CAAAAOdkMaVxcnJKTkzV16lQ9+OCDZscBAACAnGiG9PLly3ruueeUkpJCGQUAALAhTlNIBw0apA8//FDlypUzOwoAAAD+xeGX7C9duqRdu3Zp2bJlcnd3+B8XAADA7jj0DOnFixfVqVMnlS9fnjIKAABgoxy2kBqGoZ07d2rGjBmqW7eu2XEAAACQCYcspBcuXFCnTp3UunVryigAAICNc7h17Bs3bqhLly76+OOP5ebmZnYcAAAA3IFDFdLo6Gi5ublp+fLlCggIMDsOAAAAsiFXS/Zz5sxR5cqV5e3trcaNG2vHjh1Z7v/FF1+oZs2a8vb21v3336/IyMhchc3KuXPn1LVrV129epUyCgAAYEdyXEgjIiIUHByssWPHateuXXrwwQcVGBioCxcuZLj/1q1b1blzZ/Xu3Vu7d+9W+/bt1b59e/355595Dv9vixYt0ty5c1WjRo18fVwAAAAUrBwX0unTp6tv377q1auXateurfnz58vX11eLFy/OcP+ZM2fqySef1NChQ1WrVi1NmDBBDz30kGbPnp3n8JKUkpKiKVOmaPTo0brvvvvy5TEBAABQeHJ0DmliYqJ27typESNGWLe5urqqVatW2rZtW4bHbNu2TcHBwWm2BQYGas2aNZk+T0JCghISEqxfx8TESJKSkpKUlJQkSUpOTpYkXblyRe3atbNuh2NJHVfG17Exzs6BcXZ8jLFzyGyc8zLuOSqkly5dUkpKSrpzNAMCAnTgwIEMj4mOjs5w/+jo6EyfJyQkROPGjUu3fcOGDfL19ZUk/fXXX5KkkiVL6vjx4zp+/HhOfhTYmaioKLMjoBAwzs6BcXZ8jLFzuH2c4+Licv1YNnmV/YgRI9LMqsbExKhSpUpq06aN/Pz8JEmPPPKIateurX379ql169by8PAwKy4KUFJSkqKiohhjB8c4OwfG2fExxs4hs3FOXdHOjRwV0tKlS8vNzU3nz59Ps/38+fMqW7ZshseULVs2R/tLkpeXl7y8vNJt9/DwsP7gAQEBatu2rVxcXNJsh2NijJ0D4+wcGGfHxxg7h9vHOS9jnqOLmjw9PdWgQQNt3LjRus1isWjjxo1q0qRJhsc0adIkzf7SP1O8me0PAAAA55LjJfvg4GD16NFDDRs2VKNGjTRjxgzFxsaqV69ekqTu3burQoUKCgkJkSQNGTJEzZs317Rp09S2bVuFh4frt99+08KFC/P3JwEAAIBdynEhDQoK0sWLFzVmzBhFR0erXr16WrdunfXCpZMnT8rV9f9PvD766KMKCwvT6NGjNXLkSFWvXl1r1qzJ0WfMG4YhKf25CUlJSYqLi1NMTAxLAw6KMXYOjLNzYJwdH2PsHDIb59SeltrbcsLFyM1Rhez06dOqVKmS2TEAAABwB6dOnVLFihVzdIxdFFKLxaKzZ8+qWLFicnFxsW5Pvfr+1KlT1qvv4VgYY+fAODsHxtnxMcbOIbNxNgxDN27cUPny5dOslmeHTd726Xaurq5ZNm0/Pz9e+A6OMXYOjLNzYJwdH2PsHDIa5+LFi+fqsXL80aEAAABAfqKQAgAAwFR2XUi9vLw0duzYDG+iD8fAGDsHxtk5MM6OjzF2DgUxznZxURMAAAAcl13PkAIAAMD+UUgBAABgKgopAAAATEUhBQAAgKlsvpDOmTNHlStXlre3txo3bqwdO3Zkuf8XX3yhmjVrytvbW/fff78iIyMLKSlyKydj/Mknn6hZs2YqWbKkSpYsqVatWt3xNQHbkNP3cqrw8HC5uLioffv2BRsQeZbTMb527ZoGDRqkcuXKycvLSzVq1ODvbDuQ03GeMWOG7rvvPvn4+KhSpUp68803FR8fX0hpkVM//vij2rVrp/Lly8vFxUVr1qy54zGbN2/WQw89JC8vL917770KDQ3N+RMbNiw8PNzw9PQ0Fi9ebPz1119G3759jRIlShjnz5/PcP+ff/7ZcHNzM6ZMmWLs27fPGD16tOHh4WHs3bu3kJMju3I6xl26dDHmzJlj7N6929i/f7/Rs2dPo3jx4sbp06cLOTlyIqfjnOr48eNGhQoVjGbNmhnPPfdc4YRFruR0jBMSEoyGDRsaTz/9tLFlyxbj+PHjxubNm409e/YUcnLkRE7Hefny5YaXl5exfPly4/jx48b69euNcuXKGW+++WYhJ0d2RUZGGqNGjTJWr15tSDK++uqrLPc/duyY4evrawQHBxv79u0zZs2aZbi5uRnr1q3L0fPadCFt1KiRMWjQIOvXKSkpRvny5Y2QkJAM9+/YsaPRtm3bNNsaN25s9O/fv0BzIvdyOsa3S05ONooVK2Z89tlnBRUR+SA345ycnGw8+uijxqeffmr06NGDQmrjcjrG8+bNM6pWrWokJiYWVkTkg5yO86BBg4zHH388zbbg4GDjscceK9CcyB/ZKaTDhg0z6tSpk2ZbUFCQERgYmKPnstkl+8TERO3cuVOtWrWybnN1dVWrVq20bdu2DI/Ztm1bmv0lKTAwMNP9Ya7cjPHt4uLilJSUpLvuuqugYiKPcjvO48ePV5kyZdS7d+/CiIk8yM0Yr127Vk2aNNGgQYMUEBCgunXratKkSUpJSSms2Mih3Izzo48+qp07d1qX9Y8dO6bIyEg9/fTThZIZBS+/upd7fobKT5cuXVJKSooCAgLSbA8ICNCBAwcyPCY6OjrD/aOjowssJ3IvN2N8u3feeUfly5dP92aA7cjNOG/ZskWLFi3Snj17CiEh8io3Y3zs2DFt2rRJXbt2VWRkpI4cOaKBAwcqKSlJY8eOLYzYyKHcjHOXLl106dIlNW3aVIZhKDk5WQMGDNDIkSMLIzIKQWbdKyYmRrdu3ZKPj0+2HsdmZ0iBO5k8ebLCw8P11Vdfydvb2+w4yCc3btxQt27d9Mknn6h06dJmx0EBsVgsKlOmjBYuXKgGDRooKChIo0aN0vz5882Ohny0efNmTZo0SXPnztWuXbu0evVqfffdd5owYYLZ0WBjbHaGtHTp0nJzc9P58+fTbD9//rzKli2b4TFly5bN0f4wV27GONWHH36oyZMn6/vvv9cDDzxQkDGRRzkd56NHj+rEiRNq166ddZvFYpEkubu76+DBg6pWrVrBhkaO5Oa9XK5cOXl4eMjNzc26rVatWoqOjlZiYqI8PT0LNDNyLjfj/O6776pbt27q06ePJOn+++9XbGys+vXrp1GjRsnVlXkxe5dZ9/Lz88v27KhkwzOknp6eatCggTZu3GjdZrFYtHHjRjVp0iTDY5o0aZJmf0mKiorKdH+YKzdjLElTpkzRhAkTtG7dOjVs2LAwoiIPcjrONWvW1N69e7Vnzx7rf88++6xatmypPXv2qFKlSoUZH9mQm/fyY489piNHjlh/2ZCkQ4cOqVy5cpRRG5WbcY6Li0tXOlN/CfnnmhnYu3zrXjm73qpwhYeHG15eXkZoaKixb98+o1+/fkaJEiWM6OhowzAMo1u3bsbw4cOt+//888+Gu7u78eGHHxr79+83xo4dy22fbFxOx3jy5MmGp6ensWrVKuPcuXPW/27cuGHWj4BsyOk4346r7G1fTsf45MmTRrFixYzBgwcbBw8eNL799lujTJkyxvvvv2/Wj4BsyOk4jx071ihWrJixYsUK49ixY8aGDRuMatWqGR07djTrR8Ad3Lhxw9i9e7exe/duQ5Ixffp0Y/fu3cbff/9tGIZhDB8+3OjWrZt1/9TbPg0dOtTYv3+/MWfOHMe77ZNhGMasWbOMu+++2/D09DQaNWpkbN++3fq95s2bGz169Eiz/8qVK40aNWoYnp6eRp06dYzvvvuukBMjp3Iyxvfcc48hKd1/Y8eOLfzgyJGcvpf/jUJqH3I6xlu3bjUaN25seHl5GVWrVjUmTpxoJCcnF3Jq5FROxjkpKcl47733jGrVqhne3t5GpUqVjIEDBxpXr14t/ODIlh9++CHDf2dTx7VHjx5G8+bN0x1Tr149w9PT06hataqxZMmSHD+vi2EwZw4AAADz2Ow5pAAAAHAOFFIAAACYikIKAAAAU1FIAQAAYCoKKQAAAExFIQUAAICpKKQAAAAwFYUUAAAApqKQAgAAwFQUUgAAAJiKQgoAAABTUUgBAABgqv8HI3GWILnmAlcAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "y_pred_prob_nn_2 = model.predict(X_test_norm)\n",
        "y_pred_class_nn_2 = np.argmax(y_pred_prob_nn_2, axis=1)\n",
        "\n",
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n",
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_2, 'NN')"
      ],
      "id": "VSZ9JHBFAv_a"
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_2.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_2.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn0WKSd2_WV8",
        "outputId": "092a52ca-0310-47f3-e5fe-7e34fbf65e12"
      },
      "id": "Qn0WKSd2_WV8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7aed12d52d40>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As I can observe in the plot, the validation stabilized in 0.5 and then gradually increases again. While the Train Loss decreases gradually. I think that it's a negative sign especially as the validation increases again it only means that the model is starting to overfit and is struggling to generalize further unseen data as it stabilizes at 0.5.\n"
      ],
      "metadata": {
        "id": "pW1vXhFHtIfR"
      },
      "id": "pW1vXhFHtIfR"
    },
    {
      "cell_type": "markdown",
      "id": "intimate-factory",
      "metadata": {
        "id": "intimate-factory"
      },
      "source": [
        "#### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broad-appointment",
      "metadata": {
        "id": "broad-appointment"
      },
      "source": [
        "#type your answer here\n",
        "In conclusion for this activity, I have been able to demonstrate and train the neural networks. With this, I get to understand the importance of training the model and the signs of overfitting. I can say that neural networks trains like a person trains itself, with proper information and application, we get to achieve we get to have a high accuracy and low validation loss. After all, I realized that as a person, if i'm not good at something, I can train myself to do better at all times, it might not be an instant but with consistency I can be great at something. That is the key value that I learned in this activity."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
